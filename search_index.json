[
["index.html", "The drake R Package User Manual Chapter 1 Introduction 1.1 The drake R package 1.2 Installation 1.3 Why drake? 1.4 Documentation 1.5 Help and troubleshooting 1.6 Similar work 1.7 Acknowledgements", " The drake R Package User Manual Will Landau, Kirill Müller, Alex Axthelm, Jasper Clarkberg, Lorenz Walthert Chapter 1 Introduction 1.1 The drake R package drake — or, Data Frames in R for Make — is a general-purpose workflow manager for data-driven tasks. It rebuilds intermediate data objects when their dependencies change, and it skips work when the results are already up to date. Not every runthrough starts from scratch, and completed workflows have tangible evidence of reproducibility. Drake is more scalable than knitr, more thorough than memoization, and more R-focused than other pipeline toolkits such as GNU Make, remake, and snakemake. 1.2 Installation You can choose among different versions of drake. # Install the latest stable release from CRAN. install.packages(&quot;drake&quot;) # Alternatively, install the development version from GitHub. install.packages(&quot;devtools&quot;) library(devtools) install_github(&quot;ropensci/drake&quot;) If you are installing the current CRAN version (5.2.1), you may encounter an error due to CodeDepends (ref: duncantl/CodeDepends#30, duncantl/CodeDepends#34). install.packages(&quot;drake&quot;) #&gt; ... #&gt; ERROR: dependency ‘graph’ is not available for package ‘CodeDepends’ #&gt; ... This is because drake 5.2.1 depends on CodeDepends, which depends on graph, which is not on CRAN. You have two possible solutions. Install the development version with devtools::install_github(&quot;ropensci/drake&quot;) Install graph from Bioconductor and proceed with the CRAN version of drake. source(&quot;https://bioconductor.org/biocLite.R&quot;) biocLite(&quot;graph&quot;) install.packages(&quot;CodeDepends&quot;) install.packages(&quot;drake&quot;) 1.3 Why drake? 1.3.1 What gets done stays done. Too many data science projects follow a Sisyphean loop: Launch the code. Wait while it runs. Discover an issue. Restart from scratch. Have you ever tried to manually salvage old results for a new runthrough? With drake, you can automatically Launch the parts that changed since last time. Skip the rest. 1.3.2 Reproducibility with confidence The R community emphasizes reproducibility. Traditional themes include scientific replicability, literate programming with knitr, and version control with git. But internal consistency is important too. Reproducibility carries the promise that your output matches the code and data you say you used. 1.3.2.1 Evidence Suppose you are reviewing someone else’s data analysis project for reproducibility. You scrutinize it carefully, checking that the datasets are available and the documentation is thorough. But could you re-create the results without the help of the original author? With drake, it is quick and easy to find out. make(plan) config &lt;- drake_config(plan) outdated(config) With everything already up to date, you have tangible evidence of reproducibility. Even though you did not re-create the results, you know the results are re-creatable. They faithfully show what the code is producing. Given the right package environment and system configuration, you have everything you need to reproduce all the output by yourself. 1.3.2.2 Ease When it comes time to actually rerun the entire project, you have much more confidence. Starting over from scratch is trivially easy. clean() # Remove the original author&#39;s results. make(plan) # Independently re-create the results from the code and input data. 1.3.2.3 Independent replication With even more evidence and confidence, you can invest the time to independently replicate the original code base if necessary. Up until this point, you relied on basic drake functions such as make(), so you may not have needed to peek at any substantive author-defined code in advance. In that case, you can stay usefully ignorant as you reimplement the original author’s methodology. In other words, drake could potentially improve the integrity of independent replication. 1.3.2.4 Readability and transparency Ideally, independent observers should be able to read your code and understand it. Drake helps in several ways. The workflow plan data frame explicitly outlines the steps of the analysis, and vis_drake_graph() visualizes how those steps depend on each other. Drake takes care of the parallel scheduling and high-performance computing (HPC) for you. That means the HPC code is no longer tangled up with the code that actually expresses your ideas. You can generate large collections of targets without necessarily changing your code base of imported functions, another nice separation between the concepts and the execution of your workflow 1.3.3 Aggressively scale up. Not every project can complete in a single R session on your laptop. Some projects need more speed or computing power. Some require a few local processor cores, and some need large high-performance computing systems. But parallel computing is hard. Your tables and figures depend on your analysis results, and your analyses depend on your datasets, so some tasks must finish before others even begin. Drake knows what to do. Parallelism is implicit and automatic. See the high-performance computing guide for all the details. # Use the spare cores on your local machine. make(plan, jobs = 4) # Or scale up to a supercomputer. drake_batchtools_tmpl_file(&quot;slurm&quot;) # https://slurm.schedmd.com/ library(future.batchtools) future::plan(batchtools_slurm, template = &quot;batchtools.slurm.tmpl&quot;, workers = 100) make(plan, parallelism = &quot;future_lapply&quot;) 1.4 Documentation The main resources to learn drake are The user manual, which contains a friendly introduction and several long-form tutorials. The documentation website, which serves as a quicker reference. Kirill Müller’s drake workshop from March 5, 2018. 1.4.1 Cheat sheet Thanks to Kirill for preparing a drake cheat sheet for the workshop. 1.4.2 Frequently asked questions The FAQ page is an index of links to appropriately-labeled issues on GitHub. To contribute, please submit a new issue and ask that it be labeled as a frequently asked question. 1.4.3 Function reference The reference section lists all the available functions. Here are the most important ones. drake_plan(): create a workflow data frame (like my_plan). make(): build your project. loadd(): load one or more built targets into your R session. readd(): read and return a built target. drake_config(): create a master configuration list for other user-side functions. vis_drake_graph(): show an interactive visual network representation of your workflow. outdated(): see which targets will be built in the next make(). deps(): check the dependencies of a command or function. failed(): list the targets that failed to build in the last make(). diagnose(): return the full context of a build, including errors, warnings, and messages. 1.4.4 Tutorials Thanks to Kirill for constructing two interactive learnr tutorials: one supporting drake itself, and a prerequisite walkthrough of the cooking package. 1.4.5 Examples Drake also has built-in example projects with code files available here. You can generate the files for a project with drake_example() (e.g. drake_example(&quot;gsp&quot;)), and you can list the available projects with drake_examples(). The beginner-oriented examples are listed below. They help you learn drake’s main features, and they show one way to organize the files of drake projects. main: drake’s main example, based on Kirill Müller’s drake pitch. This is the most accessible example for beginners. gsp: A concrete example using real econometrics data. It explores the relationships between gross state product and other quantities, and it shows off drake’s ability to generate lots of reproducibly-tracked tasks with ease. packages: A concrete example using data on R package downloads. It demonstrates how drake can refresh a project based on new incoming data without restarting everything from scratch. mtcars: An old example that demonstrates how to generate large workflow plan data frames using wildcard templating. Use load_mtcars_example() to set up the project in your workspace. 1.4.6 Presentations Kirill’s drake pitch drake + cooking with Kirill drake + cooking exercises Christine Stawitz’s R-Ladies Seattle talk on June 25, 2018 1.4.7 Real example projects Here are some real-world applications of drake in the wild. efcaguab/demografia-del-voto efcaguab/great-white-shark-nsw IndianaCHE/Detailed-SSP-Reports tiernanmartin/home-and-hope If you have a project of your own, we would love to add it. Click here to edit the README.Rmd file. 1.4.8 Context and history For context and history, check out this post on the rOpenSci blog and episode 22 of the R Podcast. 1.5 Help and troubleshooting The following resources document many known issues and challenges. Frequently-asked questions. Cautionary notes and edge cases Debugging and testing drake projects Other known issues (please search both open and closed ones). If you are still having trouble, please submit a new issue with a bug report or feature request, along with a minimal reproducible example where appropriate. 1.6 Similar work 1.6.1 GNU Make The original idea of a time-saving reproducible build system extends back at least as far as GNU Make, which still aids the work of data scientists as well as the original user base of complied language programmers. In fact, the name “drake” stands for “Data Frames in R for Make”. Make is used widely in reproducible research. Below are some examples from Karl Broman’s website. Bostock, Mike (2013). “A map of flowlines from NHDPlus.” https://github.com/mbostock/us-rivers. Powered by the Makefile at https://github.com/mbostock/us-rivers/blob/master/Makefile. Broman, Karl W (2012). “Halotype Probabilities in Advanced Intercross Populations.” G3 2(2), 199-202.Powered by the Makefile at https://github.com/kbroman/ailProbPaper/blob/master/Makefile. Broman, Karl W (2012). “Genotype Probabilities at Intermediate Generations in the Construction of Recombinant Inbred Lines.” *Genetics 190(2), 403-412. Powered by the Makefile at https://github.com/kbroman/preCCProbPaper/blob/master/Makefile. Broman, Karl W and Kim, Sungjin and Sen, Saunak and Ane, Cecile and Payseur, Bret A (2012). “Mapping Quantitative Trait Loci onto a Phylogenetic Tree.” Genetics 192(2), 267-279. Powered by the Makefile at https://github.com/kbroman/phyloQTLpaper/blob/master/Makefile. There are several reasons for R users to prefer drake instead. Drake already has a Make-powered parallel backend. Just run make(..., parallelism = &quot;Makefile&quot;, jobs = 2) to enjoy most of the original benefits of Make itself. Improved scalability. With Make, you must write a potentially large and cumbersome Makefile by hand. But with drake, you can use wildcard templating to automatically generate massive collections of targets with minimal code. Lower overhead for light-weight tasks. For each Make target that uses R, a brand new R session must spawn. For projects with thousands of small targets, that means more time may be spent loading R sessions than doing the actual work. With make(..., parallelism = &quot;mclapply, jobs = 4&quot;), drake launches 4 persistent workers up front and efficiently processes the targets in R. Convenient organization of output. With Make, the user must save each target as a file. Drake saves all the results for you automatically in a storr cache so you do not have to micromanage the results. 1.6.2 Remake Drake overlaps with its direct predecessor, remake. In fact, drake owes its core ideas to remake and Rich Fitzjohn. Remake’s development repository lists several real-world applications. Drake surpasses remake in several important ways, including but not limited to the following. High-performance computing. Remake has no native parallel computing support. Drake, on the other hand, has a thorough selection of parallel computing technologies and scheduling algorithms. Thanks to future, future.batchtools, and batchtools, it is straightforward to configure a drake project for most popular job schedulers, such as SLURM, TORQUE, and the Sun/Univa Grid Engine, as well as systems contained in Docker images. A friendly interface. In remake, the user must manually write a YAML configuration file to arrange the steps of a workflow, which leads to some of the same scalability problems as Make. Drake’s data-frame-based interface and wildcard templating functionality easily generate workflows at scale. Thorough documentation. Drake contains thorough user manual, a reference website, a comprehensive README, examples in the help files of user-side functions, and accessible example code that users can write with drake::example_drake(). Active maintenance. Drake is actively developed and maintained, and issues are usually addressed promptly. Presence on CRAN. At the time of writing, drake is available on CRAN, but remake is not. 1.6.3 Memoise Memoization is the strategic caching of the return values of functions. Every time a memoized function is called with a new set of arguments, the return value is saved for future use. Later, whenever the same function is called with the same arguments, the previous return value is salvaged, and the function call is skipped to save time. The memoise package is an excellent implementation of memoization in R. However, memoization does not go far enough. In reality, the return value of a function depends not only on the function body and the arguments, but also on any nested functions and global variables, the dependencies of those dependencies, and so on upstream. Drake surpasses memoise because it uses the entire dependency network graph of a project to decide which pieces need to be rebuilt and which ones can be skipped. 1.6.4 Knitr and R Markdown Much of the R community uses knitr and R Markdown for reproducible research. The idea is to intersperse code chunks in an R Markdown or *.Rnw file and then generate a dynamic report that weaves together code, output, and prose. Knitr is not designed to be a serious pipeline toolkit, and it should not be the primary computational engine for medium to large data analysis projects. Knitr scales far worse than Make or remake. The whole point is to consolidate output and prose, so it deliberately lacks the essential modularity. There is no obvious high-performance computing support. While there is a way to skip chunks that are already up to date (with code chunk options cache and autodep), this functionality is not the focus of knitr. It is deactivated by default, and remake and drake are more dependable ways to skip work that is already up to date. Drake was designed to manage the entire workflow with knitr reports as targets. The strategy is analogous for knitr reports within remake projects. 1.6.5 Factual’s Drake Factual’s Drake is similar in concept, but the development effort is completely unrelated to the drake R package. 1.6.6 Other pipeline toolkits There are countless other successful pipeline toolkits. The drake package distinguishes itself with its R-focused approach, Tidyverse-friendly interface, and a thorough selection of parallel computing technologies and scheduling algorithms. 1.7 Acknowledgements Special thanks to Jarad Niemi, my advisor from graduate school, for first introducing me to the idea of Makefiles for research. He originally set me down the path that led to drake. Many thanks to Julia Lowndes, Ben Marwick, and Peter Slaughter for reviewing drake for rOpenSci, and to Maëlle Salmon for such active involvement as the editor. Thanks also to the following people for contributing early in development. Alex Axthelm Chan-Yub Park Daniel Falster Eric Nantz Henrik Bengtsson Ian Watson Jasper Clarkberg Kendon Bell Kirill Müller Credit for images is attributed here. "],
["example-main.html", "Chapter 2 The main example 2.1 Set the stage. 2.2 Make your results. 2.3 Go back and fix things. 2.4 Try it yourself!", " Chapter 2 The main example A typical data analysis workflow is a sequence of data transformations. Raw data becomes tidy data, then turns into fitted models, summaries, and reports. Other analyses are usually variations of this pattern, and drake can easily accommodate them. 2.1 Set the stage. To set up a project, load your packages, library(drake) library(dplyr) library(ggplot2) load your custom functions, create_plot &lt;- function(data) { ggplot(data, aes(x = Petal.Width, fill = Species)) + geom_histogram() } check any supporting files (optional), ## Get the files with drake_example(&quot;main&quot;). file.exists(&quot;raw_data.xlsx&quot;) ## [1] TRUE file.exists(&quot;report.Rmd&quot;) ## [1] TRUE and plan what you are going to do. plan &lt;- drake_plan( raw_data = readxl::read_excel(file_in(&quot;raw_data.xlsx&quot;)), data = raw_data %&gt;% mutate(Species = forcats::fct_inorder(Species)) %&gt;% select(-X__1), hist = create_plot(data), fit = lm(Sepal.Width ~ Petal.Width + Species, data), rmarkdown::render( knitr_in(&quot;report.Rmd&quot;), output_file = file_out(&quot;report.html&quot;), quiet = TRUE ) ) plan ## # A tibble: 5 x 2 ## target command ## * &lt;chr&gt; &lt;chr&gt; ## 1 raw_data &quot;readxl::read_excel(file_in(\\&quot;raw_data.xlsx\\&quot;))&quot; ## 2 data &quot;raw_data %&gt;% mutate(Species = forcats::fct_inorder(S… ## 3 hist create_plot(data) ## 4 fit lm(Sepal.Width ~ Petal.Width + Species, data) ## 5 &quot;\\&quot;report.html\\&quot;&quot; &quot;rmarkdown::render(knitr_in(\\&quot;report.Rmd\\&quot;), output_f… Optionally, visualize your workflow to make sure you set it up correctly. The graph is interactive, so you can click, drag, hover, zoom, and explore. config &lt;- drake_config(plan) vis_drake_graph(config) 2.2 Make your results. So far, we have just been setting the stage. Use make() to do the real work. Targets are built in the correct order regardless of the row order of plan. make(plan) ## target raw_data ## target data ## target fit ## target hist ## target file &quot;report.html&quot; Except for files like report.html, your output is stored in a hidden .drake/ folder. Reading it back is easy. readd(data) # See also loadd(). ## # A tibble: 150 x 5 ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa ## 5 5 3.6 1.4 0.2 setosa ## 6 5.4 3.9 1.7 0.4 setosa ## 7 4.6 3.4 1.4 0.3 setosa ## 8 5 3.4 1.5 0.2 setosa ## 9 4.4 2.9 1.4 0.2 setosa ## 10 4.9 3.1 1.5 0.1 setosa ## # ... with 140 more rows The graph shows everything up to date. vis_drake_graph(config) 2.3 Go back and fix things. You may look back on your work and see room for improvement, but it’s all good! The whole point of drake is to help you go back and change things quickly and painlessly. For example, we forgot to give our histogram a bin width. readd(hist) ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. So let’s fix the plotting function. create_plot &lt;- function(data) { ggplot(data, aes(x = Petal.Width, fill = Species)) + geom_histogram(binwidth = 0.25) + theme_gray(20) } Drake knows which results are affected. vis_drake_graph(config) The next make() just builds hist and report.html. No point in wasting time on the data or model. make(plan) ## target hist ## target file &quot;report.html&quot; loadd(hist) hist 2.4 Try it yourself! Use drake_example(&quot;main&quot;) to get all the materials. "],
["plans.html", "Chapter 3 Workflow data frames 3.1 What is a workflow plan data frame? 3.2 Rationale 3.3 Generating large workflow plans 3.4 Optional columns in your plan.", " Chapter 3 Workflow data frames 3.1 What is a workflow plan data frame? Your workflow plan data frame is the object where you declare all the objects and files you are going to produce when you run your project. It enumerates each output item, or target, and the R command that will produce it. Here is the workflow plan from our previous example. plan &lt;- drake_plan( raw_data = readxl::read_excel(file_in(&quot;raw_data.xlsx&quot;)), data = raw_data %&gt;% mutate(Species = forcats::fct_inorder(Species)) %&gt;% select(-X__1), hist = create_plot(data), fit = lm(Sepal.Width ~ Petal.Width + Species, data), rmarkdown::render( knitr_in(&quot;report.Rmd&quot;), output_file = file_out(&quot;report.html&quot;), quiet = TRUE ) ) plan ## # A tibble: 5 x 2 ## target command ## * &lt;chr&gt; &lt;chr&gt; ## 1 raw_data &quot;readxl::read_excel(file_in(\\&quot;raw_data.xlsx\\&quot;))&quot; ## 2 data &quot;raw_data %&gt;% mutate(Species = forcats::fct_inorder(S… ## 3 hist create_plot(data) ## 4 fit lm(Sepal.Width ~ Petal.Width + Species, data) ## 5 &quot;\\&quot;report.html\\&quot;&quot; &quot;rmarkdown::render(knitr_in(\\&quot;report.Rmd\\&quot;), output_f… When you run make(plan), drake will produce targets raw_data, data, hist, fit, and report.Rmd. 3.2 Rationale The workflow plan may seem like a burden to set up, and the use of data frames may seem counterintuitive at first, but the rewards are worth the effort. 3.2.1 You can skip up-to-date work. As we saw in our previous example, repeated make()s skip work that is already up to date. The reason drake can skip things is that you declared all the skippable steps as targets in the workflow plan. Thus, workflow plans are vital to the time savings drake brings to large projects. This approach of declaring targets in advance has stood the test of time. The idea dates at least as far back as GNU Make, which uses Makefiles to declare targets and dependencies. drake’s predecessor remake uses YAML files in a similar way. 3.2.2 You do not need to worry about which targets run first. When you call make() on the plan above, drake takes care of &quot;raw_data.xlsx&quot;, then raw_data, and then data in sequence. Once data completes, fit and hist can start in any order, and then &quot;report.md&quot; begins once everything else is done. Because drake analyzes your commands for dependencies, it always builds your targets in this correct order. That means you can rearrange the rows of the workflow plan in any way you want, which is not the case with lines in an R script or code chunks in a knitr report. drake_plan( fit = lm(Sepal.Width ~ Petal.Width + Species, data), rmarkdown::render( knitr_in(&quot;report.Rmd&quot;), output_file = file_out(&quot;report.html&quot;), quiet = TRUE ), hist = create_plot(data), data = raw_data %&gt;% mutate(Species = forcats::fct_inorder(Species)) %&gt;% select(-X__1), raw_data = readxl::read_excel(file_in(&quot;raw_data.xlsx&quot;)) ) ## # A tibble: 5 x 2 ## target command ## * &lt;chr&gt; &lt;chr&gt; ## 1 fit lm(Sepal.Width ~ Petal.Width + Species, data) ## 2 &quot;\\&quot;report.html\\&quot;&quot; &quot;rmarkdown::render(knitr_in(\\&quot;report.Rmd\\&quot;), output_f… ## 3 hist create_plot(data) ## 4 data &quot;raw_data %&gt;% mutate(Species = forcats::fct_inorder(S… ## 5 raw_data &quot;readxl::read_excel(file_in(\\&quot;raw_data.xlsx\\&quot;))&quot; 3.2.3 Data frames scale well. Makefiles are successful for Make because they accommodate software written in multiple languages. However, such external configuration files are not the best solution for R. Maintaining a Makefile or a remake YAML file requires a lot of manual typing. But with drake plans, you can use the usual data frame manipulation tools to expand, generate, and piece together large projets. The gsp example shows how expand.grid() and rbind() to automatically create plans with hundreds of targets. In addition, drake has a wildcard templating mechanism to generate large plans. 3.3 Generating large workflow plans drake provides many more utilites that increase the flexibility of workflow plan generation beyond expand.grid(). drake_plan() evaluate_plan() plan_analyses() plan_summaries() expand_plan() gather_plan() reduce_plan() 3.3.1 Wildcard templating In drake, you can write plans with wildcards. These wilrdards are placeholders for text in commands. By iterating over the possible values of a wildcard, you can easily generate plans with thousands of targets. Let’s say you are running a simulation study, and you need to generate sets of random numbers from different distributions. plan &lt;- drake_plan( t = rt(1000, df = 5), normal = runif(1000, mean = 0, sd = 1) ) If you need to generate many datasets with different means, you may wish to write out each target individually. drake_plan( t = rt(1000, df = 5), normal_0 = runif(1000, mean = 0, sd = 1), normal_1 = runif(1000, mean = 1, sd = 1), normal_2 = runif(1000, mean = 2, sd = 1), normal_3 = runif(1000, mean = 3, sd = 1), normal_4 = runif(1000, mean = 4, sd = 1), normal_5 = runif(1000, mean = 5, sd = 1), normal_6 = runif(1000, mean = 6, sd = 1), normal_7 = runif(1000, mean = 7, sd = 1), normal_8 = runif(1000, mean = 8, sd = 1), normal_9 = runif(1000, mean = 9, sd = 1) ) But writing all that code manually is a pain and prone to human error. Instead, use evaluate_plan() plan &lt;- drake_plan( t = rt(1000, df = 5), normal = runif(1000, mean = mean__, sd = 1) ) evaluate_plan(plan, wildcard = &quot;mean__&quot;, values = 0:9) ## # A tibble: 11 x 2 ## target command ## * &lt;chr&gt; &lt;chr&gt; ## 1 t rt(1000, df = 5) ## 2 normal_0 runif(1000, mean = 0, sd = 1) ## 3 normal_1 runif(1000, mean = 1, sd = 1) ## 4 normal_2 runif(1000, mean = 2, sd = 1) ## 5 normal_3 runif(1000, mean = 3, sd = 1) ## 6 normal_4 runif(1000, mean = 4, sd = 1) ## 7 normal_5 runif(1000, mean = 5, sd = 1) ## 8 normal_6 runif(1000, mean = 6, sd = 1) ## 9 normal_7 runif(1000, mean = 7, sd = 1) ## 10 normal_8 runif(1000, mean = 8, sd = 1) ## 11 normal_9 runif(1000, mean = 9, sd = 1) You can specify multiple wildcards at once. If multiple wildcards appear in the same command, you will get a new target for each unique combination of values. plan &lt;- drake_plan( t = rt(1000, df = df__), normal = runif(1000, mean = mean__, sd = sd__) ) evaluate_plan( plan, rules = list( mean__ = c(0, 1), sd__ = c(3, 4), df__ = 5:7 ) ) ## # A tibble: 7 x 2 ## target command ## * &lt;chr&gt; &lt;chr&gt; ## 1 t_5 rt(1000, df = 5) ## 2 t_6 rt(1000, df = 6) ## 3 t_7 rt(1000, df = 7) ## 4 normal_0_3 runif(1000, mean = 0, sd = 3) ## 5 normal_0_4 runif(1000, mean = 0, sd = 4) ## 6 normal_1_3 runif(1000, mean = 1, sd = 3) ## 7 normal_1_4 runif(1000, mean = 1, sd = 4) Set expand to FALSE to disable expansion. plan &lt;- drake_plan( t = rpois(samples__, lambda = mean__), normal = runif(samples__, mean = mean__) ) evaluate_plan( plan, rules = list( samples__ = c(50, 100), mean__ = c(1, 5) ), expand = FALSE ) ## # A tibble: 2 x 2 ## target command ## * &lt;chr&gt; &lt;chr&gt; ## 1 t rpois(50, lambda = 1) ## 2 normal runif(100, mean = 5) Wildcard templating can sometimes be tricky. For example, suppose your project is to analyze school data, and your workflow checks several metrics of several schools. The idea is to write a workflow plan with your metrics and let the wildcard templating expand over the available schools. hard_plan &lt;- drake_plan( credits = check_credit_hours(school__), students = check_students(school__), grads = check_graduations(school__), public_funds = check_public_funding(school__) ) evaluate_plan( hard_plan, rules = list(school__ = c(&quot;schoolA&quot;, &quot;schoolB&quot;, &quot;schoolC&quot;)) ) ## # A tibble: 12 x 2 ## target command ## * &lt;chr&gt; &lt;chr&gt; ## 1 credits_schoolA check_credit_hours(schoolA) ## 2 credits_schoolB check_credit_hours(schoolB) ## 3 credits_schoolC check_credit_hours(schoolC) ## 4 students_schoolA check_students(schoolA) ## 5 students_schoolB check_students(schoolB) ## 6 students_schoolC check_students(schoolC) ## 7 grads_schoolA check_graduations(schoolA) ## 8 grads_schoolB check_graduations(schoolB) ## 9 grads_schoolC check_graduations(schoolC) ## 10 public_funds_schoolA check_public_funding(schoolA) ## 11 public_funds_schoolB check_public_funding(schoolB) ## 12 public_funds_schoolC check_public_funding(schoolC) But what if some metrics do not make sense? For example, what if schoolC is a completely privately-funded school? With no public funds, check_public_funds(schoolC) may quit in error if we are not careful. This is where setting up workflow plans requires a little creativity. In this case, we recommend that you use two wildcards: one for all the schools and another for just the public schools. The new plan has no twelfth row. plan_template &lt;- drake_plan( school = get_school_data(&quot;school__&quot;), credits = check_credit_hours(all_schools__), students = check_students(all_schools__), grads = check_graduations(all_schools__), public_funds = check_public_funding(public_schools__) ) evaluate_plan( plan = plan_template, rules = list( school__ = c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;), all_schools__ = c(&quot;school_A&quot;, &quot;school_B&quot;, &quot;school_C&quot;), public_schools__ = c(&quot;school_A&quot;, &quot;school_B&quot;) ), trace = TRUE ) ## # A tibble: 14 x 5 ## target command school__ all_schools__ public_schools__ ## * &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 school_A &quot;get_sch… A &lt;NA&gt; &lt;NA&gt; ## 2 school_B &quot;get_sch… B &lt;NA&gt; &lt;NA&gt; ## 3 school_C &quot;get_sch… C &lt;NA&gt; &lt;NA&gt; ## 4 credits_school_A check_cr… &lt;NA&gt; school_A &lt;NA&gt; ## 5 credits_school_B check_cr… &lt;NA&gt; school_B &lt;NA&gt; ## 6 credits_school_C check_cr… &lt;NA&gt; school_C &lt;NA&gt; ## 7 students_school_A check_st… &lt;NA&gt; school_A &lt;NA&gt; ## 8 students_school_B check_st… &lt;NA&gt; school_B &lt;NA&gt; ## 9 students_school_C check_st… &lt;NA&gt; school_C &lt;NA&gt; ## 10 grads_school_A check_gr… &lt;NA&gt; school_A &lt;NA&gt; ## 11 grads_school_B check_gr… &lt;NA&gt; school_B &lt;NA&gt; ## 12 grads_school_C check_gr… &lt;NA&gt; school_C &lt;NA&gt; ## 13 public_funds_school_A check_pu… &lt;NA&gt; &lt;NA&gt; school_A ## 14 public_funds_school_B check_pu… &lt;NA&gt; &lt;NA&gt; school_B Thanks to Alex Axthelm for this use case in issue 235. 3.3.2 Wildcard clusters With evaluate_plan(trace = TRUE), you can generate columns that show how the targets were generated from the wildcards. plan_template &lt;- drake_plan( school = get_school_data(&quot;school__&quot;), credits = check_credit_hours(all_schools__), students = check_students(all_schools__), grads = check_graduations(all_schools__), public_funds = check_public_funding(public_schools__) ) plan &lt;- evaluate_plan( plan = plan_template, rules = list( school__ = c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;), all_schools__ = c(&quot;school_A&quot;, &quot;school_B&quot;, &quot;school_C&quot;), public_schools__ = c(&quot;school_A&quot;, &quot;school_B&quot;) ), trace = TRUE ) plan ## # A tibble: 14 x 5 ## target command school__ all_schools__ public_schools__ ## * &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 school_A &quot;get_sch… A &lt;NA&gt; &lt;NA&gt; ## 2 school_B &quot;get_sch… B &lt;NA&gt; &lt;NA&gt; ## 3 school_C &quot;get_sch… C &lt;NA&gt; &lt;NA&gt; ## 4 credits_school_A check_cr… &lt;NA&gt; school_A &lt;NA&gt; ## 5 credits_school_B check_cr… &lt;NA&gt; school_B &lt;NA&gt; ## 6 credits_school_C check_cr… &lt;NA&gt; school_C &lt;NA&gt; ## 7 students_school_A check_st… &lt;NA&gt; school_A &lt;NA&gt; ## 8 students_school_B check_st… &lt;NA&gt; school_B &lt;NA&gt; ## 9 students_school_C check_st… &lt;NA&gt; school_C &lt;NA&gt; ## 10 grads_school_A check_gr… &lt;NA&gt; school_A &lt;NA&gt; ## 11 grads_school_B check_gr… &lt;NA&gt; school_B &lt;NA&gt; ## 12 grads_school_C check_gr… &lt;NA&gt; school_C &lt;NA&gt; ## 13 public_funds_school_A check_pu… &lt;NA&gt; &lt;NA&gt; school_A ## 14 public_funds_school_B check_pu… &lt;NA&gt; &lt;NA&gt; school_B And then when you visualize the dependency graph, you can cluster nodes based on the wildcard info. config &lt;- drake_config(plan) vis_drake_graph( config, group = &quot;all_schools__&quot;, clusters = c(&quot;school_A&quot;, &quot;school_B&quot;, &quot;school_C&quot;) ) See the visualization guide for more details. 3.3.3 Specialized wildcard functionality In the mtcars example, we will analyze bootstrapped versions of the mtcars dataset to look for an association between the weight and the fuel efficiency of cars. This example uses plan_analyses() and plan_summaries(), two specialized applications of evaluate_plan(). First, we generate the plan for the bootstrapped datasets. my_datasets &lt;- drake_plan( small = simulate(48), large = simulate(64)) my_datasets ## # A tibble: 2 x 2 ## target command ## * &lt;chr&gt; &lt;chr&gt; ## 1 small simulate(48) ## 2 large simulate(64) We want to analyze each dataset with one of two regression models. methods &lt;- drake_plan( regression1 = reg1(dataset__), regression2 = reg2(dataset__)) methods ## # A tibble: 2 x 2 ## target command ## * &lt;chr&gt; &lt;chr&gt; ## 1 regression1 reg1(dataset__) ## 2 regression2 reg2(dataset__) We evaluate the dataset__ wildcard to generate all the regression commands we will need. my_analyses &lt;- plan_analyses(methods, datasets = my_datasets) my_analyses ## # A tibble: 4 x 2 ## target command ## * &lt;chr&gt; &lt;chr&gt; ## 1 regression1_small reg1(small) ## 2 regression1_large reg1(large) ## 3 regression2_small reg2(small) ## 4 regression2_large reg2(large) Next, we summarize each analysis of each dataset. We calculate descriptive statistics on the residuals, and we collect the regression coefficients and their p-values. summary_types &lt;- drake_plan( summ = suppressWarnings(summary(analysis__$residuals)), coef = suppressWarnings(summary(analysis__))$coefficients ) summary_types ## # A tibble: 2 x 2 ## target command ## * &lt;chr&gt; &lt;chr&gt; ## 1 summ suppressWarnings(summary(analysis__$residuals)) ## 2 coef suppressWarnings(summary(analysis__))$coefficients results &lt;- plan_summaries(summary_types, analyses = my_analyses, datasets = my_datasets, gather = NULL) # Gathering is suppressed here. results ## # A tibble: 8 x 2 ## target command ## &lt;chr&gt; &lt;chr&gt; ## 1 summ_regression1_small suppressWarnings(summary(regression1_small$resid… ## 2 summ_regression1_large suppressWarnings(summary(regression1_large$resid… ## 3 summ_regression2_small suppressWarnings(summary(regression2_small$resid… ## 4 summ_regression2_large suppressWarnings(summary(regression2_large$resid… ## 5 coef_regression1_small suppressWarnings(summary(regression1_small))$coe… ## 6 coef_regression1_large suppressWarnings(summary(regression1_large))$coe… ## 7 coef_regression2_small suppressWarnings(summary(regression2_small))$coe… ## 8 coef_regression2_large suppressWarnings(summary(regression2_large))$coe… Next, we bind all the rows together for a single plan that we can later supply to make(). my_plan &lt;- rbind(my_datasets, my_analyses, results) my_plan ## # A tibble: 14 x 2 ## target command ## &lt;chr&gt; &lt;chr&gt; ## 1 small simulate(48) ## 2 large simulate(64) ## 3 regression1_small reg1(small) ## 4 regression1_large reg1(large) ## 5 regression2_small reg2(small) ## 6 regression2_large reg2(large) ## 7 summ_regression1_small suppressWarnings(summary(regression1_small$resi… ## 8 summ_regression1_large suppressWarnings(summary(regression1_large$resi… ## 9 summ_regression2_small suppressWarnings(summary(regression2_small$resi… ## 10 summ_regression2_large suppressWarnings(summary(regression2_large$resi… ## 11 coef_regression1_small suppressWarnings(summary(regression1_small))$co… ## 12 coef_regression1_large suppressWarnings(summary(regression1_large))$co… ## 13 coef_regression2_small suppressWarnings(summary(regression2_small))$co… ## 14 coef_regression2_large suppressWarnings(summary(regression2_large))$co… 3.3.4 Non-wildcard functions 3.3.4.1 expand_plan() Sometimes, you just want multiple replicates of the same targets. plan &lt;- drake_plan( fake_data = simulate_from_model(), bootstrapped_data = bootstrap_from_real_data(real_data) ) expand_plan(plan, values = 1:3) ## # A tibble: 6 x 2 ## target command ## * &lt;chr&gt; &lt;chr&gt; ## 1 fake_data_1 simulate_from_model() ## 2 fake_data_2 simulate_from_model() ## 3 fake_data_3 simulate_from_model() ## 4 bootstrapped_data_1 bootstrap_from_real_data(real_data) ## 5 bootstrapped_data_2 bootstrap_from_real_data(real_data) ## 6 bootstrapped_data_3 bootstrap_from_real_data(real_data) 3.3.4.2 gather_plan() Other times, you want to combine multiple targets into one. plan &lt;- drake_plan( small = data.frame(type = &quot;small&quot;, x = rnorm(25), y = rnorm(25)), large = data.frame(type = &quot;large&quot;, x = rnorm(1000), y = rnorm(1000)) ) gather_plan(plan, target = &quot;combined&quot;) ## # A tibble: 1 x 2 ## target command ## &lt;chr&gt; &lt;chr&gt; ## 1 combined list(small = small, large = large) In this case, small and large are data frames, so it may be more convenient to combine the rows together. gather_plan(plan, target = &quot;combined&quot;, gather = &quot;rbind&quot;) ## # A tibble: 1 x 2 ## target command ## &lt;chr&gt; &lt;chr&gt; ## 1 combined rbind(small = small, large = large) 3.3.4.3 reduce_plan() reduce_plan() is similar to gather_plan(), but it allows you to combine multiple targets together in pairs. This is useful if combining everything at once requires too much time or computer memory, or if you want to parallelize the aggregation. plan &lt;- drake_plan( a = 1, b = 2, c = 3, d = 4 ) reduce_plan(plan) ## # A tibble: 3 x 2 ## target command ## &lt;chr&gt; &lt;chr&gt; ## 1 target_1 a + b ## 2 target_2 c + d ## 3 target target_1 + target_2 You can control how each pair of targets gets combined. reduce_plan(plan, begin = &quot;c(&quot;, op = &quot;, &quot;, end = &quot;)&quot;) ## # A tibble: 3 x 2 ## target command ## &lt;chr&gt; &lt;chr&gt; ## 1 target_1 c(a, b) ## 2 target_2 c(c, d) ## 3 target c(target_1, target_2) 3.4 Optional columns in your plan. Besides the usual columns target and command, there are other columns you can add. cpu, elapsed, and timeout: number of seconds to wait for the target to build before timing out (timeout for a general upper bound, cpu for CPU time, and elapsed for elapsed time). priority: for paralllel computing, optionally rank the targets according to priority. That way, when two targets become ready to build at the same time, drake will pick the one with the dominant priority first. retries: number of times to retry building a target in the event of an error. trigger: choose the criterion that drake uses to decide whether to build the target. See ?triggers to learn more. worker: for paralllel computing, optionally name the preferred worker to assign to each target. "],
["example-packages.html", "Chapter 4 Example: R package download trends 4.1 Get the code. 4.2 Overview 4.3 Analysis 4.4 What remote data sources in general?", " Chapter 4 Example: R package download trends This chapter explores R package download trends using the cranlogs package. 4.1 Get the code. Write the code files to your workspace. drake_example(&quot;packages&quot;) The new packages folder now includes a file structure of a serious drake project, plus an interactive-tutorial.R to narrate the example. The code is also online here. 4.2 Overview This small data analysis project explores some trends in R package downloads over time. The datasets are downloaded using the cranlogs package. library(cranlogs) cran_downloads(packages = &quot;dplyr&quot;, when = &quot;last-week&quot;) ## date count package ## 1 2018-07-05 18972 dplyr ## 2 2018-07-06 16684 dplyr ## 6 2018-07-07 0 dplyr ## 7 2018-07-08 0 dplyr ## 3 2018-07-09 19157 dplyr ## 4 2018-07-10 18547 dplyr ## 5 2018-07-11 17816 dplyr Above, each count is the number of times dplyr was downloaded from the RStudio CRAN mirror on the given day. To stay up to date with the latest download statistics, we need to refresh the data frequently. With drake, we can bring all our work up to date without restarting everything from scratch. 4.3 Analysis First, we load the required packages. Drake knows about the packages you install and load. library(cranlogs) library(drake) library(dplyr) library(ggplot2) library(knitr) We want to explore the daily downloads from these packages. package_list &lt;- c( &quot;knitr&quot;, &quot;Rcpp&quot;, &quot;ggplot2&quot; ) We plan to use the cranlogs package. The data frames older and recent will contain the number of daily downloads for each package from the RStudio CRAN mirror. data_plan &lt;- drake_plan( older = cran_downloads( packages = package_list, from = &quot;2016-11-01&quot;, to = &quot;2016-12-01&quot; ), recent = target( command = cran_downloads( packages = package_list, when = &quot;last-month&quot; ), trigger = &quot;always&quot; ), strings_in_dots = &quot;literals&quot; ) data_plan ## # A tibble: 2 x 3 ## target command trigger ## * &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 older &quot;cran_downloads(packages = package_list, from = \\&quot;2016-1… any ## 2 recent &quot;cran_downloads(packages = package_list, when = \\&quot;last-m… always Our data_plan data frame has a &quot;trigger&quot; column because the latest download data needs to be refreshed every day. We use triggers to force recent to always build. For more on triggers, see the chapter on debugging and testing. Instead of triggers, we could have just made recent a global variable like package_list instead of a formal target in data_plan. We want to summarize each set of download statistics a couple different ways. output_types &lt;- drake_plan( averages = make_my_table(dataset__), plot = make_my_plot(dataset__) ) output_types ## # A tibble: 2 x 2 ## target command ## * &lt;chr&gt; &lt;chr&gt; ## 1 averages make_my_table(dataset__) ## 2 plot make_my_plot(dataset__) We need to define functions to summarize and plot the data. make_my_table &lt;- function(downloads){ group_by(downloads, package) %&gt;% summarize(mean_downloads = mean(count)) } make_my_plot &lt;- function(downloads){ ggplot(downloads) + geom_line(aes(x = date, y = count, group = package, color = package)) } Below, the targets recent and older each take turns substituting the dataset__ wildcard. Thus, output_plan has four rows. output_plan &lt;- plan_analyses( plan = output_types, datasets = data_plan ) output_plan ## # A tibble: 4 x 2 ## target command ## * &lt;chr&gt; &lt;chr&gt; ## 1 averages_older make_my_table(older) ## 2 averages_recent make_my_table(recent) ## 3 plot_older make_my_plot(older) ## 4 plot_recent make_my_plot(recent) We plan to weave the results together in a dynamic knitr report. report_plan &lt;- drake_plan( knit(knitr_in(&quot;report.Rmd&quot;), file_out(&quot;report.md&quot;), quiet = TRUE) ) report_plan ## # A tibble: 1 x 2 ## target command ## * &lt;chr&gt; &lt;chr&gt; ## 1 &quot;\\&quot;report.md\\&quot;&quot; &quot;knit(knitr_in(\\&quot;report.Rmd\\&quot;), file_out(\\&quot;report.md\\&quot;)… Because of the mention of knitr_in() above, make() will look dependencies inside report.Rmd (targets mentioned with loadd() or readd() in active code chunks). That way, whenever a dependency changes, drake will rebuild report.md when you call make(). For that to happen, we need report.Rmd to exist before the call to make(). For this example, you can find report.Rmd here. Now, we complete the workflow plan data frame by concatenating the results together. Drake analyzes the plan to figure out the dependency network, so row order does not matter. whole_plan &lt;- bind_plans( data_plan, output_plan, report_plan ) whole_plan ## # A tibble: 7 x 3 ## target command trigger ## * &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 older &quot;cran_downloads(packages = package_list, from =… any ## 2 recent &quot;cran_downloads(packages = package_list, when =… always ## 3 averages_older make_my_table(older) any ## 4 averages_recent make_my_table(recent) any ## 5 plot_older make_my_plot(older) any ## 6 plot_recent make_my_plot(recent) any ## 7 &quot;\\&quot;report.md\\&quot;&quot; &quot;knit(knitr_in(\\&quot;report.Rmd\\&quot;), file_out(\\&quot;repo… any Now, we run the project to download the data and analyze it. The results will be summarized in the knitted report, report.md, but you can also read the results directly from the cache. make(whole_plan) ## target older ## target recent: trigger &quot;always&quot; ## target averages_older ## target plot_older ## target averages_recent ## target plot_recent ## target file &quot;report.md&quot; ## Used non-default triggers. Some targets may not be up to date. readd(averages_recent) ## # A tibble: 3 x 2 ## package mean_downloads ## &lt;chr&gt; &lt;dbl&gt; ## 1 ggplot2 15399. ## 2 knitr 9280. ## 3 Rcpp 20398. readd(averages_older) ## # A tibble: 3 x 2 ## package mean_downloads ## &lt;chr&gt; &lt;dbl&gt; ## 1 ggplot2 14641. ## 2 knitr 9069. ## 3 Rcpp 14408. readd(plot_recent) readd(plot_older) Because we used triggers, each make() rebuilds the recent target to get the latest download numbers for today. If the newly-downloaded data are the same as last time and nothing else changes, drake skips all the other targets. make(whole_plan) ## target recent: trigger &quot;always&quot; ## target averages_older ## target plot_older ## target averages_recent ## target plot_recent ## target file &quot;report.md&quot; ## Used non-default triggers. Some targets may not be up to date. To visualize the build behavior, plot the dependency network. Target recent and everything depending on it is always out of date because of the &quot;always&quot; trigger. If you rerun the project tomorrow, the recent dataset will have shifted one day forward, so make() will refresh averages_recent, plot_recent, and report.md. Targets averages_older and plot_older should be unaffected, so drake will skip them. config &lt;- drake_config(whole_plan) vis_drake_graph(config) 4.4 What remote data sources in general? When you rely on data from the internet, you should trigger a new download when the data change remotely. The best practices guide explains how to automatically refresh the data when the online timestamp changes. "],
["example-gsp.html", "Chapter 5 Example: gross state products 5.1 Get the code. 5.2 Objective and methods 5.3 Data 5.4 Analysis 5.5 Results 5.6 Comparison with GNU Make 5.7 References", " Chapter 5 Example: gross state products The following data analysis workflow shows off drake’s ability to generate lots of reproducibly-tracked tasks with ease. The same technique would be cumbersome, even intractable, with GNU Make. 5.1 Get the code. Write the code files to your workspace. drake_example(&quot;gsp&quot;) The new gsp folder now includes a file structure of a serious drake project, plus an interactive-tutorial.R to narrate the example. The code is also online here. 5.2 Objective and methods The goal is to search for factors closely associated with the productivity of states in the USA around the 1970s and 1980s. For the sake of simplicity, we use gross state product as a metric of productivity, and we restrict ourselves to multiple linear regression models with three variables. For each of the 84 possible models, we fit the data and then evaluate the root mean squared prediction error (RMSPE). \\[ \\begin{aligned} \\text{RMSPE} = \\sqrt{(\\text{y} - \\widehat{y})^T(y - \\widehat{y})} \\end{aligned} \\] Here, \\(y\\) is the vector of observed gross state products in the data, and \\(\\widehat{y}\\) is the vector of predicted gross state products under one of the models. We take the best variables to be the triplet in the model with the lowest RMSPE. 5.3 Data The Produc dataset from the Ecdat package contains data on the Gross State Product from 1970 to 1986. Each row is a single observation on a single state for a single year. The dataset has the following variables as columns. See the references later in this report for more details. gsp: gross state product. state: the state. year: the year. pcap: private capital stock. hwy: highway and streets. water: water and sewer facilities. util: other public buildings and structures. pc: public capital. emp: labor input measured by the employment in non-agricultural payrolls. unemp: state unemployment rate. library(Ecdat) data(Produc) head(Produc) ## state year pcap hwy water util pc gsp emp ## 1 ALABAMA 1970 15032.67 7325.80 1655.68 6051.20 35793.80 28418 1010.5 ## 2 ALABAMA 1971 15501.94 7525.94 1721.02 6254.98 37299.91 29375 1021.9 ## 3 ALABAMA 1972 15972.41 7765.42 1764.75 6442.23 38670.30 31303 1072.3 ## 4 ALABAMA 1973 16406.26 7907.66 1742.41 6756.19 40084.01 33430 1135.5 ## 5 ALABAMA 1974 16762.67 8025.52 1734.85 7002.29 42057.31 33749 1169.8 ## 6 ALABAMA 1975 17316.26 8158.23 1752.27 7405.76 43971.71 33604 1155.4 ## unemp ## 1 4.7 ## 2 5.2 ## 3 4.7 ## 4 3.9 ## 5 5.5 ## 6 7.7 5.4 Analysis First, we load the required packages. Drake is aware of all the packages you load with library() or require(). library(drake) library(Ecdat) # econometrics datasets library(knitr) library(ggplot2) Next, set up our workflow plan data frame in stages. We start with the models. Each model has 3 predictors, and we try all 84 possible models. predictors &lt;- setdiff(colnames(Produc), &quot;gsp&quot;) combos &lt;- t(combn(predictors, 3)) head(combos) ## [,1] [,2] [,3] ## [1,] &quot;state&quot; &quot;year&quot; &quot;pcap&quot; ## [2,] &quot;state&quot; &quot;year&quot; &quot;hwy&quot; ## [3,] &quot;state&quot; &quot;year&quot; &quot;water&quot; ## [4,] &quot;state&quot; &quot;year&quot; &quot;util&quot; ## [5,] &quot;state&quot; &quot;year&quot; &quot;pc&quot; ## [6,] &quot;state&quot; &quot;year&quot; &quot;emp&quot; targets &lt;- apply(combos, 1, paste, collapse = &quot;_&quot;) commands &lt;- apply(combos, 1, function(row){ covariates &lt;- paste(row, collapse = &quot; + &quot;) formula &lt;- paste0(&quot;as.formula(\\&quot;gsp ~ &quot;, covariates, &quot;\\&quot;)&quot;) command &lt;- paste0(&quot;lm(&quot;, formula, &quot;, data = Produc)&quot;) }) model_plan &lt;- data.frame(target = targets, command = commands) head(model_plan) ## target ## 1 state_year_pcap ## 2 state_year_hwy ## 3 state_year_water ## 4 state_year_util ## 5 state_year_pc ## 6 state_year_emp ## command ## 1 lm(as.formula(&quot;gsp ~ state + year + pcap&quot;), data = Produc) ## 2 lm(as.formula(&quot;gsp ~ state + year + hwy&quot;), data = Produc) ## 3 lm(as.formula(&quot;gsp ~ state + year + water&quot;), data = Produc) ## 4 lm(as.formula(&quot;gsp ~ state + year + util&quot;), data = Produc) ## 5 lm(as.formula(&quot;gsp ~ state + year + pc&quot;), data = Produc) ## 6 lm(as.formula(&quot;gsp ~ state + year + emp&quot;), data = Produc) Next, we make a plan to judge each model based on its root mean squared prediction error (RMSPE). commands &lt;- paste0(&quot;get_rmspe(&quot;, targets, &quot;, data = Produc)&quot;) targets &lt;- paste0(&quot;rmspe_&quot;, targets) rmspe_plan &lt;- data.frame(target = targets, command = commands) head(rmspe_plan) ## target command ## 1 rmspe_state_year_pcap get_rmspe(state_year_pcap, data = Produc) ## 2 rmspe_state_year_hwy get_rmspe(state_year_hwy, data = Produc) ## 3 rmspe_state_year_water get_rmspe(state_year_water, data = Produc) ## 4 rmspe_state_year_util get_rmspe(state_year_util, data = Produc) ## 5 rmspe_state_year_pc get_rmspe(state_year_pc, data = Produc) ## 6 rmspe_state_year_emp get_rmspe(state_year_emp, data = Produc) We need to define a function to get the RMSPE for each model. get_rmspe &lt;- function(lm_fit, data){ y &lt;- data$gsp yhat &lt;- predict(lm_fit, data = data) terms &lt;- attr(summary(lm_fit)$terms, &quot;term.labels&quot;) data.frame( rmspe = sqrt(mean((y - yhat)^2)), # nolint X1 = terms[1], X2 = terms[2], X3 = terms[3] ) } In our current plan, RMSPE is distributed over 84 targets (one for each model). Let’s plan to combine them all together in a single data frame. rmspe_results_plan &lt;- gather_plan( plan = rmspe_plan, target = &quot;rmspe&quot;, gather = &quot;rbind&quot; ) At the end, let’s generate a pdf plot of the RMSPE scores and a knitr report. output_plan &lt;- drake_plan( ggsave( filename = file_out(&quot;rmspe.pdf&quot;), plot = plot_rmspe(rmspe) ), knit(knitr_in(&quot;report.Rmd&quot;), file_out(&quot;report.md&quot;), quiet = TRUE) ) ## Warning: knitr/rmarkdown report &#39;report.Rmd&#39; does not exist and cannot be ## inspected for dependencies. head(output_plan) ## # A tibble: 2 x 2 ## target command ## &lt;chr&gt; &lt;chr&gt; ## 1 &quot;\\&quot;rmspe.pdf\\&quot;&quot; &quot;ggsave(filename = file_out(\\&quot;rmspe.pdf\\&quot;), plot = plot… ## 2 &quot;\\&quot;report.md\\&quot;&quot; &quot;knit(knitr_in(\\&quot;report.Rmd\\&quot;), file_out(\\&quot;report.md\\&quot;)… We see warnings above because our R Markdown report report.Rmd does not exist yet. You can find it here, and the code below generates it. local &lt;- file.path(&quot;examples&quot;, &quot;gsp&quot;, &quot;report.Rmd&quot;) path &lt;- system.file(path = local, package = &quot;drake&quot;, mustWork = TRUE) file.copy(from = path, to = &quot;report.Rmd&quot;, overwrite = TRUE) ## [1] TRUE At this point, we can gather together the whole workflow plan. whole_plan &lt;- rbind(model_plan, rmspe_plan, rmspe_results_plan, output_plan) Before we run the project, we need to define the plot_rmspe() function. plot_rmspe &lt;- function(rmspe){ ggplot(rmspe) + geom_histogram(aes(x = rmspe), bins = 30) } Now, we can run the project make(whole_plan, verbose = FALSE) ## Saving 6 x 6 in image 5.5 Results Here are the root mean squared prediction errors of all the models. results &lt;- readd(rmspe) loadd(plot_rmspe) library(ggplot2) plot_rmspe(rmspe = results) And here are the best models. The best variables are in the top row under X1, X2, and X3. head(results[order(results$rmspe, decreasing = FALSE), ]) ## rmspe X1 X2 X3 ## rmspe_state_hwy_emp 2613.669 state hwy emp ## rmspe_state_water_emp 2664.842 state water emp ## rmspe_state_util_emp 2665.744 state util emp ## rmspe_state_pc_emp 2666.058 state pc emp ## rmspe_state_pcap_emp 2675.336 state pcap emp ## rmspe_state_emp_unemp 2692.687 state emp unemp 5.6 Comparison with GNU Make If we were using Make instead of drake with the same set of targets, the analogous Makefile would look something like this pseudo-code sketch. models = model_state_year_pcap.rds model_state_year_hwy.rds ... # 84 of these model_% Rscript -e 'saveRDS(lm(...), ...)' rmspe_%: model_% Rscript -e 'saveRDS(get_rmspe(...), ...)' rmspe.rds: rmspe_% Rscript -e 'saveRDS(rbind(...), ...)' rmspe.pdf: rmspe.rds Rscript -e 'ggplot2::ggsave(plot_rmspe(readRDS(\"rmspe.rds\")), \"rmspe.pdf\")' report.md: report.Rmd Rscript -e 'knitr::knit(\"report.Rmd\")' There are three main disadvantages to this approach. Every target requires a new call to Rscript, which means that more time is spent initializing R sessions than doing the actual work. The user must micromanage nearly one hundred output files (in this case, *.rds files), which is cumbersome, messy, and inconvenient. Drake, on the other hand, automatically manages storage using a storr cache. The user needs to write the names of the 84 models near the top of the Makefile, which is less convenient than maintaining a data frame in R. 5.7 References Baltagi, Badi H (2003). Econometric analysis of panel data, John Wiley and sons, http://www.wiley.com/legacy/wileychi/baltagi/. Baltagi, B. H. and N. Pinnoi (1995). “Public capital stock and state productivity growth: further evidence”, Empirical Economics, 20, 351-359. Munnell, A. (1990). “Why has productivity growth declined? Productivity and public investment”&quot;, New England Economic Review, 3-22. Yves Croissant (2016). Ecdat: Data Sets for Econometrics. R package version 0.3-1. https://CRAN.R-project.org/package=Ecdat. "],
["mtcars.html", "Chapter 6 The mtcars example and workflow plan generation 6.1 Get the code. 6.2 Quick examples 6.3 The motivation of the mtcars example 6.4 Set up the mtcars example 6.5 The workflow plan data frame 6.6 Generate the workflow plan 6.7 Flexible workflow plan generation 6.8 Run the workflow 6.9 Automatic watching for changed dependencies 6.10 A note on tidy evaluation 6.11 Need more speed?", " Chapter 6 The mtcars example and workflow plan generation This chapter is a walkthrough of drake’s main functionality based on the mtcars example. It sets up the project and runs it repeatedly to demonstrate drake’s most important functionality. 6.1 Get the code. Write the code files to your workspace. drake_example(&quot;mtcars&quot;) The new mtcars folder now includes a file structure of a serious drake project, plus an interactive-tutorial.R to narrate the example. The code is also online here. 6.2 Quick examples Inspect and run your project. library(drake) load_mtcars_example() # Get the code with drake_example(&quot;mtcars&quot;). config &lt;- drake_config(my_plan) # Master configuration list vis_drake_graph(config) # Hover, click, drag, zoom, pan. make(my_plan) # Run the workflow. outdated(config) # Everything is up to date. Debug errors. failed() # Targets that failed in the most recent `make()` context &lt;- diagnose(large) # Diagnostic metadata: errors, warnings, etc. error &lt;- context$error str(error) # Object of class &quot;error&quot; error$message error$call error$calls # Full traceback of nested calls leading up to the error. # nolint Dive deeper into the built-in examples. drake_example(&quot;mtcars&quot;) # Write the code files. drake_examples() # List the other examples. 6.3 The motivation of the mtcars example Is there an association between the weight and the fuel efficiency of cars? To find out, we use the mtcars dataset from the datasets package. The mtcars dataset originally came from the 1974 Motor Trend US magazine, and it contains design and performance data on 32 models of automobile. ## ?mtcars # more info head(mtcars) ## mpg cyl disp hp drat wt qsec vs am gear carb ## Mazda RX4 21.0 6 160 110 3.90 2.620 16.46 0 1 4 4 ## Mazda RX4 Wag 21.0 6 160 110 3.90 2.875 17.02 0 1 4 4 ## Datsun 710 22.8 4 108 93 3.85 2.320 18.61 1 1 4 1 ## Hornet 4 Drive 21.4 6 258 110 3.08 3.215 19.44 1 0 3 1 ## Hornet Sportabout 18.7 8 360 175 3.15 3.440 17.02 0 0 3 2 ## Valiant 18.1 6 225 105 2.76 3.460 20.22 1 0 3 1 Here, wt is weight in tons, and mpg is fuel efficiency in miles per gallon. We want to figure out if there is an association between wt and mpg. The mtcars dataset itself only has 32 rows, so we generate two larger bootstrapped datasets and then analyze them with regression models. We summarize the regression models to see if there is an association. 6.4 Set up the mtcars example Before you run your project, you need to set up the workspace. In other words, you need to gather the “imports”: functions, pre-loaded data objects, and saved files that you want to be available before the real work begins. library(knitr) # Drake knows which packages you load. library(drake) We need a function to bootstrap larger datasets from mtcars. ## Pick a random subset of n rows from a dataset random_rows &lt;- function(data, n){ data[sample.int(n = nrow(data), size = n, replace = TRUE), ] } ## Bootstrapped datasets from mtcars. simulate &lt;- function(n){ # Pick a random set of cars to bootstrap from the mtcars data. data &lt;- random_rows(data = mtcars, n = n) # x is the car&#39;s weight, and y is the fuel efficiency. data.frame( x = data$wt, y = data$mpg ) } We also need functions to apply the regression models we need for detecting associations. ## Is fuel efficiency linearly related to weight? reg1 &lt;- function(d){ lm(y ~ + x, data = d) } ## Is fuel efficiency related to the SQUARE of the weight? reg2 &lt;- function(d){ d$x2 &lt;- d$x ^ 2 lm(y ~ x2, data = d) } We want to summarize the final results in an R Markdown report, so we need the following report.Rmd source file. path &lt;- file.path(&quot;examples&quot;, &quot;mtcars&quot;, &quot;report.Rmd&quot;) report_file &lt;- system.file(path, package = &quot;drake&quot;, mustWork = TRUE) file.copy(from = report_file, to = getwd(), overwrite = TRUE) ## [1] TRUE Here are the contents of the report. It will serve as a final summary of our work, and we will process it at the very end. Admittedly, some of the text spoils the punch line. cat(readLines(&quot;report.Rmd&quot;), sep = &quot;\\n&quot;) ## --- ## title: &quot;Final results report for the mtcars example&quot; ## author: You ## output: html_document ## --- ## ## # The weight and fuel efficiency of cars ## ## Is there an association between the weight and the fuel efficiency of cars? To find out, we use the `mtcars` dataset from the `datasets` package. The `mtcars` data originally came from the 1974 Motor Trend US magazine, and it contains design and performance data on 32 models of automobile. ## ## ```{r showmtcars} ## # ?mtcars # more info ## head(mtcars) ## ``` ## ## Here, `wt` is weight in tons, and `mpg` is fuel efficiency in miles per gallon. We want to figure out if there is an association between `wt` and `mpg`. The `mtcars` dataset itself only has 32 rows, so we generated two larger bootstrapped datasets. We called them `small` and `large`. ## ## ```{r example_chunk} ## library(drake) ## head(readd(small)) # 48 rows ## loadd(large) # 64 rows ## head(large) ## ``` ## ## Then, we fit a couple regression models to the `small` and `large` to try to detect an association between `wt` and `mpg`. Here are the coefficients and p-values from one of the model fits. ## ## ```{r second_example_chunk} ## readd(coef_regression2_small) ## ``` ## ## Since the p-value on `x2` is so small, there may be an association between weight and fuel efficiency after all. ## ## # A note on knitr reports in drake projects. ## ## Because of the calls to `readd()` and `loadd()`, `drake` knows that `small`, `large`, and `coef_regression2_small` are dependencies of this R Markdown report. This dependency relationship is what causes the report to be processed at the very end. Now, all our imports are set up. When the real work begins, drake will import functions and data objects from your R session environment ls() ## [1] &quot;check_credit_hours&quot; &quot;check_graduations&quot; &quot;check_public_funding&quot; ## [4] &quot;check_students&quot; &quot;combos&quot; &quot;commands&quot; ## [7] &quot;config&quot; &quot;create_plot&quot; &quot;dat&quot; ## [10] &quot;data_plan&quot; &quot;get_rmspe&quot; &quot;get_school_data&quot; ## [13] &quot;hard_plan&quot; &quot;hist&quot; &quot;local&quot; ## [16] &quot;make_my_plot&quot; &quot;make_my_table&quot; &quot;methods&quot; ## [19] &quot;model_plan&quot; &quot;my_analyses&quot; &quot;my_datasets&quot; ## [22] &quot;my_plan&quot; &quot;output_plan&quot; &quot;output_types&quot; ## [25] &quot;package_list&quot; &quot;path&quot; &quot;plan&quot; ## [28] &quot;plan_template&quot; &quot;plot_rmspe&quot; &quot;predictors&quot; ## [31] &quot;Produc&quot; &quot;random_rows&quot; &quot;reg1&quot; ## [34] &quot;reg2&quot; &quot;report_file&quot; &quot;report_plan&quot; ## [37] &quot;reportfile&quot; &quot;results&quot; &quot;rmd&quot; ## [40] &quot;rmspe_plan&quot; &quot;rmspe_results_plan&quot; &quot;simulate&quot; ## [43] &quot;summary_types&quot; &quot;targets&quot; &quot;tmp&quot; ## [46] &quot;whole_plan&quot; and saved files from your file system. list.files() ## [1] &quot;_book&quot; &quot;_bookdown.yml&quot; ## [3] &quot;02-example-main.Rmd&quot; &quot;03-plans.Rmd&quot; ## [5] &quot;04-example-packages.Rmd&quot; &quot;05-example-gsp.Rmd&quot; ## [7] &quot;06-example-mtcars.Rmd&quot; &quot;07-best-practices.Rmd&quot; ## [9] &quot;08-vis.Rmd&quot; &quot;09-debug.Rmd&quot; ## [11] &quot;10-hpc.Rmd&quot; &quot;11-time.Rmd&quot; ## [13] &quot;12-store.Rmd&quot; &quot;13-caution.Rmd&quot; ## [15] &quot;14-faq.Rmd&quot; &quot;build.R&quot; ## [17] &quot;deploy.sh&quot; &quot;DESCRIPTION&quot; ## [19] &quot;drake-manual_files&quot; &quot;drake-manual.Rmd&quot; ## [21] &quot;drake-manual.Rproj&quot; &quot;faq-stub.md&quot; ## [23] &quot;faq.R&quot; &quot;images&quot; ## [25] &quot;index.Rmd&quot; &quot;LICENSE&quot; ## [27] &quot;README.md&quot; &quot;report.Rmd&quot; 6.5 The workflow plan data frame Now that your workspace of imports is prepared, we can outline the real work step by step in a workflow plan data frame. load_mtcars_example() # Get the code with drake_example(&quot;mtcars&quot;). my_plan ## # A tibble: 15 x 2 ## target command ## &lt;chr&gt; &lt;chr&gt; ## 1 &quot;&quot; &quot;knit(knitr_in(\\&quot;report.Rmd\\&quot;), file_out(\\&quot;repo… ## 2 small simulate(48) ## 3 large simulate(64) ## 4 regression1_small reg1(small) ## 5 regression1_large reg1(large) ## 6 regression2_small reg2(small) ## 7 regression2_large reg2(large) ## 8 summ_regression1_small suppressWarnings(summary(regression1_small$resi… ## 9 summ_regression1_large suppressWarnings(summary(regression1_large$resi… ## 10 summ_regression2_small suppressWarnings(summary(regression2_small$resi… ## 11 summ_regression2_large suppressWarnings(summary(regression2_large$resi… ## 12 coef_regression1_small suppressWarnings(summary(regression1_small))$co… ## 13 coef_regression1_large suppressWarnings(summary(regression1_large))$co… ## 14 coef_regression2_small suppressWarnings(summary(regression2_small))$co… ## 15 coef_regression2_large suppressWarnings(summary(regression2_large))$co… Each row is an intermediate step, and each command generates a single target. A target is an output R object (cached when generated) or an output file (specified with single quotes), and a command just an ordinary piece of R code (not necessarily a single function call). Commands make use of R objects imported from your workspace, targets generated by other commands, and initial input files. These dependencies give your project an underlying network representation. ## Hover, click, drag, zoom, and pan. config &lt;- drake_config(my_plan) vis_drake_graph(config, width = &quot;100%&quot;, height = &quot;500px&quot;) # Also drake_graph() You can also check the dependencies of individual targets and imported functions. deps_code(reg2) ## [1] &quot;lm&quot; deps_code(my_plan$command[1]) # Files like report.Rmd are single-quoted. ## [1] &quot;\\&quot;report.md\\&quot;&quot; &quot;\\&quot;report.Rmd\\&quot;&quot; ## [3] &quot;coef_regression2_small&quot; &quot;knit&quot; ## [5] &quot;large&quot; &quot;small&quot; deps_code(my_plan$command[nrow(my_plan)]) ## [1] &quot;regression2_large&quot; &quot;summary&quot; &quot;suppressWarnings&quot; List all the reproducibly-tracked objects and files. tracked(config) ## [1] &quot;\\&quot;report.md\\&quot;&quot; &quot;\\&quot;report.Rmd\\&quot;&quot; ## [3] &quot;coef_regression1_large&quot; &quot;coef_regression1_small&quot; ## [5] &quot;coef_regression2_large&quot; &quot;coef_regression2_small&quot; ## [7] &quot;data.frame&quot; &quot;knit&quot; ## [9] &quot;large&quot; &quot;lm&quot; ## [11] &quot;mtcars&quot; &quot;nrow&quot; ## [13] &quot;random_rows&quot; &quot;reg1&quot; ## [15] &quot;reg2&quot; &quot;regression1_large&quot; ## [17] &quot;regression1_small&quot; &quot;regression2_large&quot; ## [19] &quot;regression2_small&quot; &quot;sample.int&quot; ## [21] &quot;simulate&quot; &quot;small&quot; ## [23] &quot;summ_regression1_large&quot; &quot;summ_regression1_small&quot; ## [25] &quot;summ_regression2_large&quot; &quot;summ_regression2_small&quot; ## [27] &quot;summary&quot; &quot;suppressWarnings&quot; Check for circular reasoning, missing input files, and other pitfalls. check_plan(my_plan) 6.6 Generate the workflow plan The workflow plan data frame my_plan would be a pain to write by hand, so drake has functions to help you. Here are the commands to generate the bootstrapped datasets. my_datasets &lt;- drake_plan( small = simulate(48), large = simulate(64)) my_datasets ## # A tibble: 2 x 2 ## target command ## * &lt;chr&gt; &lt;chr&gt; ## 1 small simulate(48) ## 2 large simulate(64) For multiple replicates: expand_plan(my_datasets, values = c(&quot;rep1&quot;, &quot;rep2&quot;)) ## # A tibble: 4 x 2 ## target command ## * &lt;chr&gt; &lt;chr&gt; ## 1 small_rep1 simulate(48) ## 2 small_rep2 simulate(48) ## 3 large_rep1 simulate(64) ## 4 large_rep2 simulate(64) Here is a template for applying our regression models to our bootstrapped datasets. methods &lt;- drake_plan( regression1 = reg1(dataset__), regression2 = reg2(dataset__)) methods ## # A tibble: 2 x 2 ## target command ## * &lt;chr&gt; &lt;chr&gt; ## 1 regression1 reg1(dataset__) ## 2 regression2 reg2(dataset__) We evaluate the dataset__ wildcard to generate all the regression commands we need. my_analyses &lt;- plan_analyses(methods, data = my_datasets) my_analyses ## # A tibble: 4 x 2 ## target command ## * &lt;chr&gt; &lt;chr&gt; ## 1 regression1_small reg1(small) ## 2 regression1_large reg1(large) ## 3 regression2_small reg2(small) ## 4 regression2_large reg2(large) Next, we summarize each analysis of each dataset. We calculate descriptive statistics on the residuals, and we collect the regression coefficients and their p-values. summary_types &lt;- drake_plan( summ = suppressWarnings(summary(analysis__$residuals)), coef = suppressWarnings(summary(analysis__))$coefficients ) summary_types ## # A tibble: 2 x 2 ## target command ## * &lt;chr&gt; &lt;chr&gt; ## 1 summ suppressWarnings(summary(analysis__$residuals)) ## 2 coef suppressWarnings(summary(analysis__))$coefficients results &lt;- plan_summaries(summary_types, analyses = my_analyses, datasets = my_datasets, gather = NULL) results ## # A tibble: 8 x 2 ## target command ## &lt;chr&gt; &lt;chr&gt; ## 1 summ_regression1_small suppressWarnings(summary(regression1_small$resid… ## 2 summ_regression1_large suppressWarnings(summary(regression1_large$resid… ## 3 summ_regression2_small suppressWarnings(summary(regression2_small$resid… ## 4 summ_regression2_large suppressWarnings(summary(regression2_large$resid… ## 5 coef_regression1_small suppressWarnings(summary(regression1_small))$coe… ## 6 coef_regression1_large suppressWarnings(summary(regression1_large))$coe… ## 7 coef_regression2_small suppressWarnings(summary(regression2_small))$coe… ## 8 coef_regression2_large suppressWarnings(summary(regression2_large))$coe… The gather feature reduces a collection of targets to a single target. The resulting commands are long, so gathering is deactivated for the sake of readability. For your knitr reports, use knitr_in() in your commands so that report.Rmd is a dependency and targets loaded with loadd() and readd() in active code chunks are also dependencies. Use file_out() to tell drake that the target is a file output. If the file is an output, you do not need to name the target. The target name will be the name of the output file in quotes. report &lt;- drake_plan( knit(knitr_in(&quot;report.Rmd&quot;), file_out(&quot;report.md&quot;), quiet = TRUE) ) report ## # A tibble: 1 x 2 ## target command ## * &lt;chr&gt; &lt;chr&gt; ## 1 &quot;\\&quot;report.md\\&quot;&quot; &quot;knit(knitr_in(\\&quot;report.Rmd\\&quot;), file_out(\\&quot;report.md\\&quot;)… Finally, consolidate your workflow using rbind(). Row order does not matter. my_plan &lt;- rbind(report, my_datasets, my_analyses, results) my_plan ## # A tibble: 15 x 2 ## target command ## &lt;chr&gt; &lt;chr&gt; ## 1 &quot;\\&quot;report.md\\&quot;&quot; &quot;knit(knitr_in(\\&quot;report.Rmd\\&quot;), file_out(\\&quot;repo… ## 2 small simulate(48) ## 3 large simulate(64) ## 4 regression1_small reg1(small) ## 5 regression1_large reg1(large) ## 6 regression2_small reg2(small) ## 7 regression2_large reg2(large) ## 8 summ_regression1_small suppressWarnings(summary(regression1_small$resi… ## 9 summ_regression1_large suppressWarnings(summary(regression1_large$resi… ## 10 summ_regression2_small suppressWarnings(summary(regression2_small$resi… ## 11 summ_regression2_large suppressWarnings(summary(regression2_large$resi… ## 12 coef_regression1_small suppressWarnings(summary(regression1_small))$co… ## 13 coef_regression1_large suppressWarnings(summary(regression1_large))$co… ## 14 coef_regression2_small suppressWarnings(summary(regression2_small))$co… ## 15 coef_regression2_large suppressWarnings(summary(regression2_large))$co… 6.7 Flexible workflow plan generation If your workflow does not fit the rigid datasets/analyses/summaries framework, consider using functions expand_plan(), evaluate_plan(), gather_plan(), and reduce_plan(). df &lt;- drake_plan(data = simulate(center = MU, scale = SIGMA)) df ## # A tibble: 1 x 2 ## target command ## * &lt;chr&gt; &lt;chr&gt; ## 1 data simulate(center = MU, scale = SIGMA) df &lt;- expand_plan(df, values = c(&quot;rep1&quot;, &quot;rep2&quot;)) df ## # A tibble: 2 x 2 ## target command ## * &lt;chr&gt; &lt;chr&gt; ## 1 data_rep1 simulate(center = MU, scale = SIGMA) ## 2 data_rep2 simulate(center = MU, scale = SIGMA) evaluate_plan(df, wildcard = &quot;MU&quot;, values = 1:2) ## # A tibble: 4 x 2 ## target command ## * &lt;chr&gt; &lt;chr&gt; ## 1 data_rep1_1 simulate(center = 1, scale = SIGMA) ## 2 data_rep1_2 simulate(center = 2, scale = SIGMA) ## 3 data_rep2_1 simulate(center = 1, scale = SIGMA) ## 4 data_rep2_2 simulate(center = 2, scale = SIGMA) evaluate_plan(df, wildcard = &quot;MU&quot;, values = 1:2, expand = FALSE) ## # A tibble: 2 x 2 ## target command ## * &lt;chr&gt; &lt;chr&gt; ## 1 data_rep1 simulate(center = 1, scale = SIGMA) ## 2 data_rep2 simulate(center = 2, scale = SIGMA) evaluate_plan(df, rules = list(MU = 1:2, SIGMA = c(0.1, 1)), expand = FALSE) ## # A tibble: 2 x 2 ## target command ## * &lt;chr&gt; &lt;chr&gt; ## 1 data_rep1 simulate(center = 1, scale = 0.1) ## 2 data_rep2 simulate(center = 2, scale = 1) evaluate_plan(df, rules = list(MU = 1:2, SIGMA = c(0.1, 1, 10))) ## # A tibble: 12 x 2 ## target command ## * &lt;chr&gt; &lt;chr&gt; ## 1 data_rep1_1_0.1 simulate(center = 1, scale = 0.1) ## 2 data_rep1_1_1 simulate(center = 1, scale = 1) ## 3 data_rep1_1_10 simulate(center = 1, scale = 10) ## 4 data_rep1_2_0.1 simulate(center = 2, scale = 0.1) ## 5 data_rep1_2_1 simulate(center = 2, scale = 1) ## 6 data_rep1_2_10 simulate(center = 2, scale = 10) ## 7 data_rep2_1_0.1 simulate(center = 1, scale = 0.1) ## 8 data_rep2_1_1 simulate(center = 1, scale = 1) ## 9 data_rep2_1_10 simulate(center = 1, scale = 10) ## 10 data_rep2_2_0.1 simulate(center = 2, scale = 0.1) ## 11 data_rep2_2_1 simulate(center = 2, scale = 1) ## 12 data_rep2_2_10 simulate(center = 2, scale = 10) gather_plan(df) ## # A tibble: 1 x 2 ## target command ## &lt;chr&gt; &lt;chr&gt; ## 1 target list(data_rep1 = data_rep1, data_rep2 = data_rep2) gather_plan(df, target = &quot;my_summaries&quot;, gather = &quot;rbind&quot;) ## # A tibble: 1 x 2 ## target command ## &lt;chr&gt; &lt;chr&gt; ## 1 my_summaries rbind(data_rep1 = data_rep1, data_rep2 = data_rep2) x_plan &lt;- evaluate_plan( drake_plan(x = VALUE), wildcard = &quot;VALUE&quot;, values = 1:8 ) x_plan ## # A tibble: 8 x 2 ## target command ## * &lt;chr&gt; &lt;chr&gt; ## 1 x_1 1 ## 2 x_2 2 ## 3 x_3 3 ## 4 x_4 4 ## 5 x_5 5 ## 6 x_6 6 ## 7 x_7 7 ## 8 x_8 8 x_plan ## # A tibble: 8 x 2 ## target command ## * &lt;chr&gt; &lt;chr&gt; ## 1 x_1 1 ## 2 x_2 2 ## 3 x_3 3 ## 4 x_4 4 ## 5 x_5 5 ## 6 x_6 6 ## 7 x_7 7 ## 8 x_8 8 reduce_plan( x_plan, target = &quot;x_sum&quot;, pairwise = TRUE, begin = &quot;fun(&quot;, op = &quot;, &quot;, end = &quot;)&quot; ) ## # A tibble: 7 x 2 ## target command ## &lt;chr&gt; &lt;chr&gt; ## 1 x_sum_1 fun(x_1, x_2) ## 2 x_sum_2 fun(x_3, x_4) ## 3 x_sum_3 fun(x_5, x_6) ## 4 x_sum_4 fun(x_7, x_8) ## 5 x_sum_5 fun(x_sum_1, x_sum_2) ## 6 x_sum_6 fun(x_sum_3, x_sum_4) ## 7 x_sum fun(x_sum_5, x_sum_6) 6.8 Run the workflow You may want to check for outdated or missing targets/imports first. config &lt;- drake_config(my_plan, verbose = FALSE) outdated(config) # Targets that need to be (re)built. ## [1] &quot;\\&quot;report.md\\&quot;&quot; &quot;coef_regression1_large&quot; ## [3] &quot;coef_regression1_small&quot; &quot;coef_regression2_large&quot; ## [5] &quot;coef_regression2_small&quot; &quot;large&quot; ## [7] &quot;regression1_large&quot; &quot;regression1_small&quot; ## [9] &quot;regression2_large&quot; &quot;regression2_small&quot; ## [11] &quot;small&quot; &quot;summ_regression1_large&quot; ## [13] &quot;summ_regression1_small&quot; &quot;summ_regression2_large&quot; ## [15] &quot;summ_regression2_small&quot; missed(config) # Checks your workspace. ## character(0) Then just make(my_plan). make(my_plan) ## target large ## target small ## target regression1_large ## target regression2_large ## target regression1_small ## target regression2_small ## target summ_regression1_large ## target coef_regression1_large ## target summ_regression2_large ## target coef_regression2_large ## target summ_regression1_small ## target coef_regression1_small ## target coef_regression2_small ## target summ_regression2_small ## target file &quot;report.md&quot; For the reg2() model on the small dataset, the p-value on x2 is so small that there may be an association between weight and fuel efficiency after all. readd(coef_regression2_small) ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 27.504915 1.02496426 26.835000 9.676340e-30 ## x2 -0.708536 0.08285938 -8.551066 4.617125e-11 The non-file dependencies of your last target are already loaded in your workspace. ls() ## [1] &quot;check_credit_hours&quot; &quot;check_graduations&quot; &quot;check_public_funding&quot; ## [4] &quot;check_students&quot; &quot;combos&quot; &quot;commands&quot; ## [7] &quot;config&quot; &quot;create_plot&quot; &quot;dat&quot; ## [10] &quot;data_plan&quot; &quot;df&quot; &quot;get_rmspe&quot; ## [13] &quot;get_school_data&quot; &quot;hard_plan&quot; &quot;hist&quot; ## [16] &quot;local&quot; &quot;make_my_plot&quot; &quot;make_my_table&quot; ## [19] &quot;methods&quot; &quot;model_plan&quot; &quot;my_analyses&quot; ## [22] &quot;my_datasets&quot; &quot;my_plan&quot; &quot;output_plan&quot; ## [25] &quot;output_types&quot; &quot;package_list&quot; &quot;path&quot; ## [28] &quot;plan&quot; &quot;plan_template&quot; &quot;plot_rmspe&quot; ## [31] &quot;predictors&quot; &quot;Produc&quot; &quot;random_rows&quot; ## [34] &quot;reg1&quot; &quot;reg2&quot; &quot;report&quot; ## [37] &quot;report_file&quot; &quot;report_plan&quot; &quot;reportfile&quot; ## [40] &quot;results&quot; &quot;rmd&quot; &quot;rmspe_plan&quot; ## [43] &quot;rmspe_results_plan&quot; &quot;simulate&quot; &quot;summary_types&quot; ## [46] &quot;targets&quot; &quot;tmp&quot; &quot;whole_plan&quot; ## [49] &quot;x_plan&quot; outdated(config) # Everything is up to date. ## character(0) build_times(digits = 4) # How long did it take to make each target? ## # A tibble: 28 x 5 ## item type elapsed user system ## * &lt;chr&gt; &lt;chr&gt; &lt;S4: Duration&gt; &lt;S4: Duration&gt; &lt;S4: Durat&gt; ## 1 &quot;\\&quot;report.md\\&quot;&quot; target 0.064s 0.064s 0s ## 2 &quot;\\&quot;report.Rmd\\&quot;&quot; import 0.001s 0s 0s ## 3 coef_regression1_large target 0.007s 0.008s 0s ## 4 coef_regression1_small target 0.007s 0s 0.004s ## 5 coef_regression2_large target 0.006s 0.008s 0s ## 6 coef_regression2_small target 0.007s 0.004s 0s ## 7 data.frame import 0.038s 0.032s 0.004s ## 8 knit import 0.027s 0.028s 0s ## 9 large target 0.007s 0.004s 0s ## 10 lm import 0.014s 0.012s 0s ## # ... with 18 more rows See also predict_runtime() and rate_limiting_times(). In the new graph, the black nodes from before are now green. ## Hover, click, drag, zoom, and explore. vis_drake_graph(config, width = &quot;100%&quot;, height = &quot;500px&quot;) Optionally, get visNetwork nodes and edges so you can make your own plot with visNetwork() or render_drake_graph(). drake_graph_info(config) Use readd() and loadd() to load targets into your workspace. (They are cached in the hidden .drake/ folder using storr). There are many more functions for interacting with the cache. readd(coef_regression2_large) ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 26.8613175 0.82963761 32.37717 1.485222e-40 ## x2 -0.6299583 0.05501956 -11.44972 6.167412e-17 loadd(small) head(small) ## x y ## 1 3.730 17.3 ## 2 5.250 10.4 ## 3 3.730 17.3 ## 4 5.345 14.7 ## 5 3.190 24.4 ## 6 3.440 17.8 rm(small) cached(small, large) ## small large ## TRUE TRUE cached() ## [1] &quot;\\&quot;report.md\\&quot;&quot; &quot;\\&quot;report.Rmd\\&quot;&quot; ## [3] &quot;coef_regression1_large&quot; &quot;coef_regression1_small&quot; ## [5] &quot;coef_regression2_large&quot; &quot;coef_regression2_small&quot; ## [7] &quot;data.frame&quot; &quot;knit&quot; ## [9] &quot;large&quot; &quot;lm&quot; ## [11] &quot;mtcars&quot; &quot;nrow&quot; ## [13] &quot;random_rows&quot; &quot;reg1&quot; ## [15] &quot;reg2&quot; &quot;regression1_large&quot; ## [17] &quot;regression1_small&quot; &quot;regression2_large&quot; ## [19] &quot;regression2_small&quot; &quot;sample.int&quot; ## [21] &quot;simulate&quot; &quot;small&quot; ## [23] &quot;summ_regression1_large&quot; &quot;summ_regression1_small&quot; ## [25] &quot;summ_regression2_large&quot; &quot;summ_regression2_small&quot; ## [27] &quot;summary&quot; &quot;suppressWarnings&quot; built() ## [1] &quot;\\&quot;report.md\\&quot;&quot; &quot;coef_regression1_large&quot; ## [3] &quot;coef_regression1_small&quot; &quot;coef_regression2_large&quot; ## [5] &quot;coef_regression2_small&quot; &quot;large&quot; ## [7] &quot;regression1_large&quot; &quot;regression1_small&quot; ## [9] &quot;regression2_large&quot; &quot;regression2_small&quot; ## [11] &quot;small&quot; &quot;summ_regression1_large&quot; ## [13] &quot;summ_regression1_small&quot; &quot;summ_regression2_large&quot; ## [15] &quot;summ_regression2_small&quot; imported() ## [1] &quot;\\&quot;report.Rmd\\&quot;&quot; &quot;data.frame&quot; &quot;knit&quot; ## [4] &quot;lm&quot; &quot;mtcars&quot; &quot;nrow&quot; ## [7] &quot;random_rows&quot; &quot;reg1&quot; &quot;reg2&quot; ## [10] &quot;sample.int&quot; &quot;simulate&quot; &quot;summary&quot; ## [13] &quot;suppressWarnings&quot; head(read_drake_plan()) ## # A tibble: 6 x 2 ## target command ## &lt;chr&gt; &lt;chr&gt; ## 1 &quot;\\&quot;report.md\\&quot;&quot; &quot;knit(knitr_in(\\&quot;report.Rmd\\&quot;), file_out(\\&quot;report.md\\… ## 2 small simulate(48) ## 3 large simulate(64) ## 4 regression1_small reg1(small) ## 5 regression1_large reg1(large) ## 6 regression2_small reg2(small) head(progress()) # See also in_progress() ## &quot;report.md&quot; &quot;report.Rmd&quot; coef_regression1_large ## &quot;finished&quot; &quot;finished&quot; &quot;finished&quot; ## coef_regression1_small coef_regression2_large coef_regression2_small ## &quot;finished&quot; &quot;finished&quot; &quot;finished&quot; progress(large) ## large ## &quot;finished&quot; ## drake_session() # sessionInfo() of the last make() # nolint The next time you run make(my_plan), nothing will build because drake knows everything is already up to date. config &lt;- make(my_plan) # Will use config later. See also drake_config(). ## All targets are already up to date. But if you change one of your functions, commands, or other dependencies, drake will update the affected targets. Suppose we change the quadratic term to a cubic term in reg2(). We might want to do this if we suspect a cubic relationship between tons and miles per gallon. reg2 &lt;- function(d) { d$x3 &lt;- d$x ^ 3 lm(y ~ x3, data = d) } The targets that depend on reg2() need to be rebuilt. outdated(config) ## [1] &quot;\\&quot;report.md\\&quot;&quot; &quot;coef_regression2_large&quot; ## [3] &quot;coef_regression2_small&quot; &quot;regression2_large&quot; ## [5] &quot;regression2_small&quot; &quot;summ_regression2_large&quot; ## [7] &quot;summ_regression2_small&quot; Advanced: To find out why a target is out of date, you can load the storr cache and compare the appropriate hash keys to the output of dependency_profile(). dependency_profile(target = &quot;regression2_small&quot;, config = config) ## $cached_command ## [1] &quot;{\\n reg2(small) \\n}&quot; ## ## $current_command ## [1] &quot;{\\n reg2(small) \\n}&quot; ## ## $cached_file_modification_time ## NULL ## ## $cached_dependency_hash ## [1] &quot;b5124bdceef8650183170ba11007bb7b52cb8e34d3f16da33d8e429406c8dcbd&quot; ## ## $current_dependency_hash ## [1] &quot;80a7eb5288828c2f5816caf84db9ebf97d423021e4682949705d682586218012&quot; ## ## $hashes_of_dependencies ## small reg2 ## &quot;7d836504e5060e6d&quot; &quot;d47109544c89ca7a&quot; config$cache$get_hash(key = &quot;small&quot;) # same ## [1] &quot;7d836504e5060e6d&quot; config$cache$get_hash(key = &quot;reg2&quot;) # different ## [1] &quot;2b279027900690e9&quot; ## Hover, click, drag, zoom, and explore. vis_drake_graph(config, width = &quot;100%&quot;, height = &quot;500px&quot;) The next make() will rebuild the targets depending on reg2() and leave everything else alone. make(my_plan) ## target regression2_large ## target regression2_small ## target summ_regression2_large ## target coef_regression2_large ## target coef_regression2_small ## target summ_regression2_small ## target file &quot;report.md&quot; Trivial changes to whitespace and comments are totally ignored. reg2 &lt;- function(d) { d$x3 &lt;- d$x ^ 3 lm(y ~ x3, data = d) # I indented here. } outdated(config) # Everything is up to date. ## character(0) Drake cares about nested functions too: nontrivial changes to random_rows() will propagate to simulate() and all the downstream targets. random_rows &lt;- function(data, n){ n &lt;- n + 1 data[sample.int(n = nrow(data), size = n, replace = TRUE), ] } outdated(config) ## [1] &quot;\\&quot;report.md\\&quot;&quot; &quot;coef_regression1_large&quot; ## [3] &quot;coef_regression1_small&quot; &quot;coef_regression2_large&quot; ## [5] &quot;coef_regression2_small&quot; &quot;large&quot; ## [7] &quot;regression1_large&quot; &quot;regression1_small&quot; ## [9] &quot;regression2_large&quot; &quot;regression2_small&quot; ## [11] &quot;small&quot; &quot;summ_regression1_large&quot; ## [13] &quot;summ_regression1_small&quot; &quot;summ_regression2_large&quot; ## [15] &quot;summ_regression2_small&quot; make(my_plan) ## target large ## target small ## target regression1_large ## target regression2_large ## target regression1_small ## target regression2_small ## target summ_regression1_large ## target coef_regression1_large ## target summ_regression2_large ## target coef_regression2_large ## target summ_regression1_small ## target coef_regression1_small ## target coef_regression2_small ## target summ_regression2_small ## target file &quot;report.md&quot; Need to add new work on the fly? Just append rows to the workflow plan. If the rest of your workflow is up to date, only the new work is run. new_simulation &lt;- function(n){ data.frame(x = rnorm(n), y = rnorm(n)) } additions &lt;- drake_plan( new_data = new_simulation(36) + sqrt(10)) additions ## # A tibble: 1 x 2 ## target command ## * &lt;chr&gt; &lt;chr&gt; ## 1 new_data new_simulation(36) + sqrt(10) my_plan &lt;- rbind(my_plan, additions) my_plan ## # A tibble: 16 x 2 ## target command ## &lt;chr&gt; &lt;chr&gt; ## 1 &quot;\\&quot;report.md\\&quot;&quot; &quot;knit(knitr_in(\\&quot;report.Rmd\\&quot;), file_out(\\&quot;repo… ## 2 small simulate(48) ## 3 large simulate(64) ## 4 regression1_small reg1(small) ## 5 regression1_large reg1(large) ## 6 regression2_small reg2(small) ## 7 regression2_large reg2(large) ## 8 summ_regression1_small suppressWarnings(summary(regression1_small$resi… ## 9 summ_regression1_large suppressWarnings(summary(regression1_large$resi… ## 10 summ_regression2_small suppressWarnings(summary(regression2_small$resi… ## 11 summ_regression2_large suppressWarnings(summary(regression2_large$resi… ## 12 coef_regression1_small suppressWarnings(summary(regression1_small))$co… ## 13 coef_regression1_large suppressWarnings(summary(regression1_large))$co… ## 14 coef_regression2_small suppressWarnings(summary(regression2_small))$co… ## 15 coef_regression2_large suppressWarnings(summary(regression2_large))$co… ## 16 new_data new_simulation(36) + sqrt(10) make(my_plan) ## target new_data If you ever need to erase your work, use clean(). The next make() will rebuild any cleaned targets, so be careful. You may notice that by default, the size of the cache does not go down very much. To purge old data, you could use clean(garbage_collection = TRUE, purge = TRUE). To do garbage collection without removing any important targets, use drake_gc(). ## Uncaches individual targets and imported objects. clean(small, reg1, verbose = FALSE) clean(verbose = FALSE) # Cleans all targets out of the cache. drake_gc(verbose = FALSE) # Just garbage collection. clean(destroy = TRUE, verbose = FALSE) # removes the cache entirely 6.9 Automatic watching for changed dependencies As you have seen with reg2(), drake reacts to changes in dependencies. In other words, make() notices when your dependencies are different from last time, rebuilds any affected targets, and continues downstream. In particular, drake watches for nontrivial changes to the following items as long as they are connected to your workflow. The output values of targets in your workflow plan. The commands themselves. External files, if their names are enclosed in single quotes in commands. R objects mentioned in the commands, including but not limited to user-defined functions and functions from packages. R objects (but not files) nested inside user-defined functions. For packages exposed with expose_imports(), R objects (but not files) nested inside package functions. Files declared with file_in() inside your commands or custom functions. knitr reports declared with knitr_in() in your commands, along with any targets explicitly loaded in active code chunks with loadd() or readd(). Do not use knitr_in() inside your imported functions. Files declared with file_out() in your commands. Do not use file_out() inside your imported functions. To enhance reproducibility beyond the scope of drake, you might consider packrat and a container tool (such as Singularity or Docker. Packrat creates a tightly-controlled local library of packages to extend the shelf life of your project. And with containerization, you can execute your project on a virtual machine to ensure platform independence. Together, packrat and containers can help others reproduce your work even if they have different software and hardware. 6.10 A note on tidy evaluation Running commands in your R console is not always exactly like running them with make(). That’s because make() uses tidy evaluation as implemented in the rlang package. ## This workflow plan uses rlang&#39;s quasiquotation operator `!!`. my_plan &lt;- drake_plan(list = c( little_b = &quot;\\&quot;b\\&quot;&quot;, letter = &quot;!!little_b&quot; )) my_plan ## # A tibble: 2 x 2 ## target command ## * &lt;chr&gt; &lt;chr&gt; ## 1 little_b &quot;\\&quot;b\\&quot;&quot; ## 2 letter !!little_b make(my_plan) ## target little_b ## target letter readd(letter) ## [1] &quot;b&quot; For the commands you specify the free-form ... argument, drake_plan() also supports tidy evaluation. For example, it supports quasiquotation with the !! argument. Use tidy_evaluation = FALSE or the list argument to suppress this behavior. my_variable &lt;- 5 drake_plan( a = !!my_variable, b = !!my_variable + 1, list = c(d = &quot;!!my_variable&quot;) ) ## # A tibble: 3 x 2 ## target command ## * &lt;chr&gt; &lt;chr&gt; ## 1 a 5 ## 2 b 5 + 1 ## 3 d !!my_variable drake_plan( a = !!my_variable, b = !!my_variable + 1, list = c(d = &quot;!!my_variable&quot;), tidy_evaluation = FALSE ) ## # A tibble: 3 x 2 ## target command ## * &lt;chr&gt; &lt;chr&gt; ## 1 a !!my_variable ## 2 b !!my_variable + 1 ## 3 d !!my_variable For instances of !! that remain in the workflow plan, make() will run these commands in tidy fashion, evaluating the !! operator using the environment you provided. 6.11 Need more speed? Drake has extensive high-performance computing support, from local multicore processing to serious distributed computing across multiple nodes of a cluster. See the high-performance computing chapter for detailed instructions. "],
["best-practices.html", "Chapter 7 General best practices for drake projects 7.1 How to organize your files 7.2 Remote data sources", " Chapter 7 General best practices for drake projects This chapter describes general best practices for creating, configuring, and running drake projects. It answers frequently asked questions and clears up common misconceptions, and it will continuously develop in response to community feedback. 7.1 How to organize your files 7.1.1 Examples For examples of how to structure your code files, see the beginner oriented example projects: mtcars gsp packages Write the code directly with the drake_example() function. drake_example(&quot;mtcars&quot;) drake_example(&quot;gsp&quot;) drake_example(&quot;packages&quot;) In practice, you do not need to organize your files the way the examples do, but it does happen to be a reasonable way of doing things. 7.1.2 Where do you put your code? It is best to write your code as a bunch of functions. You can save those functions in R scripts and then source() them before doing anything else. ## Load functions get_data(), analyze_data, and summarize_results() source(&quot;my_functions.R&quot;) Then, set up your workflow plan data frame. good_plan &lt;- drake_plan( my_data = get_data(file_in(&quot;data.csv&quot;)), # External files need to be in commands explicitly. # nolint my_analysis = analyze_data(my_data), my_summaries = summarize_results(my_data, my_analysis) ) good_plan ## # A tibble: 3 x 2 ## target command ## * &lt;chr&gt; &lt;chr&gt; ## 1 my_data &quot;get_data(file_in(\\&quot;data.csv\\&quot;))&quot; ## 2 my_analysis analyze_data(my_data) ## 3 my_summaries summarize_results(my_data, my_analysis) Drake knows that my_analysis depends on my_data because my_data is an argument to analyze_data(), which is part of the command for my_analysis. config &lt;- drake_config(good_plan) vis_drake_graph(config) Now, you can call make() to build the targets. make(good_plan) If your commands are really long, just put them in larger functions. Drake analyzes imported functions for non-file dependencies. 7.1.3 Remember: your commands are code chunks, not R scripts Some people are accustomed to dividing their work into R scripts and then calling source() to run each step of the analysis. For example you might have the following files. get_data.R analyze_data.R summarize_results.R If you migrate to drake, you may be tempted to set up a workflow plan like this. bad_plan &lt;- drake_plan( my_data = source(file_in(&quot;get_data.R&quot;)), my_analysis = source(file_in(&quot;analyze_data.R&quot;)), my_summaries = source(file_in(&quot;summarize_data.R&quot;)) ) bad_plan ## # A tibble: 3 x 2 ## target command ## * &lt;chr&gt; &lt;chr&gt; ## 1 my_data &quot;source(file_in(\\&quot;get_data.R\\&quot;))&quot; ## 2 my_analysis &quot;source(file_in(\\&quot;analyze_data.R\\&quot;))&quot; ## 3 my_summaries &quot;source(file_in(\\&quot;summarize_data.R\\&quot;))&quot; But now, the dependency structure of your work is broken. Your R script files are dependencies, but since my_data is not mentioned in a function or command, drake does not know that my_analysis depends on it. ## [[1]] ## [1] TRUE ## ## [[2]] ## [1] TRUE ## ## [[3]] ## [1] TRUE config &lt;- drake_config(bad_plan) vis_drake_graph(config) ## [[1]] ## [1] TRUE ## ## [[2]] ## [1] TRUE ## ## [[3]] ## [1] TRUE Dangers: In the first make(bad_plan, jobs = 2), drake will try to build my_data and my_analysis at the same time even though my_data must finish before my_analysis begins. Drake is oblivious to data.csv since it is not explicitly mentioned in a workflow plan command. So when data.csv changes, make(bad_plan) will not rebuild my_data. my_analysis will not update when my_data changes. The return value of source() is formatted counter-intuitively. If source(file_in(&quot;get_data.R&quot;)) is the command for my_data, then my_data will always be a list with elements &quot;value&quot; and &quot;visible&quot;. In other words, source(file_in(&quot;get_data.R&quot;))$value is really what you would want. In addition, this source()-based approach is simply inconvenient. Drake rebuilds my_data every time get_data.R changes, even when those changes are just extra comments or blank lines. On the other hand, in the previous plan that uses my_data = get_data(), drake does not trigger rebuilds when comments or whitespace in get_data() are modified. Drake is R-focused, not file-focused. If you embrace this viewpoint, your work will be easier. 7.1.4 File output targets In your plan, the file_out() function tells drake that your target is an external file rather than an ordinary R object. plan &lt;- drake_plan( writeLines(text = letters[1:6], con = file_out(&quot;file.txt&quot;)) ) plan ## # A tibble: 1 x 2 ## target command ## * &lt;chr&gt; &lt;chr&gt; ## 1 &quot;\\&quot;file.txt\\&quot;&quot; &quot;writeLines(text = letters[1:6], con = file_out(\\&quot;file.t… Now, make() knows to expect a file called file.txt. make(plan) ## target file &quot;file.txt&quot; And if you manually mangle file.txt by accident, make() restores it to its reproducible state. writeLines(text = &quot;123&quot;, con = file_out(&quot;file.txt&quot;)) make(plan) ## target file &quot;file.txt&quot; make(plan) ## All targets are already up to date. But just because your command produces files does not mean you need to track them. plan &lt;- drake_plan(real_output = long_job()) make(plan) list.files() ### [1] &quot;date-time.log&quot; &quot;error.log&quot; &quot;console.log&quot; These log files probably have nothing to do with the objectives of your research. If that is the case, you can safely ignore them with no loss of reproducibility. Generally speaking, drake was designed to be as R-focused as possible, which means you should treat targets as R objects most of the time. External files are really an afterthought. This might be an uncomfortable notion. You may be accustomed to generating lots of files. drake_plan( write.csv(tabulate_results(data), file_out(&quot;results.csv&quot;)), ggsave(my_ggplot(data), file = file_out(&quot;plot.pdf&quot;)) ) ## # A tibble: 2 x 2 ## target command ## * &lt;chr&gt; &lt;chr&gt; ## 1 &quot;\\&quot;results.csv\\&quot;&quot; &quot;write.csv(tabulate_results(data), file_out(\\&quot;results… ## 2 &quot;\\&quot;plot.pdf\\&quot;&quot; &quot;ggsave(my_ggplot(data), file = file_out(\\&quot;plot.pdf\\&quot;… But R object targets are much more convenient in the long run. If you really want to display them, consolidate them all in an R Markdown report at the end of the pipeline to reduce the number of output files. drake_plan( tab_results = tabulate_results(data), data_plot = my_ggplot(data), rmarkdown::render( knitr_in(&quot;report.Rmd&quot;), # References tab_results` and data_plot in active code chunks using loadd() or readd(). output_file = file_out(&quot;report.html&quot;) ) ) ## # A tibble: 3 x 2 ## target command ## * &lt;chr&gt; &lt;chr&gt; ## 1 tab_results tabulate_results(data) ## 2 data_plot my_ggplot(data) ## 3 &quot;\\&quot;report.html\\&quot;&quot; &quot;rmarkdown::render(knitr_in(\\&quot;report.Rmd\\&quot;), output_f… But sometimes, you may unavoidably have multiple important files for each target. For example, maybe you work with spatial data and use the sf package. st_write(spatial_data, &quot;spatial_data.shp&quot;, driver = &quot;ESRI Shapefile&quot;) ### Creates: ### - &quot;spatial_data.shp&quot; ### - &quot;spatial_data.shx&quot; ### - &quot;spatial_data.prj&quot; ### - &quot;spatial_data.dbf&quot; Later targets may depend on many of these files, but there can only be one output file per target. So what do we do? Spoof drake: pick one file to be the real target, and let the other files be targets that depend on it. library(drake) library(magrittr) drake_plan( st_write(spatial_data, file_out(&quot;spatial_data.shp&quot;), driver = &quot;ESRI Shapefile&quot;), c(file_out(&quot;spatial_data.EXTN&quot;), file_in(&quot;spatial_data.shp&quot;)), out = process_shx(file_in(&quot;spatial_data.EXTN&quot;)) ) %&gt;% evaluate_plan(wildcard = &quot;EXTN&quot;, values = c(&quot;shx&quot;, &quot;prj&quot;, &quot;dbj&quot;)) ## # A tibble: 7 x 2 ## target command ## * &lt;chr&gt; &lt;chr&gt; ## 1 &quot;\\&quot;spatial_data.shp\\&quot;&quot; &quot;st_write(spatial_data, file_out(\\&quot;spatial_data.… ## 2 &quot;\\&quot;spatial_data.shx\\&quot;&quot; &quot;c(file_out(\\&quot;spatial_data.shx\\&quot;), file_in(\\&quot;spa… ## 3 &quot;\\&quot;spatial_data.prj\\&quot;&quot; &quot;c(file_out(\\&quot;spatial_data.prj\\&quot;), file_in(\\&quot;spa… ## 4 &quot;\\&quot;spatial_data.dbj\\&quot;&quot; &quot;c(file_out(\\&quot;spatial_data.dbj\\&quot;), file_in(\\&quot;spa… ## 5 out_shx &quot;process_shx(file_in(\\&quot;spatial_data.shx\\&quot;))&quot; ## 6 out_prj &quot;process_shx(file_in(\\&quot;spatial_data.prj\\&quot;))&quot; ## 7 out_dbj &quot;process_shx(file_in(\\&quot;spatial_data.dbj\\&quot;))&quot; But be warned: If you manually mangle spatial_data.shx, spatial_data.prj or spatial_data.dbj later on, make() will not restore them. Having lots of output files can also slow down the construction of workflow plan data frames (ref: issue 366). It may actually be safer to divide the workflow into two pipelines with separate caches and separate plans. That way, all the output files from the first pipeline, tracked or not tracked, become inputs to the second pipeline. An overarching R script can run both pipelines back to back. plan1 &lt;- drake_plan( st_write(spatial_data, file_out(&quot;spatial_data.shp&quot;), driver = &quot;ESRI Shapefile&quot;) ) plan2 &lt;- drake_plan(out = process_shx(file_in(&quot;spatial_data.EXTN&quot;)))%&gt;% evaluate_plan(wildcard = &quot;EXTN&quot;, values = c(&quot;shx&quot;, &quot;prj&quot;, &quot;dbj&quot;)) cache1 &lt;- new_cache(path = &quot;cache1&quot;) cache2 &lt;- new_cache(path = &quot;cache2&quot;) make(plan1, cache = cache1) make(plan2, cache = cache2) See the storage guide for more on caching, particularly functions get_cache() and this_cache(). 7.1.5 R Markdown and knitr reports For a serious project, you should use drake’s make() function outside knitr. In other words, you should treat R Markdown reports and other knitr documents as targets and imports, not as a way to run make(). Viewed as targets, drake makes special exceptions for R Markdown reports and other knitr reports such as *.Rmd and *.Rnw files. Not every drake project needs them, but it is good practice to use them to summarize the final results of a project once all the other targets have already been built. The mtcars example, for instance, has an R Markdown report. report.Rmd is knitted to build report.md, which summarizes the final results. To see where report.md will be built, look to the right of the dependency graph. load_mtcars_example(overwrite = TRUE) # Get the code with drake_example(&quot;mtcars&quot;). ## Warning in load_mtcars_example(overwrite = TRUE): Overwriting file ## &#39;report.Rmd&#39;. config &lt;- drake_config(my_plan) vis_drake_graph(config) Drake treats knitr report as a special cases. Whenever drake sees knit() or render() (rmarkdown) mentioned in a command, it dives into the source file to look for dependencies. Consider report.Rmd, which you can view here. When drake sees readd(small) in an active code chunk, it knows report.Rmd depends on the target called small, and it draws the appropriate arrow in the dependency graph above. And if small ever changes, make(my_plan) will re-process report.Rmd to produce the target file report.md. knitr reports are the only kind of file that drake analyzes for dependencies. It does not give R scripts the same special treatment. 7.1.6 Workflows as R packages The R package structure is a great way to organize the files of your project. Writing your own package to contain your data science workflow is a good idea, but you will need to Use expose_imports() to properly account for all your nested function dependencies, and If you load the package with devtools::load_all(), set the prework argument of make(): e.g. make(prework = &quot;devtools::load_all()&quot;). Thanks to Jasper Clarkberg for the workaround behind expose_imports(). 7.1.6.1 Advantages of putting workflows in R packages The file organization of R packages is a well-understood community standard. If you follow it, your work may be more readable and thus reproducible. R package installation is a standard process. The system makes it easier for others to obtain and run your code. You get development and quality control tools for free: helpers for loading code and creating files, unit testing, package checks, code coverage, and continuous integration. 7.1.6.2 The problem For drake, there is one problem: nested functions. Drake always looks for imported functions nested in other imported functions, but only in your environment. When it sees a function from a package, it does not look in its body for other imports. To see this, consider the digest() function from the digest package. Digest package is a utility for computing hashes, not a data science workflow, but I will use it to demonstrate how drake treats imports from packages. library(digest) g &lt;- function(x){ digest(x) } f &lt;- function(x){ g(x) } plan &lt;- drake_plan(x = f(1)) ## Here are the reproducibly tracked objects in the workflow. config &lt;- drake_config(plan) tracked(config) ## [1] &quot;digest&quot; &quot;f&quot; &quot;g&quot; &quot;x&quot; ## But the `digest()` function has dependencies too. ## Because `drake` knows `digest()` is from a package, ## it ignores these dependencies by default. head(deps_code(digest), 10) ## [1] &quot;.Call&quot; &quot;any&quot; &quot;as.integer&quot; ## [4] &quot;as.raw&quot; &quot;base::serialize&quot; &quot;digest_impl&quot; ## [7] &quot;file.access&quot; &quot;file.exists&quot; &quot;file.info&quot; ## [10] &quot;formals&quot; 7.1.6.3 The solution To force drake to dive deeper into the nested functions in a package, you must use expose_imports(). Again, I demonstrate with the digest package package, but you should really only do this with a package you write yourself to contain your workflow. For external packages, packrat is a much better solution for package reproducibility. expose_imports(digest) ## &lt;environment: R_GlobalEnv&gt; config &lt;- drake_config(plan) new_objects &lt;- tracked(config) head(new_objects, 10) ## [1] &quot;.Call&quot; &quot;any&quot; &quot;as.integer&quot; ## [4] &quot;as.raw&quot; &quot;base::serialize&quot; &quot;digest&quot; ## [7] &quot;digest_impl&quot; &quot;f&quot; &quot;file.access&quot; ## [10] &quot;file.exists&quot; length(new_objects) ## [1] 31 ## Now when you call `make()`, `drake` will dive into `digest` ## to import dependencies. cache &lt;- storr::storr_environment() # just for examples make(plan, cache = cache) ## target x head(cached(cache = cache), 10) ## [1] &quot;any&quot; &quot;as.integer&quot; &quot;as.raw&quot; ## [4] &quot;base::serialize&quot; &quot;digest&quot; &quot;digest_impl&quot; ## [7] &quot;f&quot; &quot;file.access&quot; &quot;file.exists&quot; ## [10] &quot;file.info&quot; length(cached(cache = cache)) ## [1] 30 ## [1] TRUE 7.2 Remote data sources Some workflows rely on remote data from the internet, and the workflow needs to refresh when the datasets change. As an example, let us consider the download logs of CRAN packages. library(drake) library(R.utils) # For unzipping the files we download. library(curl) # For downloading data. library(httr) # For querying websites. url &lt;- &quot;http://cran-logs.rstudio.com/2018/2018-02-09-r.csv.gz&quot; How do we know when the data at the URL changed? We get the time that the file was last modified. (Alternatively, we could use an HTTP ETag.) query &lt;- HEAD(url) timestamp &lt;- query$headers[[&quot;last-modified&quot;]] timestamp ## [1] &quot;Mon, 12 Feb 2018 16:34:48 GMT&quot; In our workflow plan, the timestamp is a target and a dependency. When the timestamp changes, so does everything downstream. cranlogs_plan &lt;- drake_plan( timestamp = HEAD(url)$headers[[&quot;last-modified&quot;]], logs = get_logs(url, timestamp), strings_in_dots = &quot;literals&quot; ) cranlogs_plan ## # A tibble: 2 x 2 ## target command ## * &lt;chr&gt; &lt;chr&gt; ## 1 timestamp &quot;HEAD(url)$headers[[\\&quot;last-modified\\&quot;]]&quot; ## 2 logs get_logs(url, timestamp) To make sure we always have the latest timestamp, we use the &quot;always&quot; trigger. (For more on triggers, see the guide to debugging and testing drake projects.) cranlogs_plan$trigger &lt;- c(&quot;always&quot;, &quot;any&quot;) cranlogs_plan ## # A tibble: 2 x 3 ## target command trigger ## * &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 timestamp &quot;HEAD(url)$headers[[\\&quot;last-modified\\&quot;]]&quot; always ## 2 logs get_logs(url, timestamp) any Lastly, we define the get_logs() function, which actually downloads the data. ## The ... is just so we can write dependencies as function arguments ## in the workflow plan. get_logs &lt;- function(url, ...){ curl_download(url, &quot;logs.csv.gz&quot;) # Get a big file. gunzip(&quot;logs.csv.gz&quot;, overwrite = TRUE) # Unzip it. out &lt;- read.csv(&quot;logs.csv&quot;, nrows = 4) # Extract the data you need. unlink(c(&quot;logs.csv.gz&quot;, &quot;logs.csv&quot;)) # Remove the big files out # Value of the target. } When we are ready, we run the workflow. make(cranlogs_plan) ## Unloading targets from environment: ## timestamp ## target timestamp: trigger &quot;always&quot; ## target logs ## Used non-default triggers. Some targets may not be up to date. readd(logs) ## date time size version os country ip_id ## 1 2018-02-09 13:01:13 82375220 3.4.3 win RO 1 ## 2 2018-02-09 13:02:06 74286541 3.3.3 win US 2 ## 3 2018-02-09 13:02:10 82375216 3.4.3 win US 3 ## 4 2018-02-09 13:03:30 82375220 3.4.3 win IS 4 "],
["vis.html", "Chapter 8 Visualization with drake 8.1 Underlying graph data: node and edge data frames 8.2 Visualizing target status 8.3 Subgraphs 8.4 Control the vis_drake_graph() legend. 8.5 Clusters", " Chapter 8 Visualization with drake Data analysis projects have complicated networks of dependencies, and drake can help you visualize them with vis_drake_graph(), sankey_drake_graph(), and static_drake_graph(). 8.0.1 vis_drake_graph() Powered by visNetwork, these graphs are interactive. Hover, click, and drag the nodes, and zoom and pan the whole graph. Colors represent target status, and shapes represent data type. library(drake) load_mtcars_example() # Get the code with drake_example(&quot;mtcars&quot;). config &lt;- drake_config(my_plan) vis_drake_graph(config) 8.0.2 sankey_drake_graph() These interactive networkD3 Sankey diagrams have more nuance: the height of each node is proportional to its number of connections. Nodes with many incoming connnections tend to fall out of date more often, and nodes with many outgoing connections can invalidate bigger chunks of the downstream pipeline. sankey_drake_graph(config) Unfortunately, a legend is not yet available for Sankey diagrams, but drake exposes a separate legend for the colors and shapes. library(visNetwork) legend_nodes() ## # A tibble: 10 x 6 ## label color shape font.color font.size id ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; ## 1 Up to date #228B22 dot black 20 1 ## 2 Outdated #000000 dot black 20 2 ## 3 In progress #FF7221 dot black 20 3 ## 4 Failed #AA0000 dot black 20 4 ## 5 Imported #1874CD dot black 20 5 ## 6 Missing #9A32CD dot black 20 6 ## 7 Object #888888 dot black 20 7 ## 8 Function #888888 triangle black 20 8 ## 9 File #888888 square black 20 9 ## 10 Cluster #888888 diamond black 20 10 visNetwork(nodes = legend_nodes()) 8.0.3 static_drake_graph() Powered by ggraph, these graphs are not interactive. However, they are useful for reproducible examples, you can customize the output with additional ggplot2 layers, and you can save them with ggsave(). plan &lt;- drake_plan(data = get_data(), model = data, plot = data) plan ## # A tibble: 3 x 2 ## target command ## * &lt;chr&gt; &lt;chr&gt; ## 1 data get_data() ## 2 model data ## 3 plot data get_data &lt;- function(){} config &lt;- drake_config(plan) static_drake_graph(config) 8.1 Underlying graph data: node and edge data frames drake_graph_info() is used behind the scenes in vis_drake_graph(), sankey_drake_graph(), and static_drake_graph() to get the graph information ready for rendering. To save time, you can call drake_graph_info() to get these internals and then call render_drake_graph(), render_sankey_drake_graph(), or render_static_drake_graph(). str(drake_graph_info(config)) ## List of 4 ## $ nodes :Classes &#39;tbl_df&#39;, &#39;tbl&#39; and &#39;data.frame&#39;: 4 obs. of 10 variables: ## ..$ id : chr [1:4] &quot;data&quot; &quot;get_data&quot; &quot;model&quot; &quot;plot&quot; ## ..$ label : chr [1:4] &quot;data&quot; &quot;get_data\\n0.002s&quot; &quot;model&quot; &quot;plot&quot; ## ..$ command : chr [1:4] &quot;get_data()&quot; NA &quot;data&quot; &quot;data&quot; ## ..$ status : chr [1:4] &quot;outdated&quot; &quot;imported&quot; &quot;outdated&quot; &quot;outdated&quot; ## ..$ type : chr [1:4] &quot;object&quot; &quot;function&quot; &quot;object&quot; &quot;object&quot; ## ..$ font.size : num [1:4] 20 20 20 20 ## ..$ color : chr [1:4] &quot;#000000&quot; &quot;#1874CD&quot; &quot;#000000&quot; &quot;#000000&quot; ## ..$ shape : chr [1:4] &quot;dot&quot; &quot;triangle&quot; &quot;dot&quot; &quot;dot&quot; ## ..$ level : num [1:4] 2 1 3 3 ## ..$ hover_label: chr [1:4] &quot;get_data()&quot; &quot;function () \\n{\\n}&quot; &quot;data&quot; &quot;data&quot; ## $ edges :Classes &#39;tbl_df&#39;, &#39;tbl&#39; and &#39;data.frame&#39;: 3 obs. of 3 variables: ## ..$ from : chr [1:3] &quot;get_data&quot; &quot;data&quot; &quot;data&quot; ## ..$ to : chr [1:3] &quot;data&quot; &quot;model&quot; &quot;plot&quot; ## ..$ arrows: chr [1:3] &quot;to&quot; &quot;to&quot; &quot;to&quot; ## $ legend_nodes :Classes &#39;tbl_df&#39;, &#39;tbl&#39; and &#39;data.frame&#39;: 4 obs. of 6 variables: ## ..$ label : chr [1:4] &quot;Outdated&quot; &quot;Imported&quot; &quot;Object&quot; &quot;Function&quot; ## ..$ color : chr [1:4] &quot;#000000&quot; &quot;#1874CD&quot; &quot;#888888&quot; &quot;#888888&quot; ## ..$ shape : chr [1:4] &quot;dot&quot; &quot;dot&quot; &quot;dot&quot; &quot;triangle&quot; ## ..$ font.color: chr [1:4] &quot;black&quot; &quot;black&quot; &quot;black&quot; &quot;black&quot; ## ..$ font.size : num [1:4] 20 20 20 20 ## ..$ id : int [1:4] 2 5 7 8 ## $ default_title: chr &quot;Dependency graph&quot; 8.2 Visualizing target status drake’s visuals tell you which targets are up to date and which are outdated. config &lt;- make(my_plan, jobs = 4, verbose = FALSE) outdated(config) ## character(0) sankey_drake_graph(config) When you change a dependency, some targets fall out of date (black nodes). reg2 &lt;- function(d){ d$x3 &lt;- d$x ^ 3 lm(y ~ x3, data = d) } sankey_drake_graph(config) 8.3 Subgraphs Graphs can grow enormous for serious projects, so there are multiple ways to focus on a manageable subgraph. The most brute-force way is to just pick a manual subset of nodes. However, with the subset argument, the graphing functions can drop intermediate nodes and edges. vis_drake_graph( config, subset = c(&quot;regression2_small&quot;, file_store(&quot;report.md&quot;)) ) The rest of the subgraph functionality preserves connectedness. Use targets_only to ignore the imports. vis_drake_graph(config, targets_only = TRUE) Similarly, you can just show downstream nodes. vis_drake_graph(config, from = c(&quot;regression2_small&quot;, &quot;regression2_large&quot;)) Or upstream ones. vis_drake_graph(config, from = &quot;small&quot;, mode = &quot;in&quot;) In fact, let us just take a small neighborhood around a target in both directions. vis_drake_graph(config, from = &quot;small&quot;, mode = &quot;all&quot;, order = 1) 8.4 Control the vis_drake_graph() legend. To remove superfluous information from the vis_drake_graph() legend, set the full_legend argument to FALSE. vis_drake_graph(config, full_legend = FALSE) To remove the legend altogether, set the ncol_legend argument to 0. vis_drake_graph(config, ncol_legend = 0) 8.5 Clusters With the group and clusters arguments to the graphing functions, you can condense nodes into clusters. This is handy for workflows with lots of targets. Take the schools scenario from the workflow plan guide. Our plan was generated with evaluate_plan(trace = TRUE), so it has wildcard columns that group nodes into natural clusters already. You can manually add such columns if you wish. plan_template &lt;- drake_plan( school = get_school_data(&quot;school__&quot;), credits = check_credit_hours(all_schools__), students = check_students(all_schools__), grads = check_graduations(all_schools__), public_funds = check_public_funding(public_schools__) ) plan &lt;- evaluate_plan( plan = plan_template, rules = list( school__ = c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;), all_schools__ = c(&quot;school_A&quot;, &quot;school_B&quot;, &quot;school_C&quot;), public_schools__ = c(&quot;school_A&quot;, &quot;school_B&quot;) ), trace = TRUE ) plan ## # A tibble: 14 x 5 ## target command school__ all_schools__ public_schools__ ## * &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 school_A &quot;get_sch… A &lt;NA&gt; &lt;NA&gt; ## 2 school_B &quot;get_sch… B &lt;NA&gt; &lt;NA&gt; ## 3 school_C &quot;get_sch… C &lt;NA&gt; &lt;NA&gt; ## 4 credits_school_A check_cr… &lt;NA&gt; school_A &lt;NA&gt; ## 5 credits_school_B check_cr… &lt;NA&gt; school_B &lt;NA&gt; ## 6 credits_school_C check_cr… &lt;NA&gt; school_C &lt;NA&gt; ## 7 students_school_A check_st… &lt;NA&gt; school_A &lt;NA&gt; ## 8 students_school_B check_st… &lt;NA&gt; school_B &lt;NA&gt; ## 9 students_school_C check_st… &lt;NA&gt; school_C &lt;NA&gt; ## 10 grads_school_A check_gr… &lt;NA&gt; school_A &lt;NA&gt; ## 11 grads_school_B check_gr… &lt;NA&gt; school_B &lt;NA&gt; ## 12 grads_school_C check_gr… &lt;NA&gt; school_C &lt;NA&gt; ## 13 public_funds_school_A check_pu… &lt;NA&gt; &lt;NA&gt; school_A ## 14 public_funds_school_B check_pu… &lt;NA&gt; &lt;NA&gt; school_B Ordinarily, the workflow graph gives a separate node to each individual import object or target. config &lt;- drake_config(plan) vis_drake_graph(config) For large projects with hundreds of nodes, this can get quite cumbersome. But here, we can choose a wildcard column (or any other column in the plan, even custom columns) to condense nodes into natural clusters. For the group argument to the graphing functions, choose the name of a column in plan or a column you know will be in drake_graph_info(config)$nodes. Then for clusters, choose the values in your group column that correspond to nodes you want to bunch together. The new graph is not as cumbersome. config &lt;- drake_config(plan) vis_drake_graph( config, group = &quot;all_schools__&quot;, clusters = c(&quot;school_A&quot;, &quot;school_B&quot;, &quot;school_C&quot;) ) As I mentioned, you can group on any column in drake_graph_info(config)$nodes. Let’s return to the mtcars project for demonstration. config &lt;- drake_config(my_plan) vis_drake_graph(config) Let’s condense all the imports into one node and all the up-to-date targets into another. That way, the outdated targets stand out. vis_drake_graph( config, group = &quot;status&quot;, clusters = c(&quot;imported&quot;, &quot;up to date&quot;) ) "],
["debug.html", "Chapter 9 Debugging and testing drake projects 9.1 The configuration list 9.2 Plan your work. 9.3 Test with triggers. 9.4 Skipping imports 9.5 Impose timeouts and retries 9.6 Diagnose failures. 9.7 Debrief a build session. 9.8 Start tinkering.", " Chapter 9 Debugging and testing drake projects This chapter is a guide to debugging and testing drake projects. Please also see the compendium of cautionary notes, which addresses drake’s known edge cases, pitfalls, and weaknesses that may or may not be fixed in future releases. For the most up-to-date information on unhandled edge cases, please visit the issue tracker, where you can submit your own bug reports as well. Be sure to search the closed issues too, especially if you are not using the most up-to-date development version. 9.1 The configuration list Most of drake’s functions rely on a central config list. An understanding of config will help you grasp the internals. make() and drake_config() both return the config list. Unlike make(), drake_config()’s return value is visible, and its only purpose is to construct your config. load_mtcars_example() # Get the code with drake_example(&quot;mtcars&quot;). config &lt;- drake_config(my_plan) sort(names(config)) ## [1] &quot;all_imports&quot; &quot;all_targets&quot; &quot;args&quot; ## [4] &quot;cache&quot; &quot;cache_log_file&quot; &quot;cache_path&quot; ## [7] &quot;caching&quot; &quot;command&quot; &quot;console_log_file&quot; ## [10] &quot;cpu&quot; &quot;elapsed&quot; &quot;ensure_workers&quot; ## [13] &quot;envir&quot; &quot;evaluator&quot; &quot;fetch_cache&quot; ## [16] &quot;garbage_collection&quot; &quot;graph&quot; &quot;hook&quot; ## [19] &quot;jobs&quot; &quot;jobs_imports&quot; &quot;jobs_targets&quot; ## [22] &quot;keep_going&quot; &quot;lazy_load&quot; &quot;log_progress&quot; ## [25] &quot;long_hash_algo&quot; &quot;makefile_path&quot; &quot;parallelism&quot; ## [28] &quot;plan&quot; &quot;prepend&quot; &quot;prework&quot; ## [31] &quot;pruning_strategy&quot; &quot;recipe_command&quot; &quot;retries&quot; ## [34] &quot;seed&quot; &quot;session&quot; &quot;session_info&quot; ## [37] &quot;short_hash_algo&quot; &quot;skip_imports&quot; &quot;skip_safety_checks&quot; ## [40] &quot;skip_targets&quot; &quot;targets&quot; &quot;timeout&quot; ## [43] &quot;trigger&quot; &quot;verbose&quot; The fields of config mostly arguments to make() and are documented there. The rest of the fields are as follows. graph: An igraph object with the directed acyclic graph (DAG) of the workflow. inventory: A running list of the cached objects in each storr namespace. Maintaining this list helps avoid repeated calls to config$cache$list(), which increases speed. long_hash_algo: Name of the long hash algorithm used throughout make(). Used to generate hash keys that will not become the names of files. See the custom storage guide for details. seed: The random number generator seed taken from the user’s R session. Each target is built reproducibly using a deterministic function of this seed, and the build does not change the seed outside the scope of the target’s command. short_hash_algo: Name of the short hash algorithm used throughout make(). Used to generate hash keys that could become names of files. See the custom storage guide for details. Early in make(), the config list is stored in the cache. You can retrieve it with read_drake_config() and you can access parts of it with some companion functions. read_drake_graph() read_drake_plan() 9.2 Plan your work. 9.2.1 Workflow plan data frames The workflow plan data frame is your responsibility, and it takes effort and care. Fortunately, functions in drake can help. You can check the plan for formatting issues, missing input files, etc. with the check_plan() function. load_mtcars_example() # Get the code with drake_example(&quot;mtcars&quot;). my_plan ## # A tibble: 15 x 2 ## target command ## &lt;chr&gt; &lt;chr&gt; ## 1 &quot;&quot; &quot;knit(knitr_in(\\&quot;report.Rmd\\&quot;), file_out(\\&quot;repo… ## 2 small simulate(48) ## 3 large simulate(64) ## 4 regression1_small reg1(small) ## 5 regression1_large reg1(large) ## 6 regression2_small reg2(small) ## 7 regression2_large reg2(large) ## 8 summ_regression1_small suppressWarnings(summary(regression1_small$resi… ## 9 summ_regression1_large suppressWarnings(summary(regression1_large$resi… ## 10 summ_regression2_small suppressWarnings(summary(regression2_small$resi… ## 11 summ_regression2_large suppressWarnings(summary(regression2_large$resi… ## 12 coef_regression1_small suppressWarnings(summary(regression1_small))$co… ## 13 coef_regression1_large suppressWarnings(summary(regression1_large))$co… ## 14 coef_regression2_small suppressWarnings(summary(regression2_small))$co… ## 15 coef_regression2_large suppressWarnings(summary(regression2_large))$co… check_plan(my_plan) # No issues. 9.2.2 Visualize your workflow. After quality-checking your plan, you should check that you understand how the steps of your workflow are interconnected. The web of dependencies affects which targets are built and which ones are skipped during make(). ## Hover, click, drag, zoom, and pan. See args &#39;from&#39; and &#39;to&#39;. config &lt;- drake_config(my_plan) vis_drake_graph(config, width = &quot;100%&quot;, height = &quot;500px&quot;) See the visualization chapter to learn more about how graphing can help (for example, how to visualize small subgraphs). If you want to take control of your own visNetwork graph, use the drake_graph_info() function to get data frames of nodes, edges, and legend nodes. 9.2.3 Check dependency relationships. Programmatically, several functions can help you check immediate dependencies. deps_code(reg2) ## [1] &quot;lm&quot; ## knitr_in() makes sure your target depends on `report.Rmd` ## and any dependencies loaded with loadd() and readd() ## in the report&#39;s active code chunks. deps_code(my_plan$command[1]) ## [1] &quot;\\&quot;report.md\\&quot;&quot; &quot;\\&quot;report.Rmd\\&quot;&quot; ## [3] &quot;coef_regression2_small&quot; &quot;knit&quot; ## [5] &quot;large&quot; &quot;small&quot; deps_code(my_plan$command[nrow(my_plan)]) ## [1] &quot;regression2_large&quot; &quot;summary&quot; &quot;suppressWarnings&quot; Drake takes special precautions so that a target/import does not depend on itself. For example, deps_code(f) might return &quot;f&quot; if f() is a recursive function, but make() just ignores this conflict and runs as expected. In other words, make() automatically removes all self-referential loops in the dependency network. List all the reproducibly-tracked objects and files, including imports and targets. config &lt;- drake_config(my_plan) tracked(config) ## [1] &quot;\\&quot;report.md\\&quot;&quot; &quot;\\&quot;report.Rmd\\&quot;&quot; ## [3] &quot;coef_regression1_large&quot; &quot;coef_regression1_small&quot; ## [5] &quot;coef_regression2_large&quot; &quot;coef_regression2_small&quot; ## [7] &quot;data.frame&quot; &quot;knit&quot; ## [9] &quot;large&quot; &quot;lm&quot; ## [11] &quot;mtcars&quot; &quot;nrow&quot; ## [13] &quot;random_rows&quot; &quot;reg1&quot; ## [15] &quot;reg2&quot; &quot;regression1_large&quot; ## [17] &quot;regression1_small&quot; &quot;regression2_large&quot; ## [19] &quot;regression2_small&quot; &quot;sample.int&quot; ## [21] &quot;simulate&quot; &quot;small&quot; ## [23] &quot;summ_regression1_large&quot; &quot;summ_regression1_small&quot; ## [25] &quot;summ_regression2_large&quot; &quot;summ_regression2_small&quot; ## [27] &quot;summary&quot; &quot;suppressWarnings&quot; 9.2.4 Outdated, up to date, and missing items missed() reports import dependencies missing from your environment config &lt;- drake_config(my_plan, verbose = FALSE) missed(config) # Nothing is missing right now. ## character(0) outdated() reports any targets that are outdated, plus any downstream targets that depend on them. outdated(config) ## [1] &quot;\\&quot;report.md\\&quot;&quot; &quot;coef_regression1_large&quot; ## [3] &quot;coef_regression1_small&quot; &quot;coef_regression2_large&quot; ## [5] &quot;coef_regression2_small&quot; &quot;large&quot; ## [7] &quot;regression1_large&quot; &quot;regression1_small&quot; ## [9] &quot;regression2_large&quot; &quot;regression2_small&quot; ## [11] &quot;small&quot; &quot;summ_regression1_large&quot; ## [13] &quot;summ_regression1_small&quot; &quot;summ_regression2_large&quot; ## [15] &quot;summ_regression2_small&quot; To find out why a target is out of date, you can load the storr-based cache and compare the appropriate hash keys to the output of dependency_profile(). To use dependency_profile(), be sure to supply the master configuration list as the config argument. The same is true for drake_meta(), another alternative. load_mtcars_example() # Get the code with drake_example(&quot;mtcars&quot;). config &lt;- make(my_plan, verbose = FALSE) ## Change a dependency. reg2 &lt;- function(d) { d$x3 &lt;- d$x ^ 3 lm(y ~ x3, data = d) } outdated(config) ## [1] &quot;\\&quot;report.md\\&quot;&quot; &quot;coef_regression2_large&quot; ## [3] &quot;coef_regression2_small&quot; &quot;regression2_large&quot; ## [5] &quot;regression2_small&quot; &quot;summ_regression2_large&quot; ## [7] &quot;summ_regression2_small&quot; dependency_profile(target = &quot;regression2_small&quot;, config = config) ## $cached_command ## [1] &quot;{\\n reg2(small) \\n}&quot; ## ## $current_command ## [1] &quot;{\\n reg2(small) \\n}&quot; ## ## $cached_file_modification_time ## NULL ## ## $cached_dependency_hash ## [1] &quot;b5124bdceef8650183170ba11007bb7b52cb8e34d3f16da33d8e429406c8dcbd&quot; ## ## $current_dependency_hash ## [1] &quot;80a7eb5288828c2f5816caf84db9ebf97d423021e4682949705d682586218012&quot; ## ## $hashes_of_dependencies ## small reg2 ## &quot;7d836504e5060e6d&quot; &quot;d47109544c89ca7a&quot; drake_meta(target = &quot;regression2_small&quot;, config = config) ## $target ## [1] &quot;regression2_small&quot; ## ## $imported ## [1] FALSE ## ## $foreign ## [1] TRUE ## ## $missing ## [1] FALSE ## ## $seed ## [1] 1034257256 ## ## $command ## [1] &quot;{\\n reg2(small) \\n}&quot; ## ## $depends ## [1] &quot;80a7eb5288828c2f5816caf84db9ebf97d423021e4682949705d682586218012&quot; ## ## $file ## [1] NA config$cache$get_hash(key = &quot;small&quot;, namespace = &quot;kernels&quot;) # same ## [1] &quot;7d836504e5060e6d&quot; config$cache$get_hash(key = &quot;small&quot;) # same ## [1] &quot;7d836504e5060e6d&quot; config$cache$get_hash(key = &quot;reg2&quot;, namespace = &quot;kernels&quot;) # same ## [1] &quot;d47109544c89ca7a&quot; config$cache$get_hash(key = &quot;reg2&quot;) # different ## [1] &quot;7566566c08e764d6&quot; In drake, the “kernel” of a target or import is the piece of the output that is reproducibly tracked. For ordinary R objects, the kernel is just the object itself. For custom external files, it is a separate hash. But for functions, the kernel is the deparsed body of the function, together with the dependency hash if the function is imported (see drake:::store_function()). The internal functions drake:::meta() and drake:::meta_list() compute the metadata on each target that drake uses to decide which targets to build and which to skip (via drake:::should_build_target()). Then, after the target/import is processed, drake:::finish_meta() updates the metadata (except for the $missing element) before it is cached. See diagnose() to read available metadata, along with any errors, warnings, and messages generated during the build. str(diagnose(small)) ## List of 11 ## $ target : chr &quot;small&quot; ## $ imported : logi FALSE ## $ foreign : logi TRUE ## $ missing : logi TRUE ## $ seed : num 1.95e+09 ## $ command : chr &quot;{\\n simulate(48) \\n}&quot; ## $ depends : chr &quot;eb89933a9211e556671c06c5018dcdb7efdad4593b4adff4f88ee6a34de61f7f&quot; ## $ file : chr NA ## $ start : &#39;proc_time&#39; Named num [1:5] 51.78 5 70.83 10.8 6.14 ## ..- attr(*, &quot;names&quot;)= chr [1:5] &quot;user.self&quot; &quot;sys.self&quot; &quot;elapsed&quot; &quot;user.child&quot; ... ## $ time_command:&#39;data.frame&#39;: 1 obs. of 5 variables: ## ..$ item : chr &quot;small&quot; ## ..$ type : chr &quot;target&quot; ## ..$ elapsed: num 0 ## ..$ user : num 0 ## ..$ system : num 0 ## $ time_build :&#39;data.frame&#39;: 1 obs. of 5 variables: ## ..$ item : chr &quot;small&quot; ## ..$ type : chr &quot;target&quot; ## ..$ elapsed: num 0.005 ## ..$ user : num 0.004 ## ..$ system : num 0 str(diagnose(&quot;\\&quot;report.md\\&quot;&quot;)) ## List of 12 ## $ target : chr &quot;\\&quot;report.md\\&quot;&quot; ## $ imported : logi FALSE ## $ foreign : logi TRUE ## $ missing : logi TRUE ## $ seed : num 1.85e+09 ## $ command : chr &quot;{\\n knit(knitr_in(\\&quot;report.Rmd\\&quot;), file_out(\\&quot;report.md\\&quot;), quiet = TRUE) \\n}&quot; ## $ depends : chr &quot;6052046ce2b9f28564cecc5200f36c0783dace985fee747bc3a332d2010b2581&quot; ## $ file : chr &quot;65f43df5f3fb7d0e2b78b2fa2ada9a635a7557780e79e08805156d60b53e7abc&quot; ## $ start : &#39;proc_time&#39; Named num [1:5] 52.02 5.02 71.09 10.8 6.14 ## ..- attr(*, &quot;names&quot;)= chr [1:5] &quot;user.self&quot; &quot;sys.self&quot; &quot;elapsed&quot; &quot;user.child&quot; ... ## $ time_command:&#39;data.frame&#39;: 1 obs. of 5 variables: ## ..$ item : chr &quot;\\&quot;report.md\\&quot;&quot; ## ..$ type : chr &quot;target&quot; ## ..$ elapsed: num 0.056 ## ..$ user : num 0.056 ## ..$ system : num 0 ## $ mtime : POSIXct[1:1], format: &quot;2018-07-13 04:09:53&quot; ## $ time_build :&#39;data.frame&#39;: 1 obs. of 5 variables: ## ..$ item : chr &quot;\\&quot;report.md\\&quot;&quot; ## ..$ type : chr &quot;target&quot; ## ..$ elapsed: num 0.063 ## ..$ user : num 0.06 ## ..$ system : num 0 If your target’s last build succeeded, then diagnose(your_target) has the most current information from that build. But if your target failed, then only diagnose(your_target)$error, diagnose(your_target)$warnings, and diagnose(your_target)$messages correspond to the failure, and all the other metadata correspond to the last build that completed without an error. 9.3 Test with triggers. To track dependencies and make decisions about what needs building, make() store the fingerprint, or hash, of each target. Hashing is great for detecting the right changes in targets, but if all you want to do is test and debug a workflow, the full rigor can be time-consuming. Fortunately, you can change the triggers that tell drake when to (re)build each target. Below, drake disregards outdatedness and just builds the targets that are missing. clean(verbose = FALSE) # Start from scratch config &lt;- make(my_plan, trigger = &quot;missing&quot;) ## target large: trigger &quot;missing&quot; ## target small: trigger &quot;missing&quot; ## target regression1_large: trigger &quot;missing&quot; ## target regression2_large: trigger &quot;missing&quot; ## target regression1_small: trigger &quot;missing&quot; ## target regression2_small: trigger &quot;missing&quot; ## target summ_regression1_large: trigger &quot;missing&quot; ## target coef_regression1_large: trigger &quot;missing&quot; ## target summ_regression2_large: trigger &quot;missing&quot; ## target coef_regression2_large: trigger &quot;missing&quot; ## target summ_regression1_small: trigger &quot;missing&quot; ## target coef_regression1_small: trigger &quot;missing&quot; ## target coef_regression2_small: trigger &quot;missing&quot; ## target summ_regression2_small: trigger &quot;missing&quot; ## target file &quot;report.md&quot;: trigger &quot;missing&quot; ## Used non-default triggers. Some targets may not be up to date. You can choose from any of the following triggers for all targets or for each target individually. always: Always build the target regardless of the circumstance, even if the target is already up to date. any: Apply all the triggers below (default). In other words, trigger a build if the command trigger, depends trigger, file trigger, or missing trigger is activated. command: Build if the workflow plan command changed since the last make() or the target is missing. depends: Build if any of the target’s dependencies changed since the last make() or if the target is missing. file: Build if the target is an output file and the file is either missing or corrupted. Also build if the file’s hash is missing from the cache. missing: Build if and only if the target is missing. To select triggers for individual targets, create an optional trigger column in the workflow plan data frame. Entries in this column override the trigger argument to make() my_plan$trigger &lt;- &quot;command&quot; my_plan$trigger[1] &lt;- &quot;file&quot; my_plan ## # A tibble: 15 x 3 ## target command trigger ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 &quot;&quot; &quot;knit(knitr_in(\\&quot;report.Rmd\\&quot;), file_ou… file ## 2 small simulate(48) command ## 3 large simulate(64) command ## 4 regression1_small reg1(small) command ## 5 regression1_large reg1(large) command ## 6 regression2_small reg2(small) command ## 7 regression2_large reg2(large) command ## 8 summ_regression1_small suppressWarnings(summary(regression1_sm… command ## 9 summ_regression1_large suppressWarnings(summary(regression1_la… command ## 10 summ_regression2_small suppressWarnings(summary(regression2_sm… command ## 11 summ_regression2_large suppressWarnings(summary(regression2_la… command ## 12 coef_regression1_small suppressWarnings(summary(regression1_sm… command ## 13 coef_regression1_large suppressWarnings(summary(regression1_la… command ## 14 coef_regression2_small suppressWarnings(summary(regression2_sm… command ## 15 coef_regression2_large suppressWarnings(summary(regression2_la… command ## Change an imported dependency: reg2 ## function(d) { ## d$x3 &lt;- d$x ^ 3 ## lm(y ~ x3, data = d) ## } reg2 &lt;- function(d) { d$x3 &lt;- d$x ^ 3 lm(y ~ x3, data = d) } make(my_plan, trigger = &quot;any&quot;) # Nothing changes! ## Used non-default triggers. Some targets may not be up to date. The outdated() function responds to triggers. For example, even if outdated(my_plan) shows all targets up to date, outdated(my_plan, trigger = &quot;always&quot;) will claim that all the targets are outdated. 9.4 Skipping imports Similar to triggers, you can also to skip the processing of imported objects and files. However, you should only use this for testing purposes. If some of your imports are not already cached and up to date, any built targets will be out of sync. In other words, outdated() is more likely to be wrong, and your project may no longer be reproducible. clean(verbose = FALSE) my_plan$trigger &lt;- NULL make(my_plan, skip_imports = TRUE) ## target large ## target small ## target regression1_large ## target regression2_large ## target regression1_small ## target regression2_small ## target summ_regression1_large ## target coef_regression1_large ## target summ_regression2_large ## target coef_regression2_large ## target summ_regression1_small ## target coef_regression1_small ## target coef_regression2_small ## target summ_regression2_small ## target file &quot;report.md&quot; ## Skipped the imports. If some imports are not already cached, targets could be out of date. 9.5 Impose timeouts and retries See the timeout, cpu, elapsed, and retries argument to make(). clean(verbose = FALSE) f &lt;- function(...){ Sys.sleep(1) } debug_plan &lt;- drake_plan(x = 1, y = f(x)) debug_plan ## # A tibble: 2 x 2 ## target command ## * &lt;chr&gt; &lt;chr&gt; ## 1 x 1 ## 2 y f(x) withr::with_message_sink( stdout(), make(debug_plan, timeout = 1e-3, retries = 2) ) ## target x ## target y ## retry y: 1 of 2 ## retry y: 2 of 2 ## fail y ## Error: Target `y` failed. Call `diagnose(y)` for details. Error message: ## reached elapsed time limit ## Warning: No message sink to remove. To tailor these settings to each individual target, create new timeout, cpu, elapsed, or retries columns in your workflow plan. These columns override the analogous arguments to make(). clean(verbose = FALSE) debug_plan$timeout &lt;- c(1e-3, 2e-3) debug_plan$retries &lt;- 1:2 debug_plan ## # A tibble: 2 x 4 ## target command timeout retries ## * &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; ## 1 x 1 0.001 1 ## 2 y f(x) 0.002 2 withr::with_message_sink( new = stdout(), make(debug_plan, timeout = Inf, retries = 0) ) ## Unloading targets from environment: ## x ## target x ## target y ## [2018-07-13 04:10:05] TimeoutException: reached CPU time limit [cpu=0.002s, ## elapsed=0.002s] ## Warning: No message sink to remove. 9.6 Diagnose failures. Drake records diagnostic metadata on all your targets, including the latest errors, warnings, messages, and other bits of context. diagnose(verbose = FALSE) # Targets with available metadata. ## [1] &quot;f&quot; &quot;Sys.sleep&quot; &quot;x&quot; &quot;y&quot; f &lt;- function(x){ if (x &lt; 0){ stop(&quot;`x` cannot be negative.&quot;) } x } bad_plan &lt;- drake_plan( a = 12, b = -a, my_target = f(b) ) bad_plan ## # A tibble: 3 x 2 ## target command ## * &lt;chr&gt; &lt;chr&gt; ## 1 a 12 ## 2 b -a ## 3 my_target f(b) withr::with_message_sink( new = stdout(), make(bad_plan) ) ## target a ## target b ## target my_target ## fail my_target ## Error: Target `my_target` failed. Call `diagnose(my_target)` for details. Error message: ## `x` cannot be negative. ## Warning: No message sink to remove. failed(verbose = FALSE) # from the last make() only ## [1] &quot;my_target&quot; ## See also warnings and messages. error &lt;- diagnose(my_target, verbose = FALSE)$error error$message ## [1] &quot;`x` cannot be negative.&quot; error$call ## f(b) error$calls # View the traceback. ## [[1]] ## local({ ## f(b) ## }) ## ## [[2]] ## eval.parent(substitute(eval(quote(expr), envir))) ## ## [[3]] ## eval(expr, p) ## ## [[4]] ## eval(expr, p) ## ## [[5]] ## eval(quote({ ## f(b) ## }), new.env()) ## ## [[6]] ## eval(quote({ ## f(b) ## }), new.env()) ## ## [[7]] ## f(b) ## ## [[8]] ## stop(&quot;`x` cannot be negative.&quot;) To figure out what went wrong, you could try to build the failed target interactively. To do that, simply call drake_build(). This function first calls loadd(deps = TRUE) to load any missing dependencies (see the replace argument here) and then builds your target. ## Pretend we just opened a new R session. library(drake) ## Unloads target `b`. config &lt;- drake_config(plan = bad_plan) ## Unloading targets from environment: ## b ## my_target depends on b. &quot;b&quot; %in% ls() ## [1] FALSE ## Try to build my_target until the error is fixed. ## Skip all that pesky work checking dependencies. drake_build(my_target, config = config) ## target my_target ## fail my_target ## Error: Target `my_target` failed. Call `diagnose(my_target)` for details. Error message: ## `x` cannot be negative. ## The target failed, but the dependency was loaded. &quot;b&quot; %in% ls() ## [1] TRUE ## What was `b` again? b ## [1] -12 ## How was `b` used? diagnose(my_target)$message ## NULL diagnose(my_target)$call ## NULL f ## function(x){ ## if (x &lt; 0){ ## stop(&quot;`x` cannot be negative.&quot;) ## } ## x ## } ## Aha! The error was in f(). Let&#39;s fix it and try again. f &lt;- function(x){ x &lt;- abs(x) if (x &lt; 0){ stop(&quot;`x` cannot be negative.&quot;) } x } ## Now it works! ## Since you called make() previously, `config` is read from the cache ## if you do not supply it. drake_build(my_target) ## target my_target readd(my_target) ## [1] 12 9.6.1 Tidy evaluation: a caveat to diagnosing interactively Running commands in your R console is not always exactly like running them with make(). That’s because make() uses tidy evaluation as implemented in the rlang package. ## This workflow plan uses rlang&#39;s quasiquotation operator `!!`. my_plan &lt;- drake_plan(list = c( little_b = &quot;\\&quot;b\\&quot;&quot;, letter = &quot;!!little_b&quot; )) my_plan ## # A tibble: 2 x 2 ## target command ## * &lt;chr&gt; &lt;chr&gt; ## 1 little_b &quot;\\&quot;b\\&quot;&quot; ## 2 letter !!little_b make(my_plan) ## target little_b ## target letter readd(letter) ## [1] &quot;b&quot; 9.7 Debrief a build session. After your project is at least somewhat built, you can inspect and read your results from the cache. make(my_plan, verbose = FALSE) ## drake_session(verbose = FALSE) # Prints the sessionInfo() of the last make(). # nolint cached(verbose = FALSE) ## [1] &quot;a&quot; &quot;b&quot; &quot;f&quot; &quot;letter&quot; &quot;little_b&quot; &quot;my_target&quot; ## [7] &quot;stop&quot; &quot;Sys.sleep&quot; &quot;x&quot; built(verbose = FALSE) ## [1] &quot;a&quot; &quot;b&quot; &quot;letter&quot; &quot;little_b&quot; &quot;my_target&quot; &quot;x&quot; imported(verbose = FALSE) ## [1] &quot;f&quot; &quot;stop&quot; &quot;Sys.sleep&quot; loadd(little_b, verbose = FALSE) little_b ## [1] &quot;b&quot; readd(letter, verbose = FALSE) ## [1] &quot;b&quot; progress(verbose = FALSE) ## Error in progress(verbose = FALSE): unused argument (verbose = FALSE) in_progress(verbose = FALSE) # Unfinished targets ## character(0) There are functions to help you locate the project’s cache. ## find_project() # nolint ## find_cache() # nolint For more information on the cache, see the chapter on storage and caches. 9.8 Start tinkering. The load_mtcars_example() function loads the mtcars example from drake_example(&quot;mtcars&quot;) right into your workspace. The workflow plan data frame, workspace, and import files are set up for you. Only make(my_plan) is left to you. Drake has many more built-in examples. To see your choices, use drake_examples() ## [1] &quot;Docker-psock&quot; &quot;gsp&quot; &quot;lfs&quot; ## [4] &quot;main&quot; &quot;Makefile-cluster&quot; &quot;mtcars&quot; ## [7] &quot;packages&quot; &quot;sge&quot; &quot;slurm&quot; ## [10] &quot;torque&quot; To write the files for an example, use drake_example(). drake_example(&quot;mtcars&quot;) drake_example(&quot;slurm&quot;) "],
["hpc.html", "Chapter 10 High-performance computing with drake 10.1 Batch mode for long workflows 10.2 Let drake schedule your targets. 10.3 Parallel backends 10.4 Local workers 10.5 Remote workers 10.6 Scheduling algorithms 10.7 Final thoughts 10.8 Footnotes", " Chapter 10 High-performance computing with drake Drake is not only a reproducibility tool, but also a high-performance computing engine. To activate parallel computing, just set the jobs argument of make() to a value greater than 1. Below, up to 2 targets can run simultaneously at any given time. library(drake) load_mtcars_example() make(my_plan, jobs = 2) 10.1 Batch mode for long workflows To deploy serious long workflows, we recommend putting the call to make() in a script (say, drake_work.R) and running it in an unobtrusive background process that persists after you log out. In the Linux command line, this is straightforward. nohup nice -19 R CMD BATCH drake_work.R & Or, you could call drake inside an overarching Makefile that chains multiple stages together in a larger reproducible pipeline. (See Karl Broman’s post on Makefiles for reproducible research.) all: final_output.pdf final_output.pdf: python_magic.py results_summary.csv python python_magic.py results_summary.csv: drake_work.R Rscript drake_work.R clean: rm -rf .drake Then, run your whole pipleine in a persistent background process. nohup nice -19 R CMD BATCH make & If you do write a custom Makefile at the root of your project and you plan to use make(parallelism = &quot;Makefile&quot;), please read about make(parallelism = &quot;Makefile&quot;) later in this document to avoid potential conflicts between your Makefile and the one drake writes. 10.2 Let drake schedule your targets. When you deploy your project, drake uses the dependency network to figure out how to run your work in parallel. You as the user do not have to micromanage when individual targets are built. load_mtcars_example() config &lt;- drake_config(my_plan) vis_drake_graph(config) 10.3 Parallel backends There are multiple ways to walk this graph and multiple ways to launch workers, and every project has its own needs. Thus, drake supports multiple parallel backends. Choose the backend with the parallelism argument. make(my_plan, parallelism = &quot;parLapply&quot;, jobs = 2) You can use a different backend for the imports than you select for the targets. If you do so, you force all the imports to be processed before any of the targets are built, but you might want to do so anyway. For example, staged scheduling could be great for imports even when it is not be the right choice for the targets (more on that later). make( my_plan, parallelism = c(imports = &quot;mclapply_staged&quot;, targets = &quot;mclapply&quot;), jobs = 2 ) List your options with parallelism_choices(). parallelism_choices() ## [1] &quot;mclapply&quot; &quot;parLapply&quot; &quot;mclapply_staged&quot; ## [4] &quot;parLapply_staged&quot; &quot;clustermq_staged&quot; &quot;future&quot; ## [7] &quot;future_lapply&quot; &quot;future_lapply_staged&quot; &quot;Makefile&quot; The backends vary widely in terms of how the workers deploy and how they are scheduled. Deploy: local Deploy: remote Schedule: persistent “mclapply”, “parLapply” “future_lapply” Schedule: transient “future”, “Makefile” Schedule: staged “mclapply_staged”, “parLapply_staged” “clustermq_staged”, “future_lapply_staged” The next sections describe how and when to use each scheduling algorithm and deployment strategy. 10.4 Local workers Local workers deploy as separate forks or processes to you computer. The &quot;mclapply&quot; and &quot;mclapply_staged&quot; backends uses the mclapply() function from the parallel package to launch workers. make(my_plan, parallelism = &quot;mclapply&quot;, jobs = 2) make(my_plan, parallelism = &quot;mclapply_staged&quot;, jobs = 2) Workers are quicker to launch than in any other drake backend, so these two choices are the lowest-overhead options. However, they have limitations: the mclapply() function is inefficient with respect to computer memory (see explanations here and here) and it cannot launch multiple workers on Windows. For this reason, drake supports platform agnostic backends &quot;parLapply&quot; and &quot;parLapply_staged&quot;, both of which are based on the parLapply() function from the parallel package. These options work on Windows, but each make() requires extra overhead to create a parallel socket (PSOCK) cluster. make(my_plan, parallelism = &quot;parLapply&quot;, jobs = 2) make(my_plan, parallelism = &quot;parLapply_staged&quot;, jobs = 2) The default parallelism is &quot;parLapply&quot; on Windows and &quot;mclapply&quot; everywhere else. default_parallelism() ## [1] &quot;mclapply&quot; 10.5 Remote workers The &quot;future_lapply&quot;, &quot;future&quot;, and &quot;Makefile&quot; backends have the option to launch workers to remote resources such as nodes on a computing cluster. parallelism_choices(distributed_only = TRUE) ## [1] &quot;clustermq_staged&quot; &quot;future&quot; &quot;future_lapply&quot; ## [4] &quot;future_lapply_staged&quot; &quot;Makefile&quot; Testing them out is straightforward. make(my_plan, parallelism = &quot;future&quot;, jobs = 2) make(my_plan, parallelism = &quot;future_lapply&quot;, jobs = 2) make(my_plan, parallelism = &quot;Makefile&quot;, jobs = 2) For remote workers, the all the imports are processed with one of the local worker backends before any of the targets start. You can use different numbers of workers for the imports and the targets. make(my_plan, parallelism = &quot;future&quot;, jobs = c(imports = 2, targets = 4)) By default, these backends launch the workers on your local machine. It takes extra configuring to actually deploy them to a remote cluster. The next subsections have the details. 10.5.1 &quot;future&quot;, &quot;future_lapply&quot;, and &quot;future_lapply_staged&quot; The plan() function from the future package configures how and where the workers will deploy on the next make(). For example, the following code uses future’s multisession backend, which is analogous to drake’s &quot;parLapply&quot; parallelism. library(future) future::plan(multisession) make(my_plan, parallelism = &quot;future&quot;, jobs = 2) ## Same technology, different scheduling: make(my_plan, parallelism = &quot;future_lapply&quot;, jobs = 2) For &quot;future_lapply_staged&quot; parallelism, the jobs argument is ignored, and you must instead specify the number of workers in future::plan(). future::plan(multisession, workers = 2) make(my_plan, parallelism = &quot;future_lapply_staged&quot;) To deploy to a cluster (say, a SLURM cluster), you need the batchtools and future.batchtools packages. library(future.batchtools) You also need template file to configure batchtools with the cluster: memory specifications, wall time limits etc. Use drake_hpc_template_file() to write one of the available example template files for batchtools (list with drake_hpc_template_files()). You will probably need to edit your tempalte file manually to match your resources and needs. drake_hpc_tempalte_file(&quot;slurm_batchtools.tmpl&quot;) # Write the file slurm_batchtools.tmpl. Load the template file your future::plan() and call make() to run the project. future::plan(batchtools_slurm, template = &quot;slurm_batchtools.tmpl&quot;) make(my_plan, parallelism = &quot;future&quot;, jobs = 2) ## Same technology, different scheduling options: make(my_plan, parallelism = &quot;future_lapply&quot;, jobs = 2) And as before, &quot;future_lapply_staged&quot; uses the workers argument from future::plan() rather than jobs in make(). future::plan(batchtools_slurm, template = &quot;slurm_batchtools.tmpl&quot;, workers = 2) make(my_plan, parallelism = &quot;future_lapply_staged&quot;) See packages future, future.batchtools, and batchtools for more options. For example, the alternatives for future::plan() are listed here and here. 10.5.2 &quot;clustermq_staged&quot; The clustermq R package is a fast, user-friendly tool for sending R jobs to clusters, and clustermq-powered drake workers suffer less overhead than other remote workers. To use drake’s clustermq backends, you must first install ZeroMQ (installation instructions here). Then, install clustermq explicitly (it does not come with drake). install.packages(&quot;clustermq&quot;) # CRAN release # Alternatively, install the GitHub development version. devtools::install_github(&quot;mschubert/clustermq&quot;) clustermq detects most clusters automatically. However, you may still want to configure resources, wall time limits, etc. If so, you will need a template file. Use drake_hpc_template_file() to write one of the available example template files for clustermq. (list with drake_hpc_template_files()). You will probably need to edit your tempalte file manually to match your resources and needs. drake_hpc_tempalte_file(&quot;slurm_clustermq.tmpl&quot;) # Write the file slurm_clustermq.tmpl. Next, configure clustermq to use your scheduler and template file. clustermq has a really nice wiki with more detailed directions. options(clustermq.scheduler = &quot;slurm&quot;, template = &quot;slurm_clustermq.tmpl&quot;) Tip: for a dry run on your local machine, use options(clustermq.scheduler = &quot;multicore&quot;) instead. Either way, once it is time to run your project, simply call make() with one of the clustermq parallelism backends. make(my_plan, parallelism = &quot;clustermq_staged&quot;, jobs = 4) 10.5.3 &quot;Makefile&quot; Here, drake actually writes, configures, and runs a proper Makefile to run the targets. make(my_plan, parallelism = &quot;Makefile&quot;, jobs = 2) You can configure both the Unix command that runs the Makefile and the command line arguments passed to it. make( my_plan, parallelism = &quot;Makefile&quot;, command = &quot;lsmake&quot;, args = c(&quot;--touch&quot;, &quot;--silent&quot;) ) If drake’s Makefile conflicts with a Makefile you already wrote yourself, drake does not overwrite your Makefile. Instead, make() tells you about the conflict and then stops running. To force drake to use a different Makefile that does not conflict with yours, pass the file path to the makefile_path argument and set the --file argument in args. make( my_plan, parallelism = &quot;Makefile&quot;, makefile_path = &quot;my_folder/my_makefile&quot;, args = &quot;--file=my_folder/my_makefile&quot; ) There are more customization options in make(), such as the recipe_command argument. make(my_plan, parallelism = &quot;Makefile&quot;, jobs = 4, recipe_command = &quot;R -e &#39;R_RECIPE&#39; -q&quot;) See the help files of individual functions for details. default_Makefile_command() ## [1] &quot;make&quot; default_recipe_command() ## [1] &quot;Rscript -e &#39;R_RECIPE&#39;&quot; r_recipe_wildcard() ## [1] &quot;R_RECIPE&quot; Makefile_recipe( recipe_command = &quot;R -e &#39;R_RECIPE&#39; -q&quot;, target = &quot;this_target&quot;, cache_path = &quot;custom_cache&quot; ) ## R -e &#39;drake::mk(target = &quot;this_target&quot;, cache_path = &quot;custom_cache&quot;)&#39; -q To deploy workers to a cluster, you need to supply the Makefile with a custom shell script that launches cluster jobs. Use the shell_file() function to write an example compatible with the Univa Grid Engine. You will probably need to configure it manually. Suppose our file is shell.sh. #!/bin/bash shift echo \"module load R; $*\" | qsub -sync y -cwd -j y You will need to set permissions to allow execution. In the Linux command line, this is straightforward. $ chmod +x shell.sh When you actually call make(), use the prepend argument to write a line at the top of the Makefile to reference your shell file. make(my_plan, parallelism = &quot;Makefile&quot;, jobs = 2, prepend = &quot;SHELL=./shell.sh&quot;) SLURM users may be able to invoke srun and dispense with shell.sh altogether, though success may vary depending on the SLURM system. You will probably also need to set resource allocation parameters governing memory, runtime, etc. See man srun for the possible .SHELLFLAGS. make( my_plan, parallelism = &quot;Makefile&quot;, jobs = 2, prepend = c( &quot;SHELL=srun&quot;, &quot;.SHELLFLAGS=-N1 -n1 bash -c&quot; ) ) 10.6 Scheduling algorithms 10.6.1 Persistent scheduling Backends “mclapply”, “parLapply”, and “future_lapply” launch persistent workers. make(my_plan, parallelism = &quot;mclapply&quot;, jobs = 2) make(my_plan, parallelism = &quot;parLapply&quot;, jobs = 2) future::plan(future::multisession) make(my_plan, parallelism = &quot;future_lapply&quot;, jobs = 2) In each of these calls to make(), three processes launch: two workers and one master. Whenever a worker is idle, the master assigns it the next available target (whose dependencies have been built). The workers keep running until there are no more targets to build. The following video demonstrates the concept. For staged scheduling, you can micromanage which workers can run which targets. This column can be an integer vector or a list of integer vectors. Simply set an optional workers column in your drake_plan(). Why would you wish to do this? Consider the mtcars example. load_mtcars_example() my_plan$workers &lt;- 1 my_plan$workers[grepl(&quot;large&quot;, my_plan$target)] &lt;- 2 my_plan ## # A tibble: 15 x 3 ## target command workers ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 &quot;&quot; &quot;knit(knitr_in(\\&quot;report.Rmd\\&quot;), file_ou… 1 ## 2 small simulate(48) 1 ## 3 large simulate(64) 2 ## 4 regression1_small reg1(small) 1 ## 5 regression1_large reg1(large) 2 ## 6 regression2_small reg2(small) 1 ## 7 regression2_large reg2(large) 2 ## 8 summ_regression1_small suppressWarnings(summary(regression1_sm… 1 ## 9 summ_regression1_large suppressWarnings(summary(regression1_la… 2 ## 10 summ_regression2_small suppressWarnings(summary(regression2_sm… 1 ## 11 summ_regression2_large suppressWarnings(summary(regression2_la… 2 ## 12 coef_regression1_small suppressWarnings(summary(regression1_sm… 1 ## 13 coef_regression1_large suppressWarnings(summary(regression1_la… 2 ## 14 coef_regression2_small suppressWarnings(summary(regression2_sm… 1 ## 15 coef_regression2_large suppressWarnings(summary(regression2_la… 2 Here, one of the workers is in charge of all the targets that have to do with the large dataset. That way, we do not need other workers to read large from disk. If reads from disk take a long time, this could speed up your workflow. On the other hand, delegating all the large targets to worker 2 could prevent worker 1 from sharing the computational load, which could slow things down. Ultimately, you as the user need to make these tradeoffs. Also, the workers column only applies to the persistent scheduling backends. Similarly, you can set an optional priority column for your drake_plan(). plan &lt;- drake_plan(A = build(), B = stuff()) plan$priority &lt;- c(1, 2) plan ## # A tibble: 2 x 3 ## target command priority ## * &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 A build() 1 ## 2 B stuff() 2 Because of the priority column, if targets A and B are both ready to build, then A will be assigned to a worker first. Custom priorities apply to the staged scheduling backends, plus the &quot;future&quot; backend. The predict_runtime() and predict_load_balancing() functions emulate persistent workers, and the predictions also apply to transient workers. See the timing guide for a demonstration. These functions also respond to the workers column. 10.6.2 Transient scheduling Persistent workers are great because they minimize overhead: all the workers are created at the beginning, and then you never have to create any more for the rest of the runthrough. Unfortunately, computing clusters usually limit the amount of time each worker can stay running. That is why drake also supports transient workers in backends &quot;future&quot; and &quot;Makefile&quot;. Here, the master process creates a new worker for each target individually, and the worker dies after it finishes its single target. For the &quot;future&quot; backend, the master is just the existing process calling make(). The following video demonstrates the concept. future::plan(future::multisession) make(my_plan, parallelism = &quot;future&quot;, jobs = 2) make(my_plan, parallelism = &quot;Makefile&quot;, jobs = 2) 10.6.3 Staged scheduling Backends &quot;mclapply_staged&quot; and &quot;parLapply_staged&quot; support staged scheduling. make(my_plan, parallelism = &quot;mclapply_staged&quot;, jobs = 2) make(my_plan, parallelism = &quot;parLapply_staged&quot;, jobs = 2) Here, the dependency network is divided into separate stages of conditionally independent targets. Within each stage, drake uses mclapply() or parLapply() to process the targets in parallel. Stages run one after the other, so the slowest target in the current stage needs to complete before the next stage begins. So we lose a lot of parallel efficiency. The following video demonstrates the major drawback.[1] However, because there is no formal master process in each stage, overhead is extremely low. This lack of overhead can make staged parallelism a great choice for projects with a small number of large stages: tall dependency graphs with most of the work in the tallest stages. library(dplyr) library(drake) N &lt;- 500 gen_data &lt;- function() { tibble(a = seq_len(N), b = 1, c = 2, d = 3) } plan_data &lt;- drake_plan( data = gen_data() ) plan_sub &lt;- gen_data() %&gt;% transmute( target = paste0(&quot;data&quot;, a), command = paste0(&quot;data[&quot;, a, &quot;, ]&quot;) ) plan &lt;- bind_rows(plan_data, plan_sub) plan ## # A tibble: 501 x 2 ## target command ## &lt;chr&gt; &lt;chr&gt; ## 1 data gen_data() ## 2 data1 data[1, ] ## 3 data2 data[2, ] ## 4 data3 data[3, ] ## 5 data4 data[4, ] ## 6 data5 data[5, ] ## 7 data6 data[6, ] ## 8 data7 data[7, ] ## 9 data8 data[8, ] ## 10 data9 data[9, ] ## # ... with 491 more rows config &lt;- drake_config(plan) vis_drake_graph(config) 10.7 Final thoughts 10.7.1 Debugging For large workflows, downsizing and debugging tools become super important. See the guide to debugging and testing drake projects for help on diagnosing problems with a workflow. Triggers and cached error logs especially speed the development and testing process. 10.7.2 Drake as an ordinary job scheduler If you do not care about reproducibility and you want drake to be an ordinary job scheduler, consider using alternative triggers (see ?triggers). load_mtcars_example() make(my_plan, trigger = &quot;missing&quot;) # Also consider &quot;always&quot;. Above, drake only builds the missing targets. This skips much of the time-consuming hashing that ordinarily detects which targets are out of date. 10.7.3 More resources See the timing guide for explanations of functions predict_runtime() and predict_load_balancing(), which can help you plan and strategize deployment. 10.8 Footnotes [1] The video of staged parallelism is an oversimplification. It holds mostly true for make(parallelism = &quot;parLapply_staged&quot;), but make(parallelism = &quot;mclapply_staged&quot;) is a bit different. In the former case, each stage is a call to parLapply(), which recycles existing workers on a pre-built parallel socket (PSOCK) cluster. But in the latter, every stage is a new call to mclapply(), which launches a brand new batch of workers. In that sense, workers in make(parallelism = &quot;parLapply_staged&quot;) are sort of persistent, and workers in make(parallelism = &quot;mclapply_staged&quot;) are sort of transient for some projects. "],
["time.html", "Chapter 11 Time: logging, prediction, and strategy 11.1 Predict total runtime 11.2 Strategize your high-performance computing", " Chapter 11 Time: logging, prediction, and strategy Thanks to Jasper Clarkberg, drake records how long it takes to build each target. For large projects that take hours or days to run, this feature becomes important for planning and execution. library(drake) load_mtcars_example() # Get the code with drake_example(&quot;mtcars&quot;). make(my_plan, jobs = 2) build_times(digits = 8) # From the cache. ## # A tibble: 28 x 5 ## item type elapsed user system ## * &lt;chr&gt; &lt;chr&gt; &lt;S4: Duration&gt; &lt;S4: Duration&gt; &lt;S4: Durat&gt; ## 1 &quot;\\&quot;report.md\\&quot;&quot; target 0.112s 0.08s 0.004s ## 2 &quot;\\&quot;report.Rmd\\&quot;&quot; import 0.003s 0s 0.004s ## 3 coef_regression1_large target 0.009s 0.008s 0s ## 4 coef_regression1_small target 0.007s 0.008s 0s ## 5 coef_regression2_large target 0.007s 0.008s 0s ## 6 coef_regression2_small target 0.007s 0.008s 0s ## 7 data.frame import 0.048s 0.044s 0.004s ## 8 knit import 0.119s 0.06s 0.004s ## 9 large target 0.012s 0.008s 0s ## 10 lm import 0.022s 0.016s 0.008s ## # ... with 18 more rows ## `dplyr`-style `tidyselect` commands build_times(starts_with(&quot;coef&quot;), digits = 8) ## # A tibble: 4 x 5 ## item type elapsed user system ## * &lt;chr&gt; &lt;chr&gt; &lt;S4: Duration&gt; &lt;S4: Duration&gt; &lt;S4: Durati&gt; ## 1 coef_regression1_large target 0.009s 0.008s 0s ## 2 coef_regression1_small target 0.007s 0.008s 0s ## 3 coef_regression2_large target 0.007s 0.008s 0s ## 4 coef_regression2_small target 0.007s 0.008s 0s build_times(digits = 8, targets_only = TRUE) ## # A tibble: 15 x 5 ## item type elapsed user system ## * &lt;chr&gt; &lt;chr&gt; &lt;S4: Duration&gt; &lt;S4: Duration&gt; &lt;S4: Durat&gt; ## 1 &quot;\\&quot;report.md\\&quot;&quot; target 0.112s 0.08s 0.004s ## 2 coef_regression1_large target 0.009s 0.008s 0s ## 3 coef_regression1_small target 0.007s 0.008s 0s ## 4 coef_regression2_large target 0.007s 0.008s 0s ## 5 coef_regression2_small target 0.007s 0.008s 0s ## 6 large target 0.012s 0.008s 0s ## 7 regression1_large target 0.013s 0.012s 0s ## 8 regression1_small target 0.008s 0.008s 0s ## 9 regression2_large target 0.01s 0.008s 0s ## 10 regression2_small target 0.008s 0.008s 0s ## 11 small target 0.008s 0.008s 0s ## 12 summ_regression1_large target 0.014s 0.004s 0s ## 13 summ_regression1_small target 0.008s 0.008s 0s ## 14 summ_regression2_large target 0.007s 0.008s 0s ## 15 summ_regression2_small target 0.007s 0.008s 0s For drake version 4.1.0 and earlier, build_times() just measures the elapsed runtime of each command in my_plan$command. For later versions, the build times also account for all the internal operations in drake:::build(), such as storage and hashing. 11.1 Predict total runtime Drake uses these times to predict the runtime of the next make(). At this moment, everything is up to date in the current example, so the next make() should be fast. Here, we only factor in the times of the formal targets in the workflow plan, excluding any imports. config &lt;- drake_config(my_plan, verbose = FALSE) predict_runtime(config, targets_only = TRUE) ## [1] &quot;0.237s&quot; Suppose we change a dependency to make some targets out of date. Now, even though, the next make() should take a little longer. reg2 &lt;- function(d){ d$x3 &lt;- d$x ^ 3 lm(y ~ x3, data = d) } predict_runtime(config, targets_only = TRUE) ## [1] &quot;0.237s&quot; But what if you plan on starting from scratch next time, either after clean() or with make(..., trigger = &quot;always&quot;)? predict_runtime(config, from_scratch = TRUE, targets_only = TRUE) ## [1] &quot;0.237s&quot; 11.2 Strategize your high-performance computing Let’s say you are scaling up your workflow. You just put bigger data and heavier computation in your custom code, and the next time you run make(), your targets will take much longer to build. In fact, you estimate that every target except for your R Markdown report will take two hours to complete. Let’s write down these known times in seconds. known_times &lt;- c(5, rep(7200, nrow(my_plan) - 1)) names(known_times) &lt;- c(file_store(&quot;report.md&quot;), my_plan$target[-1]) known_times ## &quot;report.md&quot; small large ## 5 7200 7200 ## regression1_small regression1_large regression2_small ## 7200 7200 7200 ## regression2_large summ_regression1_small summ_regression1_large ## 7200 7200 7200 ## summ_regression2_small summ_regression2_large coef_regression1_small ## 7200 7200 7200 ## coef_regression1_large coef_regression2_small coef_regression2_large ## 7200 7200 7200 How many parallel jobs should you use in the next make()? The predict_runtime() function can help you decide. predict_runtime(jobs = n) simulates persistent parallel workers and reports the estimated total runtime of make(jobs = n). (See also predict_load_balancing().) time &lt;- c() for (jobs in 1:12){ time[jobs] &lt;- predict_runtime( config, jobs = jobs, from_scratch = TRUE, known_times = known_times ) } library(ggplot2) ggplot(data.frame(time = time / 3600, jobs = ordered(1:12), group = 1)) + geom_line(aes(x = jobs, y = time, group = group)) + scale_y_continuous(breaks = 0:10 * 4, limits = c(0, 29)) + theme_gray(16) + xlab(&quot;jobs argument of make()&quot;) + ylab(&quot;Predicted runtime of make() (hours)&quot;) We see serious potential speed gains up to 4 jobs, but beyond that point, we have to double the jobs to shave off another 2 hours. Your choice of jobs for make() ultimately depends on the runtime you can tolerate and the computing resources at your disposal. A final note on predicting runtime: the output of predict_runtime() and predict_load_balancing() also depends the optional workers column of your drake_plan(). If you micromanage which workers are allowed to build which targets, you may minimize reads from disk, but you could also slow down your workflow if you are not careful. See the high-performance computing guide for more. "],
["store.html", "Chapter 12 Storage 12.1 Caches 12.2 Hash algorithms 12.3 Which hash algorithm should you choose? 12.4 Select the hash algorithms of the cache 12.5 Using storr directly 12.6 Cleaning up", " Chapter 12 Storage Drake’s make() function generates your project’s output, and drake takes storing this output seriously. This guide explains how drake caches and hashes its data, and describes customization options that can increase convenience and speed. 12.1 Caches When you run make(), drake stores your imports and targets in a hidden cache. library(drake) load_mtcars_example(verbose = FALSE) # Get the code with drake_example(&quot;mtcars&quot;). ## Error in load_mtcars_example(verbose = FALSE): unused argument (verbose = FALSE) config &lt;- make(my_plan) ## Warning: knitr/rmarkdown report &#39;report.Rmd&#39; does not exist and cannot be ## inspected for dependencies. ## Warning: knitr/rmarkdown report &#39;report.Rmd&#39; does not exist and cannot be ## inspected for dependencies. ## Warning: missing input files: ## report.Rmd ## Warning: File &quot;report.Rmd&quot; was built or processed, ## but the file itself does not exist. ## target file &quot;report.md&quot; ## Warning in readLines(if (is.character(input2)) {: cannot open file ## &#39;report.Rmd&#39;: No such file or directory ## Warning: File &quot;report.md&quot; was built or processed, ## but the file itself does not exist. ## Warning: target &quot;report.md&quot; warnings: ## cannot open file &#39;report.Rmd&#39;: No such file or directory ## fail &quot;report.md&quot; ## Error: Target `&quot;report.md&quot;` failed. Call `diagnose(&quot;report.md&quot;)` for details. Error message: ## cannot open the connection You can explore your cached data using functions loadd(), readd(), cached(), and others. head(cached()) ## [1] &quot;\\&quot;report.Rmd\\&quot;&quot; &quot;data.frame&quot; &quot;knit&quot; &quot;lm&quot; ## [5] &quot;mtcars&quot; &quot;nrow&quot; head(readd(small)) ## Error: key &#39;small&#39; (&#39;objects&#39;) not found loadd(large) head(large) ## Error in head(large): object &#39;large&#39; not found rm(large) # Does not remove `large` from the cache. ## Warning in rm(large): object &#39;large&#39; not found By default, these objects live in a hidden .drake folder in your working directory. find_cache() ### [1] &quot;/home/you/project/.drake&quot; find_project() ### [1] &quot;/home/you/project&quot; Drake (via storr) has an object-like interface to these caches. cache &lt;- get_cache() cache$list() ## [1] &quot;\\&quot;report.Rmd\\&quot;&quot; &quot;data.frame&quot; &quot;knit&quot; ## [4] &quot;lm&quot; &quot;mtcars&quot; &quot;nrow&quot; ## [7] &quot;random_rows&quot; &quot;reg1&quot; &quot;reg2&quot; ## [10] &quot;sample.int&quot; &quot;summary&quot; &quot;suppressWarnings&quot; head(cache$get(&quot;small&quot;)) ## Error: key &#39;small&#39; (&#39;objects&#39;) not found tail(cache$get(&quot;small&quot;, namespace = &quot;meta&quot;)) ## Error: key &#39;small&#39; (&#39;meta&#39;) not found cache$list_namespaces() ## [1] &quot;common&quot; &quot;config&quot; &quot;kernels&quot; &quot;meta&quot; &quot;objects&quot; &quot;progress&quot; ## [7] &quot;session&quot; Create a new cache of your own with new_cache(). cache2 &lt;- new_cache(path = &quot;cache2&quot;) file.exists(&quot;cache2&quot;) ## [1] TRUE You can use multiple caches simultaneously, default and non-default alike. config &lt;- drake_config(cache = cache) ## Warning: knitr/rmarkdown report &#39;report.Rmd&#39; does not exist and cannot be ## inspected for dependencies. ## Warning: knitr/rmarkdown report &#39;report.Rmd&#39; does not exist and cannot be ## inspected for dependencies. config2 &lt;- drake_config(cache = cache2) ## Warning: knitr/rmarkdown report &#39;report.Rmd&#39; does not exist and cannot be ## inspected for dependencies. ## Warning: knitr/rmarkdown report &#39;report.Rmd&#39; does not exist and cannot be ## inspected for dependencies. outdated(config) ## Warning: File &quot;report.Rmd&quot; was built or processed, ## but the file itself does not exist. ## [1] &quot;\\&quot;report.md\\&quot;&quot; &quot;coef_regression1_large&quot; ## [3] &quot;coef_regression1_small&quot; &quot;coef_regression2_large&quot; ## [5] &quot;coef_regression2_small&quot; &quot;large&quot; ## [7] &quot;regression1_large&quot; &quot;regression1_small&quot; ## [9] &quot;regression2_large&quot; &quot;regression2_small&quot; ## [11] &quot;small&quot; &quot;summ_regression1_large&quot; ## [13] &quot;summ_regression1_small&quot; &quot;summ_regression2_large&quot; ## [15] &quot;summ_regression2_small&quot; outdated(config2) ## Warning: File &quot;report.Rmd&quot; was built or processed, ## but the file itself does not exist. ## [1] &quot;\\&quot;report.md\\&quot;&quot; &quot;coef_regression1_large&quot; ## [3] &quot;coef_regression1_small&quot; &quot;coef_regression2_large&quot; ## [5] &quot;coef_regression2_small&quot; &quot;large&quot; ## [7] &quot;regression1_large&quot; &quot;regression1_small&quot; ## [9] &quot;regression2_large&quot; &quot;regression2_small&quot; ## [11] &quot;small&quot; &quot;summ_regression1_large&quot; ## [13] &quot;summ_regression1_small&quot; &quot;summ_regression2_large&quot; ## [15] &quot;summ_regression2_small&quot; make(my_plan, cache = cache) ## Warning: knitr/rmarkdown report &#39;report.Rmd&#39; does not exist and cannot be ## inspected for dependencies. ## Warning: knitr/rmarkdown report &#39;report.Rmd&#39; does not exist and cannot be ## inspected for dependencies. ## Warning: missing input files: ## report.Rmd ## Warning: File &quot;report.Rmd&quot; was built or processed, ## but the file itself does not exist. ## target file &quot;report.md&quot; ## Warning in readLines(if (is.character(input2)) {: cannot open file ## &#39;report.Rmd&#39;: No such file or directory ## Warning: File &quot;report.md&quot; was built or processed, ## but the file itself does not exist. ## Warning: target &quot;report.md&quot; warnings: ## cannot open file &#39;report.Rmd&#39;: No such file or directory ## fail &quot;report.md&quot; ## Error: Target `&quot;report.md&quot;` failed. Call `diagnose(&quot;report.md&quot;)` for details. Error message: ## cannot open the connection make(my_plan, cache = cache2) ## Warning: knitr/rmarkdown report &#39;report.Rmd&#39; does not exist and cannot be ## inspected for dependencies. ## Warning: knitr/rmarkdown report &#39;report.Rmd&#39; does not exist and cannot be ## inspected for dependencies. ## Warning: missing input files: ## report.Rmd ## Warning: File &quot;report.Rmd&quot; was built or processed, ## but the file itself does not exist. ## target file &quot;report.md&quot; ## Warning in readLines(if (is.character(input2)) {: cannot open file ## &#39;report.Rmd&#39;: No such file or directory ## Warning: File &quot;report.md&quot; was built or processed, ## but the file itself does not exist. ## Warning: target &quot;report.md&quot; warnings: ## cannot open file &#39;report.Rmd&#39;: No such file or directory ## fail &quot;report.md&quot; ## Error: Target `&quot;report.md&quot;` failed. Call `diagnose(&quot;report.md&quot;)` for details. Error message: ## cannot open the connection There are a couple different ways to retrieve caches. get_cache(path = &quot;my_path&quot;) assumes my_path is a project root containing a .drake folder. If it does not find a .drake folder in my_path, it searches up through the ancestors of my_path until it finds one. this_cache(path = &quot;my_path&quot;) literally assumes my_path is the path to the cache, .drake folder or not. storr::storr_rds(&quot;my_path&quot;, mangle_key = TRUE) is analogous to this_cache(path = &quot;my_path&quot;). cache3 &lt;- get_cache(path = getwd()) # Finds the .drake folder in your directory. head(cache3$list()) ## [1] &quot;\\&quot;report.Rmd\\&quot;&quot; &quot;data.frame&quot; &quot;knit&quot; &quot;lm&quot; ## [5] &quot;mtcars&quot; &quot;nrow&quot; cache4 &lt;- this_cache(path = &quot;cache2&quot;) # The cache folder is literally called cache2. head(cache4$list()) ## [1] &quot;\\&quot;report.Rmd\\&quot;&quot; &quot;data.frame&quot; &quot;knit&quot; &quot;lm&quot; ## [5] &quot;mtcars&quot; &quot;nrow&quot; Destroy caches to remove them from your file system. cache4$destroy() cache2$list() # Same folder as cache4. ## character(0) See storr for more on drake’s caching infrastructure. 12.2 Hash algorithms The concept of hashing is central to storr’s internals. Storr uses hashes to label stored objects, and drake leverages these hashes to figure out which targets are up to date and which ones are outdated. A hash is like a target’s fingerprint, so the hash changes when the target changes. Regardless of the target’s size, the hash is always the same number of characters. library(digest) # package for hashing objects and files smaller_data &lt;- 12 larger_data &lt;- rnorm(1000) digest(smaller_data) # compute the hash ## [1] &quot;23c80a31c0713176016e6e18d76a5f31&quot; digest(larger_data) ## [1] &quot;b03c1a142bc71a1b8afed7d23ce60f9f&quot; However, different hash algorithms vary in length. digest(larger_data, algo = &quot;sha512&quot;) ## [1] &quot;cca91831466b966d82ae4440dea3be3a1b5555f6189563eb3d8b1a83c8c70d68daae9a35f62a00a96fefa241a26ce5c183a7f8a8d584bbbe023acb4b254080e9&quot; digest(larger_data, algo = &quot;md5&quot;) ## [1] &quot;b03c1a142bc71a1b8afed7d23ce60f9f&quot; digest(larger_data, algo = &quot;xxhash64&quot;) ## [1] &quot;ec927d1d9050ae96&quot; digest(larger_data, algo = &quot;murmur32&quot;) ## [1] &quot;6faecd4e&quot; 12.3 Which hash algorithm should you choose? Hashing is expensive, and unsurprisingly, shorter hashes are usually faster to compute. So why not always use murmur32? One reason is the risk of collisions: that is, when two different objects have the same hash. In general, shorter hashes have more frequent collisions. On the other hand, a longer hash is not always the answer. Besides the loss of speed, drake and storr sometimes use hash keys as file names, and long hashes could violate the 260-character cap on Windows file paths. That is why drake uses a shorter hash algorithm for internal cache-related file names and a longer hash algorithm for everything else. default_short_hash_algo() ## [1] &quot;xxhash64&quot; default_long_hash_algo() ## [1] &quot;sha256&quot; short_hash(cache) ## [1] &quot;xxhash64&quot; long_hash(cache) ## [1] &quot;sha256&quot; 12.4 Select the hash algorithms of the cache If you want to set the hash algorithms, do so right when the cache is first created. ## cache_path(cache) # Default cache from before. # nolint ## Start from scratch to reset both hash algorithms. clean(destroy = TRUE) tmp &lt;- new_cache( path = default_cache_path(), # The `.drake/` folder. short_hash_algo = &quot;crc32&quot;, long_hash_algo = &quot;sha1&quot; ) config &lt;- make(my_plan, verbose = FALSE) ## Warning: knitr/rmarkdown report &#39;report.Rmd&#39; does not exist and cannot be ## inspected for dependencies. ## Warning: knitr/rmarkdown report &#39;report.Rmd&#39; does not exist and cannot be ## inspected for dependencies. ## Warning: missing input files: ## report.Rmd ## Warning: File &quot;report.Rmd&quot; was built or processed, ## but the file itself does not exist. ## Warning in readLines(if (is.character(input2)) {: cannot open file ## &#39;report.Rmd&#39;: No such file or directory ## Warning: File &quot;report.md&quot; was built or processed, ## but the file itself does not exist. ## Error: Target `&quot;report.md&quot;` failed. Call `diagnose(&quot;report.md&quot;)` for details. Error message: ## cannot open the connection short_hash(config$cache) # xxhash64 is the default_short_hash_algo() ## Warning: The storr-based cache actually uses xxhash64 for the short hash ## algorithm, but crc32 was also supplied. Reverting to xxhash64. ## [1] &quot;xxhash64&quot; long_hash(config$cache) # sha256 is the default_long_hash_algo() ## [1] &quot;sha1&quot; You can change the long hash algorithm without throwing away the cache, but your project will rebuild from scratch. As for the short hash, you are committed until you delete the cache and all its supporting files. outdated(config) # empty ## Warning: File &quot;report.Rmd&quot; was built or processed, ## but the file itself does not exist. ## [1] &quot;\\&quot;report.md\\&quot;&quot; &quot;coef_regression1_large&quot; ## [3] &quot;coef_regression1_small&quot; &quot;coef_regression2_large&quot; ## [5] &quot;coef_regression2_small&quot; &quot;large&quot; ## [7] &quot;regression1_large&quot; &quot;regression1_small&quot; ## [9] &quot;regression2_large&quot; &quot;regression2_small&quot; ## [11] &quot;small&quot; &quot;summ_regression1_large&quot; ## [13] &quot;summ_regression1_small&quot; &quot;summ_regression2_large&quot; ## [15] &quot;summ_regression2_small&quot; config$cache &lt;- configure_cache( config$cache, long_hash_algo = &quot;murmur32&quot;, overwrite_hash_algos = TRUE ) Below, the targets become outdated because the existing hash keys do not match the new hash algorithm. config &lt;- drake_config(my_plan, verbose = FALSE, cache = config$cache) ## Warning: knitr/rmarkdown report &#39;report.Rmd&#39; does not exist and cannot be ## inspected for dependencies. ## Warning: knitr/rmarkdown report &#39;report.Rmd&#39; does not exist and cannot be ## inspected for dependencies. outdated(config) ## Warning: File &quot;report.Rmd&quot; was built or processed, ## but the file itself does not exist. ## [1] &quot;\\&quot;report.md\\&quot;&quot; &quot;coef_regression1_large&quot; ## [3] &quot;coef_regression1_small&quot; &quot;coef_regression2_large&quot; ## [5] &quot;coef_regression2_small&quot; &quot;large&quot; ## [7] &quot;regression1_large&quot; &quot;regression1_small&quot; ## [9] &quot;regression2_large&quot; &quot;regression2_small&quot; ## [11] &quot;small&quot; &quot;summ_regression1_large&quot; ## [13] &quot;summ_regression1_small&quot; &quot;summ_regression2_large&quot; ## [15] &quot;summ_regression2_small&quot; config &lt;- make(my_plan, verbose = FALSE) ## Warning: knitr/rmarkdown report &#39;report.Rmd&#39; does not exist and cannot be ## inspected for dependencies. ## Error: hash &#39;989f3eade99b7b1b&#39; not found short_hash(config$cache) # same as before ## [1] &quot;xxhash64&quot; long_hash(config$cache) # different from before ## [1] &quot;murmur32&quot; 12.5 Using storr directly If you want bypass drake and generate a cache directly from storr, it is best to do so right from the beginning. library(storr) my_storr &lt;- storr_rds(&quot;my_storr&quot;, mangle_key = TRUE) new_plan &lt;- drake_plan(simple = sqrt(4)) make(new_plan, cache = my_storr) ## target simple cached(cache = my_storr) ## [1] &quot;simple&quot; &quot;sqrt&quot; readd(simple, cache = my_storr) ## [1] 2 In addition to storr_rds(), drake supports in-memory caches created from storr_environment(). However, parallel computing is not supported these caches. The jobs argument must be 1, and the parallelism argument must be either &quot;mclapply&quot; or &quot;parLapply&quot;. (It is sufficient to leave the default values alone.) memory_cache &lt;- storr_environment() other_plan &lt;- drake_plan( some_data = rnorm(50), more_data = rpois(75, lambda = 10), result = mean(c(some_data, more_data)) ) make(other_plan, cache = memory_cache) ## target some_data ## target more_data ## target result cached(cache = memory_cache) ## [1] &quot;c&quot; &quot;mean&quot; &quot;more_data&quot; &quot;result&quot; &quot;rnorm&quot; &quot;rpois&quot; ## [7] &quot;some_data&quot; readd(result, cache = memory_cache) ## [1] 6.232917 In theory, it should be possible to leverage serious databases using storr_dbi(). However, if you use such caches, please heed the following. Be sure you have storr version 1.1.3 or greater installed. Be careful about parallel computing. For example the storr::storr_dbi() cache is not thread-safe. Either use no parallel computing at all or set parallelism = &quot;future&quot; with caching = &quot;master&quot;. The &quot;future&quot; backend is currently experimental, but it allows the master process to do all the caching in order to avoid race conditions. The following example requires the DBI and RSQLite packages. mydb &lt;- DBI::dbConnect(RSQLite::SQLite(), &quot;my-db.sqlite&quot;) cache &lt;- storr::storr_dbi( tbl_data = &quot;data&quot;, tbl_keys = &quot;keys&quot;, con = mydb ) load_mtcars_example() # Get the code with drake_example(&quot;mtcars&quot;). unlink(&quot;.drake&quot;, recursive = TRUE) make(my_plan, cache = cache) 12.6 Cleaning up If you want to start from scratch, you can clean() the cache. Use the destroy argument to remove it completely. cache$del() and cache$destroy() are also options, but they leave output file targets dangling. By contrast, clean(destroy = TRUE) removes file targets generated by drake::make(). drake_gc() and clean(..., garbage_collection = TRUE) do garbage collection, and clean(purge = TRUE) removes all target-level data, not just the final output values. clean(small, large) ## Error: hash &#39;989f3eade99b7b1b&#39; not found cached() # &#39;small&#39; and &#39;large&#39; are gone ## Error: hash &#39;989f3eade99b7b1b&#39; not found clean(destroy = TRUE) ## Error: hash &#39;989f3eade99b7b1b&#39; not found clean(destroy = TRUE, cache = my_storr) "],
["caution.html", "Chapter 13 Cautionary notes 13.1 Projects built with drake &lt;= 4.4.0 are not back compatible with drake &gt; 4.4.0. 13.2 Workflow plans 13.3 Execution 13.4 Dependencies 13.5 High-performance computing 13.6 Storage", " Chapter 13 Cautionary notes ## Error: hash &#39;989f3eade99b7b1b&#39; not found This chapter addresses drake’s known edge cases, pitfalls, and weaknesses that might not be fixed in future releases. For the most up-to-date information on unhandled edge cases, please visit the issue tracker, where you can submit your own bug reports as well. Be sure to search the closed issues too, especially if you are not using the most up-to-date development version of drake. For a guide to debugging and testing drake projects, please refer to the separate guide to debugging and testing drake projects. 13.1 Projects built with drake &lt;= 4.4.0 are not back compatible with drake &gt; 4.4.0. The cache internals changed between 4.4.0 and 5.0.0. Unfortunately, you will need to make() your project all over again. 13.2 Workflow plans 13.2.1 Externalizing commands in R script files It is common practice to divide the work of a project into multiple R files, but if you do this, you will not get the most out of drake. Please see the best practices chapter for more details. 13.2.2 Commands are NOT perfectly flexible. In your workflow plan data frame (produced by drake_plan() and accepted by make()), your commands can usually be flexible R expressions. drake_plan( target1 = 1 + 1 - sqrt(sqrt(3)), target2 = my_function(web_scraped_data) %&gt;% my_tidy ) ## # A tibble: 2 x 2 ## target command ## * &lt;chr&gt; &lt;chr&gt; ## 1 target1 1 + 1 - sqrt(sqrt(3)) ## 2 target2 my_function(web_scraped_data) %&gt;% my_tidy However, please try to avoid formulas and function definitions in your commands. You may be able to get away with drake_plan(f = function(x){x + 1}) or drake_plan(f = y ~ x) in some use cases, but be careful. It is generally to define functions and formulas in your workspace and then let make() import them. (Alternatively, use the envir argument to make() to tightly control which imported functions are available.) Use the check_plan() function to help screen and quality-control your workflow plan data frame, use tracked() to see the items that are reproducibly tracked, and use vis_drake_graph() and build_drake_graph() to see the dependency structure of your project. 13.3 Execution 13.3.1 Install drake properly. You must properly install drake using install.packages(), devtools::install_github(), or a similar approach. Functions like devtools::load_all() are insufficient, particularly for parallel computing functionality in which separate new R sessions try to require(drake). 13.3.2 Install all your packages. Your workflow may depend on external packages such as ggplot2, dplyr, and MASS. Such packages must be formally installed with install.packages(), devtools::install_github(), devtools::install_local(), or a similar command. If you load uninstalled packages with devtools::load_all(), results may be unpredictable and incorrect. 13.3.3 A note on tidy evaluation Running commands in your R console is not always exactly like running them with make(). That’s because make() uses tidy evaluation as implemented in the rlang package. ## This workflow plan uses rlang&#39;s quasiquotation operator `!!`. my_plan &lt;- drake_plan(list = c( little_b = &quot;\\&quot;b\\&quot;&quot;, letter = &quot;!!little_b&quot; )) my_plan ## # A tibble: 2 x 2 ## target command ## * &lt;chr&gt; &lt;chr&gt; ## 1 little_b &quot;\\&quot;b\\&quot;&quot; ## 2 letter !!little_b make(my_plan) ## Error: hash &#39;989f3eade99b7b1b&#39; not found readd(letter) ## Error: hash &#39;989f3eade99b7b1b&#39; not found For the commands you specify the free-form ... argument, drake_plan() also supports tidy evaluation. For example, it supports quasiquotation with the !! argument. Use tidy_evaluation = FALSE or the list argument to suppress this behavior. my_variable &lt;- 5 drake_plan( a = !!my_variable, b = !!my_variable + 1, list = c(d = &quot;!!my_variable&quot;) ) ## # A tibble: 3 x 2 ## target command ## * &lt;chr&gt; &lt;chr&gt; ## 1 a 5 ## 2 b 5 + 1 ## 3 d !!my_variable drake_plan( a = !!my_variable, b = !!my_variable + 1, list = c(d = &quot;!!my_variable&quot;), tidy_evaluation = FALSE ) ## # A tibble: 3 x 2 ## target command ## * &lt;chr&gt; &lt;chr&gt; ## 1 a !!my_variable ## 2 b !!my_variable + 1 ## 3 d !!my_variable For instances of !! that remain in the workflow plan, make() will run these commands in tidy fashion, evaluating the !! operator using the environment you provided. 13.3.4 Find and diagnose your errors. When make() fails, use failed() and diagnose() to debug. Try the following out yourself. ## Targets with available diagnostic metadata, incluing errors, warnings, etc. diagnose() ## Error: hash &#39;989f3eade99b7b1b&#39; not found f &lt;- function(){ stop(&quot;unusual error&quot;) } bad_plan &lt;- drake_plan(target = f()) withr::with_message_sink( stdout(), make(bad_plan) ) ## Error: hash &#39;989f3eade99b7b1b&#39; not found failed() # From the last make() only ## Error: hash &#39;989f3eade99b7b1b&#39; not found error &lt;- diagnose(target)$error # See also warnings and messages. ## Error: hash &#39;989f3eade99b7b1b&#39; not found error$message ## [1] &quot;`x` cannot be negative.&quot; error$call ## f(b) error$calls # View the traceback. ## [[1]] ## local({ ## f(b) ## }) ## ## [[2]] ## eval.parent(substitute(eval(quote(expr), envir))) ## ## [[3]] ## eval(expr, p) ## ## [[4]] ## eval(expr, p) ## ## [[5]] ## eval(quote({ ## f(b) ## }), new.env()) ## ## [[6]] ## eval(quote({ ## f(b) ## }), new.env()) ## ## [[7]] ## f(b) ## ## [[8]] ## stop(&quot;`x` cannot be negative.&quot;) 13.3.5 Refresh the drake_config() list early and often. The master configuration list returned by drake_config() is important to drake’s internals, and you will need it for functions like outdated() and vis_drake_graph(). The config list corresponds to a single call to make(), and you should not modify it by hand afterwards. For example, modifying the targets element post-hoc will have no effect because the graph element will remain the same. It is best to just call drake_config() again. 13.3.6 Workflows as R packages. The R package structure is a great way to organize the files of your project. Writing your own package to contain your data science workflow is a good idea, but you will need to Use expose_imports() to properly account for all your nested function dependencies, and If you load the package with devtools::load_all(), set the prework argument of make(): e.g. make(prework = &quot;devtools::load_all()&quot;). See the best practices guide and ?expose_imports for detailed explanations. Thanks to Jasper Clarkberg for the workaround. 13.3.7 The lazy_load flag does not work with &quot;parLapply&quot; parallelism. Ordinarily, drake prunes the execution environment at every parallelizable stage. In other words, it loads all the dependencies and unloads anything superfluous for entire batches of targets. This approach may require too much memory for some use cases, so there is an option to delay the loading of dependencies using the lazy_load argument to make() (powered by delayedAssign()). There are two major risks. make(..., lazy_load = TRUE, parallelism = &quot;parLapply&quot;, jobs = 2) does not work. If you want to use local multisession parallelism with multiple jobs and lazy loading, try &quot;future_lapply&quot; parallelism instead. library(future) future::plan(multisession) load_mtcars_example() # Get the code with drake_example(&quot;mtcars&quot;). make(my_plan, lazy_load = TRUE, parallelism = &quot;future_lapply&quot;) Delayed evaluation may cause the same dependencies to be loaded multiple times, and these duplicated loads could be slow. 13.3.8 Timeouts may be unreliable. You can call make(..., timeout = 10) to time out all each target after 10 seconds. However, timeouts rely on R.utils::withTimeout(), which in turn relies on setTimeLimit(). These functions are the best that R can offer right now, but they have known issues, and timeouts may fail to take effect for certain environments. 13.4 Dependencies 13.4.1 Objects that contain functions may trigger unwanted builds For example, an R6 class changes whenever a new R6 object of that class is created. library(digest) library(R6) circle_class &lt;- R6Class( &quot;circle_class&quot;, private = list(radius = NULL), public = list( initialize = function(radius){ private$radius &lt;- radius }, area = function(){ pi * private$radius ^ 2 } ) ) digest(circle_class) ## [1] &quot;5632fd5abd5c02455190ea075dc58562&quot; circle &lt;- circle_class$new(radius = 5) digest(circle_class) # example_class changed ## [1] &quot;df1449e1686799a35e804fd712a82e1f&quot; rm(circle) Ordinarily, drake overreacts to this change and builds targets repeatedly. clean() ## Error: hash &#39;989f3eade99b7b1b&#39; not found plan &lt;- drake_plan( circle = circle_class$new(radius = 10), area = circle$area() ) make(plan) # `circle_class` changes because it is referenced. ## Error: hash &#39;989f3eade99b7b1b&#39; not found make(plan) # Builds `circle` again because `circle_class` changed. ## Error: hash &#39;989f3eade99b7b1b&#39; not found The solution is to define your R6 class inside a function. drake does the right thing when it comes to tracking changes to functions. clean() ## Error: hash &#39;989f3eade99b7b1b&#39; not found new_circle &lt;- function(radius){ circle_class &lt;- R6Class( &quot;circle_class&quot;, private = list(radius = NULL), public = list( initialize = function(radius){ private$radius &lt;- radius }, area = function(){ pi * private$radius ^ 2 } ) ) circle_class$new(radius = radius) } plan &lt;- drake_plan( circle = new_circle(radius = 10), area = circle$area() ) make(plan) ## Error: hash &#39;989f3eade99b7b1b&#39; not found make(plan) ## Error: hash &#39;989f3eade99b7b1b&#39; not found 13.4.2 The magrittr dot (.) is always ignored. It is common practice to use a literal dot (.) to carry an object through a magrittr pipeline. Due to some tricky limitations in static code analysis, drake never treats the dot (.) as a dependency, even if you use it as an ordinary variable outside of a tidyverse context. deps_code(&quot;sqrt(x + y + .)&quot;) ## [1] &quot;sqrt&quot; &quot;x&quot; &quot;y&quot; deps_code(&quot;dplyr::filter(complete.cases(.))&quot;) ## [1] &quot;complete.cases&quot; &quot;dplyr::filter&quot; 13.4.3 Triggers and skipped imports With alternate triggers (see ?triggers) and the option in make() to skip imports, you can sacrifice reproducibility to gain speed. However, these options can throw the dependency network out of sync. You should only use them for testing and debugging. 13.4.4 Dependencies are not tracked in some edge cases. You should explicitly learn the items in your workflow and the dependencies of your targets. ?deps ?tracked ?vis_drake_graph Drake can be fooled into skipping objects that should be treated as dependencies. For example: f &lt;- function(){ b &lt;- get(&quot;x&quot;, envir = globalenv()) # x is incorrectly ignored digest::digest(file_dependency) } deps_code(f) ## [1] &quot;digest::digest&quot; &quot;file_dependency&quot; &quot;get&quot; &quot;globalenv&quot; command &lt;- &quot;x &lt;- digest::digest(file_in(\\&quot;input_file.rds\\&quot;)); assign(\\&quot;x\\&quot;, 1); x&quot; # nolint deps_code(command) ## [1] &quot;\\&quot;input_file.rds\\&quot;&quot; &quot;assign&quot; &quot;digest::digest&quot; Drake takes special precautions so that a target/import does not depend on itself. For example, deps_code(f) might return &quot;f&quot; if f() is a recursive function, but make() just ignores this conflict and runs as expected. In other words, make() automatically removes all self-referential loops in the dependency network. 13.4.5 Dependencies of knitr reports If you have knitr reports, you can use knitr_report() in your commands so that your reports are refreshed every time one of their dependencies changes. See drake_example(&quot;mtcars&quot;) and the ?knitr_in() help file examples for demonstrations. Dependencies are detected if you call loadd() or readd() in your code chunks. But beware: an empty call to loadd() does not account for any dependencies even though it loads all the available targets into your R session. 13.4.6 Knitr inputs and file outputs in imported functions. Similarly, file_out() in a command tells drake that the result of a command is an output file. Clearly, this is inappropriate for imported functions, but drake will look anyway. Do not try to use file_out() or knitr_in() inside your custom imported functions. Drake only pays attention to them in proper commands in your workflow plan data frame. However, file_in() is perfectly fine if your imported function needs a file in order to run. Here are some examples. ## toally_fine() will depend on the imported data.csv file. ## But make sure data.csv is an imported file and not a file target. totally_okay &lt;- function(x, y, z){ read.csv(file_in(&quot;data.csv&quot;)) } ## file_out() is for file targets, so `drake` will ignore it. avoid_this &lt;- function(x, y, z){ read.csv(file_out(&quot;data.csv&quot;)) } ## knitr_in() is for knitr files with dependencies ## in their active code chunks (explicitly referenced with loadd() and readd(). ## Drake just treats knitr_in() as an ordinary file input in this case. ## You should really be using file_in() instead. avoid_this &lt;- function(x, y, z){ read.csv(knitr_in(&quot;report.Rmd&quot;)) } 13.4.7 Functions produced by Vectorize() With functions produced by Vectorize(), detecting dependencies is especially hard because the body of every such function is args &lt;- lapply(as.list(match.call())[-1L], eval, parent.frame()) names &lt;- if (is.null(names(args))) character(length(args)) else names(args) dovec &lt;- names %in% vectorize.args do.call(&quot;mapply&quot;, c(FUN = FUN, args[dovec], MoreArgs = list(args[!dovec]), SIMPLIFY = SIMPLIFY, USE.NAMES = USE.NAMES)) Thus, if f is constructed with Vectorize(g, ...), drake searches g() for dependencies, not f(). In fact, if drake sees that environment(f)[[&quot;FUN&quot;]] exists and is a function, then environment(f)[[&quot;FUN&quot;]] will be analyzed instead of f(). Furthermore, if f() is the output of Vectorize(), then drake reproducibly tracks environment(f)[[&quot;FUN&quot;]] rather than f() itself. Thus, if the configuration settings of vectorization change (such as which arguments are vectorized), but the core element-wise functionality remains the same, then make() will not react. Also, if you hover over the f node in vis_drake_graph(hover = TRUE), then you will see the body of environment(f)[[&quot;FUN&quot;]], not the body of f(). 13.4.8 Compiled code is not reproducibly tracked. Some R functions use .Call() to run compiled code in the backend. The R code in these functions is tracked, but not the compiled object called with .Call(), nor its C/C++/Fortran source. 13.4.9 Directories (folders) are not reproducibly tracked. In your workflow plan, you can use file_in(), file_out(), and knitr_in() to assert that some targets/imports are external files. However, entire directories (i.e. folders) cannot be reproducibly tracked this way. Please see issue 12 for a discussion. 13.4.10 Packages are not tracked as dependencies. Drake may import functions from packages, but the packages themselves are not tracked as dependencies. For this, you will need other tools that support reproducibility beyond the scope of drake. Packrat creates a tightly-controlled local library of packages to extend the shelf life of your project. And with Docker, you can execute your project on a virtual machine to ensure platform independence. Together, packrat and Docker can help others reproduce your work even if they have different software and hardware. 13.5 High-performance computing 13.5.1 The practical utility of parallel computing Drake claims that it can Build and cache your targets in parallel (in stages). Build and cache your targets in the correct order, finishing dependencies before starting targets that depend on them. Deploy your targets to the parallel backend of your choice. However, the practical efficiency of the parallel computing functionality remains to be verified rigorously. Serious performance studies will be part of future work that has not yet been conducted at the time of writing. In addition, each project has its own best parallel computing set up, and the user needs to optimize it on a case-by-case basis. Some general considerations include the following. The high overhead and high scalability of distributed computing versus the low overhead and low scalability of local multicore computing. The high memory usage of local multicore computing, especially &quot;mclapply&quot; parallelism, as opposed to distributed computing, which can spread the memory demands over the available nodes on a cluster. The marginal gains of increasing the number of jobs indefinitely, especially in the case of local multicore computing if the number of cores is low. 13.5.2 Maximum number of simultaneous jobs Be mindful of the maximum number of simultaneous parallel jobs you deploy. At best, too many jobs is poor etiquette on a system with many users and limited resources. At worst, too many jobs will crash a system. The jobs argument to make() sets the maximum number of simultaneous jobs in most cases, but not all. For most of drake’s parallel backends, jobs sets the maximum number of simultaneous parallel jobs. However, there are ways to break the pattern. For example, make(..., parallelism = &quot;Makefile&quot;, jobs = 2, args = &quot;--jobs=4&quot;) uses at most 2 jobs for the imports and at most 4 jobs for the targets. (In make(), args overrides jobs for the targets). For make(..., parallelism = &quot;future_lapply&quot;), the jobs argument is ignored altogether. Instead, you should set the workers argument where it is available (for example, future::plan(mutlisession(workers = 2)) or future::plan(future.batchtools::batchtools_local(workers = 2))) in the preparations before make(). Alternatively, you might limit the max number of jobs by setting options(mc.cores = 2) before calling make(). Depending on the future backend you select with future::plan() or future::plan(), you might make use of one of the other environment variables listed in ?future::future.options. 13.5.3 Parallel computing on Windows On Windows, do not use make(..., parallelism = &quot;mclapply&quot;, jobs = n) with n greater than 1. You could try, but jobs will just be demoted to 1. Instead, please replace &quot;mclapply&quot; with one of the other parallelism_choices() or let drake choose the parallelism backend for you. For make(..., parallelism = &quot;Makefile&quot;), Windows users need to download and install Rtools. 13.5.4 Configuring future/batchtools parallelism for clusters The &quot;future_lapply&quot; backend unlocks a large array of distributed computing options on serious computing clusters. However, it is your responsibility to configure your workflow for your specific job scheduler. In particular, special batchtools *.tmpl configuration files are required, and the technique is described in the documentation of batchtools. You can find some examples of these files in the inst/templates folders of the batchtools and future.batchtools GitHub repositories. Drake has some built-in prepackaged example workflows. See drake_examples() to view your options, and then drake_example() to write the files for an example. drake_example(&quot;sge&quot;) # Sun/Univa Grid Engine workflow and supporting files drake_example(&quot;slurm&quot;) # SLURM drake_example(&quot;torque&quot;) # TORQUE To write just *.tmpl files from these examples, see the drake_batchtools_tmpl_file() function. Unfortunately, there is no one-size-fits-all *.tmpl configuration file for any job scheduler, so we cannot guarantee that the above examples will work for you out of the box. To learn how to configure the files to suit your needs, you should make sure you understand your job scheduler and batchtools. 13.5.5 Proper Makefiles are not standalone. The Makefile generated by make(myplan, parallelism = &quot;Makefile&quot;) is not standalone. Do not run it outside of drake::make(). Drake uses dummy timestamp files to tell the Makefile what to do, and running make in the terminal will most likely give incorrect results. 13.5.6 Makefile-level parallelism for imported objects and files Makefile-level parallelism is only used for targets in your workflow plan data frame, not imports. To process imported objects and files, drake selects the best local parallel backend for your system and uses the jobs argument to make(). To use at most 2 jobs for imports and at most 4 jobs for targets, run make(..., parallelism = &quot;Makefile&quot;, jobs = 2, args = &quot;--jobs=4&quot;) 13.5.7 Zombie processes Some parallel backends, particularly mclapply and future::multicore, may create zombie processes. Zombie children are not usually harmful, but you may wish to kill them yourself. The following function by Carl Boneri should work on Unix-like systems. For a discussion, see drake issue 116. fork_kill_zombies &lt;- function(){ require(inline) includes &lt;- &quot;#include &lt;sys/wait.h&gt;&quot; code &lt;- &quot;int wstat; while (waitpid(-1, &amp;wstat, WNOHANG) &gt; 0) {};&quot; wait &lt;- inline::cfunction( body = code, includes = includes, convention = &quot;.C&quot; ) invisible(wait()) } 13.6 Storage 13.6.1 Projects hosted on Dropbox and similar platforms If download a drake project from Dropbox, you may get an error like the one in issue 198: cache pathto/.drake connect 61 imports: ... connect 200 targets: ... Error in rawToChar(as.raw(x)) : embedded nul in string: 'initial_drake_version\\0\\0\\x9a\\x9d\\xdc\\0J\\xe9\\0\\0\\0(\\x9d\\xf9brם\\0\\xca)\\0\\0\\xb4\\xd7\\0\\0\\0\\0\\xb9' In addition: Warning message: In rawToChar(as.raw(x)) : out-of-range values treated as 0 in coercion to raw This is probably because Dropbox generates a bunch of “conflicted copy” files when file transfers do not go smoothly. This confuses storr, drake’s caching backend. keys/config/aG9vaw (Sandy Sum's conflicted copy 2018-01-31) keys/config/am9icw (Sandy Sum's conflicted copy 2018-01-31) keys/config/c2VlZA (Sandy Sum's conflicted copy 2018-01-31) Just remove these files using drake_gc() and proceed with your work. cache &lt;- get_cache() drake_gc(cache) 13.6.2 Cache customization is limited The storage guide describes how storage works in drake. As explained near the end of that chapter, you can plug custom storr caches into make(). However, non-RDS caches such as storr_dbi() may not work with most forms of parallel computing. The storr::storr_dbi() cache and many others are not thread-safe. Either use no parallel computing at all or set parallelism = &quot;future&quot; with caching = &quot;master&quot;. The &quot;future&quot; backend is currently experimental, but it allows the master process to do all the caching in order to avoid race conditions. 13.6.3 Runtime predictions In predict_runtime() and rate_limiting_times(), drake only accounts for the targets with logged build times. If some targets have not been timed, drake throws a warning and prints the untimed targets. ## Error: hash &#39;989f3eade99b7b1b&#39; not found "],
["faq.html", "Chapter 14 Frequently-asked questions", " Chapter 14 Frequently-asked questions This FAQ is a compendium of pedagogically useful issues tagged on GitHub. To contribute, please submit a new issue and ask that it be labeled a frequently asked question. Can you have multiple drake plans? Metaprogramming Difficulties (vignette potentially helpful) How to propagate wild cards into future steps How to speed up construction of a (very) large plan? evaluate file.path and variables in file_out and friends Working with HPC time limits How to debug file targets Gather without loading all dependencies at the same time Reproducibility with random numbers output file as target How should I mix non-R code (e.g. Python and shell scripts) in a large drake workflow? Helper function for creating file targets with multiple files Reproducible remote data sources Command that writes a file always runs Using strings as wildcards? Trouble with caches sent through Dropbox How to add .R files to drake_plan() Add an option to always build some selected targets (add an “always” trigger) evaluate_plan() with file targets "]
]
