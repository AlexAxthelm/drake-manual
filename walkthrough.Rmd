# Walkthrough {#walkthrough}

```{r setup_main, message = FALSE, warning = FALSE, echo = FALSE}
knitr::opts_knit$set(root.dir = fs::dir_create(tempfile()))
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.width = 6,
  fig.height = 6,
  fig.align = "center"
)
```

```{r setup_main2, message = FALSE, warning = FALSE, echo = FALSE}
library(drake)
library(dplyr)
library(ggplot2)
invisible(drake_example("main", overwrite = TRUE))
invisible(file.copy("main/raw_data.xlsx", ".", overwrite = TRUE))
invisible(file.copy("main/report.Rmd", ".", overwrite = TRUE))
```

A typical data analysis workflow is a sequence of data transformations. Raw data becomes tidy data, then turns into fitted models, summaries, and reports. Other analyses are usually variations of this pattern, and `drake` can easily accommodate them.

## Set the stage.

To set up a project, load your packages,

```{r mainpackages}
library(drake)
library(dplyr)
library(ggplot2)
```

load your custom functions,

```{r createplot1}
create_plot <- function(data) {
  ggplot(data, aes(x = Petal.Width, fill = Species)) +
    geom_histogram()
}
```

check any supporting files (optional),

```{r suppfiles}
## Get the files with drake_example("main").
file.exists("raw_data.xlsx")
file.exists("report.Rmd")
```

and plan what you are going to do.

```{r createplan}
plan <- drake_plan(
  raw_data = readxl::read_excel(file_in("raw_data.xlsx")),
  data = raw_data %>%
    mutate(Species = forcats::fct_inorder(Species)),
  hist = create_plot(data),
  fit = lm(Sepal.Width ~ Petal.Width + Species, data),
  report = rmarkdown::render(
    knitr_in("report.Rmd"),
    output_file = file_out("report.html"),
    quiet = TRUE
  )
)
plan
```

Optionally, visualize your workflow to make sure you set it up correctly. The graph is interactive, so you can click, drag, hover, zoom, and explore.

```{r 02visgraph}
config <- drake_config(plan)
vis_drake_graph(config)
```

## Make your results.

So far, we have just been setting the stage. Use `make()` to do the real work. Targets are built in the correct order regardless of the row order of `plan`.

```{r make1}
make(plan)
```

Except for output files like `report.html`, your output is stored in a hidden `.drake/` folder. Reading it back is easy.

```{r readddata1}
readd(data) %>% # See also loadd().
  head()
```

The graph shows everything up to date.

```{r 02visgraph2}
vis_drake_graph(config)
```

## Go back and fix things.

You may look back on your work and see room for improvement, but it's all good! The whole point of `drake` is to help you go back and change things quickly and painlessly. For example, we forgot to give our histogram a bin width.

```{r loaddhist}
readd(hist)
```

So let's fix the plotting function.

```{r changefn}
create_plot <- function(data) {
  ggplot(data, aes(x = Petal.Width, fill = Species)) +
    geom_histogram(binwidth = 0.25) +
    theme_gray(20)
}
```

`drake` knows which results are affected.

```{r intro-visdrakegraph}
vis_drake_graph(config)
```

The next `make()` just builds `hist` and `report`. No point in wasting time on the data or model.

```{r justhistetc}
make(plan)
```

```{r hist2}
loadd(hist)
hist
```

## History and provenance

As of version 7.5.0, `drake` tracks the history and provenance of your targets:
what you built, when you built it, how you built it, the arguments you
used in your function calls, and how to get the data back.

```{r history_walkthrough}
history <- drake_history(analyze = TRUE)
history
```

Remarks:

- The `quiet` column appears above because one of the `drake_plan()` commands has `knit(quiet = TRUE)`.
- The `hash` column identifies all the previous the versions of your targets. As long as `exists` is `TRUE`, you can recover old data.
- Advanced: if you use `make(cache_log_file = TRUE)` and put the cache log file under version control, you can match the hashes from `drake_history()` with the `git` commit history of your code.

Let's use the history to recover the oldest histogram.

```{r}
hash <- history %>%
  filter(target == "hist") %>%
  pull(hash) %>%
  head(n = 1)
cache <- drake_cache()
cache$get_value(hash)
```

## Automated recovery and renaming

Note: this feature is still experimental.

In `drake` version 7.5.0 and above, `make(recover = TRUE)` can salvage old targets from the distant past. This may not be a good idea if your external dependencies have changed a lot over time (R version, package environment, etc) but it can be useful under the right circumstances.

```{r}
# Is the data really gone?
clean() # garbage_collection = FALSE

# Nope!
make(plan, recover = TRUE) # The report still builds since report.md is gone.

# When was the raw data *really* first built?
diagnose(raw_data)$date
```

You can even rename your targets! All you have to do is use the same target seed as last time. Just be aware that renaming invalidates downstream targets.

```{r}
# Get the old seed.
old_seed <- diagnose(data)$seed

# Now rename the data and supply the old seed.
plan <- drake_plan(
  raw_data = readxl::read_excel(file_in("raw_data.xlsx")),
  
  # Previously just named "data".
  iris_data = target(
    raw_data %>%
      mutate(Species = forcats::fct_inorder(Species)),
    seed = !!old_seed
  ),

  # `iris_data` will be recovered from `data`,
  # but `hist` and `fit` have changed commands,
  # so they will build from scratch.
  hist = create_plot(iris_data),
  fit = lm(Sepal.Width ~ Petal.Width + Species, iris_data),
  report = rmarkdown::render(
    knitr_in("report.Rmd"),
    output_file = file_out("report.html"),
    quiet = TRUE
  )
)

make(plan, recover = TRUE)
```

## Try the code yourself!

Use `drake_example("main")` to download the [code files](#projects) for this example.

## Thanks

Thanks to [Kirill MÃ¼ller](https://github.com/krlmlr) for originally providing this example.
