[
["index.html", "The User Manual of the drake R Package Chapter 1 Installation", " The User Manual of the drake R Package Will Landau Chapter 1 Installation You can choose among different versions of drake. # Install the latest stable release from CRAN. install.packages(&quot;drake&quot;) # Alternatively, install the development version from GitHub. install.packages(&quot;devtools&quot;) library(devtools) install_github(&quot;ropensci/drake&quot;) You must properly install drake using install.packages(), devtools::install_github(), or similar. It is not enough to use devtools::load_all(), particularly for the parallel computing functionality, in which multiple R sessions initialize and then try to require(drake). For make(parallelism = &quot;Makefile&quot;), Windows users may need to download and install Rtools. To use make(parallelism = &quot;future&quot;) and make(parallelism = &quot;future_lapply&quot;) to deploy your work to a computing cluster (see the high-performance computing guide), you will need the future.batchtools package. "],
["intro.html", "Chapter 2 Introduction 2.1 Set the stage. 2.2 Make your results. 2.3 Go back and fix things. 2.4 Try it yourself!", " Chapter 2 Introduction A typical data analysis workflow is a sequence of data transformations. Raw data becomes tidy data, then turns into fitted models, summaries, and reports. 2.1 Set the stage. To set up a project, load your packages, library(drake) library(dplyr) library(ggplot2) load your custom functions, create_plot &lt;- function(data) { ggplot(data, aes(x = Petal.Width, fill = Species)) + geom_histogram() } check any supporting files (optional), ## Get the files with drake_example(&quot;main&quot;). file.exists(&quot;raw_data.xlsx&quot;) ## [1] TRUE file.exists(&quot;report.Rmd&quot;) ## [1] TRUE and plan what you are going to do. plan &lt;- drake_plan( raw_data = readxl::read_excel(file_in(&quot;raw_data.xlsx&quot;)), data = raw_data %&gt;% mutate(Species = forcats::fct_inorder(Species)) %&gt;% select(-X__1), hist = create_plot(data), fit = lm(Sepal.Width ~ Petal.Width + Species, data), rmarkdown::render( knitr_in(&quot;report.Rmd&quot;), output_file = file_out(&quot;report.html&quot;), quiet = TRUE ) ) plan ## # A tibble: 5 x 2 ## target command ## &lt;chr&gt; &lt;chr&gt; ## 1 raw_data &quot;readxl::read_excel(file_in(\\&quot;raw_data.xlsx\\&quot;))&quot; ## 2 data &quot;raw_data %&gt;% mutate(Species = forcats::fct_inorder(S… ## 3 hist create_plot(data) ## 4 fit lm(Sepal.Width ~ Petal.Width + Species, data) ## 5 &quot;\\&quot;report.html\\&quot;&quot; &quot;rmarkdown::render(knitr_in(\\&quot;report.Rmd\\&quot;), output_f… Optionally, visualize your workflow to make sure you set it up correctly. The graph is interactive, so you can click, drag, hover, zoom, and explore. config &lt;- drake_config(plan) vis_drake_graph(config) 2.2 Make your results. So far, we have just been setting the stage. Use make() to do the real work. Targets are built in the correct order regardless of the row order of plan. make(plan) ## target raw_data ## target data ## target fit ## target hist ## target file &quot;report.html&quot; Except for files like report.html, your output is stored in a hidden .drake/ folder. Reading it back is easy. readd(data) # See also loadd(). ## # A tibble: 150 x 5 ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa ## 5 5 3.6 1.4 0.2 setosa ## 6 5.4 3.9 1.7 0.4 setosa ## 7 4.6 3.4 1.4 0.3 setosa ## 8 5 3.4 1.5 0.2 setosa ## 9 4.4 2.9 1.4 0.2 setosa ## 10 4.9 3.1 1.5 0.1 setosa ## # ... with 140 more rows The graph shows everything up to date. vis_drake_graph(config) 2.3 Go back and fix things. You may look back on your work and see room for improvement, but it’s all good! The whole point of drake is to help you go back and change things quickly and painlessly. For example, we forgot to give our histogram a bin width. readd(hist) ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. So let’s fix the plotting function. create_plot &lt;- function(data) { ggplot(data, aes(x = Petal.Width, fill = Species)) + geom_histogram(binwidth = 0.25) + theme_gray(20) } Drake knows which results are affected. vis_drake_graph(config) The next make() just builds hist and report.html. No point in wasting time on the data or model. make(plan) ## target hist ## target file &quot;report.html&quot; loadd(hist) hist 2.4 Try it yourself! Use drake_example(&quot;main&quot;) to get all the materials. "],
["example-packages.html", "Chapter 3 Example: R package download trends 3.1 Get the code. 3.2 Overview 3.3 Analysis 3.4 What remote data sources in general?", " Chapter 3 Example: R package download trends This chapter explores R package download trends using the cranlogs package. 3.1 Get the code. Write the code files to your workspace. drake_example(&quot;packages&quot;) The new packages folder now includes a file structure of a serious drake project, plus an interactive-tutorial.R to narrate the example. The code is also online here. 3.2 Overview This small data analysis project explores some trends in R package downloads over time. The datasets are downloaded using the cranlogs package. library(cranlogs) cran_downloads(packages = &quot;dplyr&quot;, when = &quot;last-week&quot;) ## date count package ## 1 2018-06-11 17692 dplyr ## 2 2018-06-12 18702 dplyr ## 3 2018-06-13 17494 dplyr ## 4 2018-06-14 17273 dplyr ## 5 2018-06-15 14177 dplyr ## 6 2018-06-16 7187 dplyr ## 7 2018-06-17 6975 dplyr Above, each count is the number of times dplyr was downloaded from the RStudio CRAN mirror on the given day. To stay up to date with the latest download statistics, we need to refresh the data frequently. With drake, we can bring all our work up to date without restarting everything from scratch. 3.3 Analysis First, we load the required packages. Drake knows about the packages you install and load. library(cranlogs) library(drake) library(dplyr) library(ggplot2) library(knitr) We want to explore the daily downloads from these packages. package_list &lt;- c( &quot;knitr&quot;, &quot;Rcpp&quot;, &quot;ggplot2&quot; ) We plan to use the cranlogs package. The data frames older and recent will contain the number of daily downloads for each package from the RStudio CRAN mirror. data_plan &lt;- drake_plan( older = cran_downloads( packages = package_list, from = &quot;2016-11-01&quot;, to = &quot;2016-12-01&quot; ), recent = target( command = cran_downloads( packages = package_list, when = &quot;last-month&quot; ), trigger = &quot;always&quot; ), strings_in_dots = &quot;literals&quot; ) data_plan ## # A tibble: 2 x 3 ## target command trigger ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 older &quot;cran_downloads(packages = package_list, from = \\&quot;2016-1… any ## 2 recent &quot;cran_downloads(packages = package_list, when = \\&quot;last-m… always Our data_plan data frame has a &quot;trigger&quot; column because the latest download data needs to be refreshed every day. We use triggers to force recent to always build. For more on triggers, see the chapter on debugging and testing. Instead of triggers, we could have just made recent a global variable like package_list instead of a formal target in data_plan. We want to summarize each set of download statistics a couple different ways. output_types &lt;- drake_plan( averages = make_my_table(dataset__), plot = make_my_plot(dataset__) ) output_types ## # A tibble: 2 x 2 ## target command ## &lt;chr&gt; &lt;chr&gt; ## 1 averages make_my_table(dataset__) ## 2 plot make_my_plot(dataset__) We need to define functions to summarize and plot the data. make_my_table &lt;- function(downloads){ group_by(downloads, package) %&gt;% summarize(mean_downloads = mean(count)) } make_my_plot &lt;- function(downloads){ ggplot(downloads) + geom_line(aes(x = date, y = count, group = package, color = package)) } Below, the targets recent and older each take turns substituting the dataset__ wildcard. Thus, output_plan has four rows. output_plan &lt;- plan_analyses( plan = output_types, datasets = data_plan ) output_plan ## # A tibble: 4 x 2 ## target command ## &lt;chr&gt; &lt;chr&gt; ## 1 averages_older make_my_table(older) ## 2 averages_recent make_my_table(recent) ## 3 plot_older make_my_plot(older) ## 4 plot_recent make_my_plot(recent) We plan to weave the results together in a dynamic knitr report. report_plan &lt;- drake_plan( knit(knitr_in(&quot;report.Rmd&quot;), file_out(&quot;report.md&quot;), quiet = TRUE) ) report_plan ## # A tibble: 1 x 2 ## target command ## &lt;chr&gt; &lt;chr&gt; ## 1 &quot;\\&quot;report.md\\&quot;&quot; &quot;knit(knitr_in(\\&quot;report.Rmd\\&quot;), file_out(\\&quot;report.md\\&quot;)… Because of the mention of knitr_in() above, make() will look dependencies inside report.Rmd (targets mentioned with loadd() or readd() in active code chunks). That way, whenever a dependency changes, drake will rebuild report.md when you call make(). For that to happen, we need report.Rmd to exist before the call to make(). For this example, you can find report.Rmd here. Now, we complete the workflow plan data frame by concatenating the results together. Drake analyzes the plan to figure out the dependency network, so row order does not matter. whole_plan &lt;- bind_plans( data_plan, output_plan, report_plan ) whole_plan ## # A tibble: 7 x 3 ## target command trigger ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 older &quot;cran_downloads(packages = package_list, from =… any ## 2 recent &quot;cran_downloads(packages = package_list, when =… always ## 3 averages_older make_my_table(older) any ## 4 averages_recent make_my_table(recent) any ## 5 plot_older make_my_plot(older) any ## 6 plot_recent make_my_plot(recent) any ## 7 &quot;\\&quot;report.md\\&quot;&quot; &quot;knit(knitr_in(\\&quot;report.Rmd\\&quot;), file_out(\\&quot;repo… any Now, we run the project to download the data and analyze it. The results will be summarized in the knitted report, report.md, but you can also read the results directly from the cache. make(whole_plan) ## target older ## target recent: trigger &quot;always&quot; ## target averages_older ## target plot_older ## target averages_recent ## target plot_recent ## target file &quot;report.md&quot; ## Used non-default triggers. Some targets may not be up to date. readd(averages_recent) ## # A tibble: 3 x 2 ## package mean_downloads ## &lt;chr&gt; &lt;dbl&gt; ## 1 ggplot2 14326. ## 2 knitr 8969. ## 3 Rcpp 21724. readd(averages_older) ## # A tibble: 3 x 2 ## package mean_downloads ## &lt;chr&gt; &lt;dbl&gt; ## 1 ggplot2 14641. ## 2 knitr 9069. ## 3 Rcpp 14408. readd(plot_recent) readd(plot_older) Because we used triggers, each make() rebuilds the recent target to get the latest download numbers for today. If the newly-downloaded data are the same as last time and nothing else changes, drake skips all the other targets. make(whole_plan) ## target recent: trigger &quot;always&quot; ## Used non-default triggers. Some targets may not be up to date. To visualize the build behavior, plot the dependency network. Target recent and everything depending on it is always out of date because of the &quot;always&quot; trigger. If you rerun the project tomorrow, the recent dataset will have shifted one day forward, so make() will refresh averages_recent, plot_recent, and report.md. Targets averages_older and plot_older should be unaffected, so drake will skip them. config &lt;- drake_config(whole_plan) vis_drake_graph(config) 3.4 What remote data sources in general? When you rely on data from the internet, you should trigger a new download when the data change remotely. The best practices guide explains how to automatically refresh the data when the online timestamp changes. "],
["example-gsp.html", "Chapter 4 Example: gross state products 4.1 Get the code. 4.2 Objective and methods 4.3 Data 4.4 Analysis 4.5 Results 4.6 Comparison with GNU Make 4.7 References", " Chapter 4 Example: gross state products The following data analysis workflow shows off drake’s ability to generate lots of reproducibly-tracked tasks with ease. The same technique would be cumbersome, even intractable, with GNU Make. 4.1 Get the code. Write the code files to your workspace. drake_example(&quot;gsp&quot;) The new gsp folder now includes a file structure of a serious drake project, plus an interactive-tutorial.R to narrate the example. The code is also online here. 4.2 Objective and methods The goal is to search for factors closely associated with the productivity of states in the USA around the 1970s and 1980s. For the sake of simplicity, we use gross state product as a metric of productivity, and we restrict ourselves to multiple linear regression models with three variables. For each of the 84 possible models, we fit the data and then evaluate the root mean squared prediction error (RMSPE). \\[ \\begin{aligned} \\text{RMSPE} = \\sqrt{(\\text{y} - \\widehat{y})^T(y - \\widehat{y})} \\end{aligned} \\] Here, \\(y\\) is the vector of observed gross state products in the data, and \\(\\widehat{y}\\) is the vector of predicted gross state products under one of the models. We take the best variables to be the triplet in the model with the lowest RMSPE. 4.3 Data The Produc dataset from the Ecdat package contains data on the Gross State Product from 1970 to 1986. Each row is a single observation on a single state for a single year. The dataset has the following variables as columns. See the references later in this report for more details. gsp: gross state product. state: the state. year: the year. pcap: private capital stock. hwy: highway and streets. water: water and sewer facilities. util: other public buildings and structures. pc: public capital. emp: labor input measured by the employment in non-agricultural payrolls. unemp: state unemployment rate. library(Ecdat) data(Produc) head(Produc) ## state year pcap hwy water util pc gsp emp ## 1 ALABAMA 1970 15032.67 7325.80 1655.68 6051.20 35793.80 28418 1010.5 ## 2 ALABAMA 1971 15501.94 7525.94 1721.02 6254.98 37299.91 29375 1021.9 ## 3 ALABAMA 1972 15972.41 7765.42 1764.75 6442.23 38670.30 31303 1072.3 ## 4 ALABAMA 1973 16406.26 7907.66 1742.41 6756.19 40084.01 33430 1135.5 ## 5 ALABAMA 1974 16762.67 8025.52 1734.85 7002.29 42057.31 33749 1169.8 ## 6 ALABAMA 1975 17316.26 8158.23 1752.27 7405.76 43971.71 33604 1155.4 ## unemp ## 1 4.7 ## 2 5.2 ## 3 4.7 ## 4 3.9 ## 5 5.5 ## 6 7.7 4.4 Analysis First, we load the required packages. Drake is aware of all the packages you load with library() or require(). library(drake) library(Ecdat) # econometrics datasets library(knitr) library(ggplot2) Next, set up our workflow plan data frame in stages. We start with the models. Each model has 3 predictors, and we try all 84 possible models. predictors &lt;- setdiff(colnames(Produc), &quot;gsp&quot;) combos &lt;- t(combn(predictors, 3)) head(combos) ## [,1] [,2] [,3] ## [1,] &quot;state&quot; &quot;year&quot; &quot;pcap&quot; ## [2,] &quot;state&quot; &quot;year&quot; &quot;hwy&quot; ## [3,] &quot;state&quot; &quot;year&quot; &quot;water&quot; ## [4,] &quot;state&quot; &quot;year&quot; &quot;util&quot; ## [5,] &quot;state&quot; &quot;year&quot; &quot;pc&quot; ## [6,] &quot;state&quot; &quot;year&quot; &quot;emp&quot; targets &lt;- apply(combos, 1, paste, collapse = &quot;_&quot;) commands &lt;- apply(combos, 1, function(row){ covariates &lt;- paste(row, collapse = &quot; + &quot;) formula &lt;- paste0(&quot;as.formula(\\&quot;gsp ~ &quot;, covariates, &quot;\\&quot;)&quot;) command &lt;- paste0(&quot;lm(&quot;, formula, &quot;, data = Produc)&quot;) }) model_plan &lt;- data.frame(target = targets, command = commands) head(model_plan) ## target ## 1 state_year_pcap ## 2 state_year_hwy ## 3 state_year_water ## 4 state_year_util ## 5 state_year_pc ## 6 state_year_emp ## command ## 1 lm(as.formula(&quot;gsp ~ state + year + pcap&quot;), data = Produc) ## 2 lm(as.formula(&quot;gsp ~ state + year + hwy&quot;), data = Produc) ## 3 lm(as.formula(&quot;gsp ~ state + year + water&quot;), data = Produc) ## 4 lm(as.formula(&quot;gsp ~ state + year + util&quot;), data = Produc) ## 5 lm(as.formula(&quot;gsp ~ state + year + pc&quot;), data = Produc) ## 6 lm(as.formula(&quot;gsp ~ state + year + emp&quot;), data = Produc) Next, we make a plan to judge each model based on its root mean squared prediction error (RMSPE). commands &lt;- paste0(&quot;get_rmspe(&quot;, targets, &quot;, data = Produc)&quot;) targets &lt;- paste0(&quot;rmspe_&quot;, targets) rmspe_plan &lt;- data.frame(target = targets, command = commands) head(rmspe_plan) ## target command ## 1 rmspe_state_year_pcap get_rmspe(state_year_pcap, data = Produc) ## 2 rmspe_state_year_hwy get_rmspe(state_year_hwy, data = Produc) ## 3 rmspe_state_year_water get_rmspe(state_year_water, data = Produc) ## 4 rmspe_state_year_util get_rmspe(state_year_util, data = Produc) ## 5 rmspe_state_year_pc get_rmspe(state_year_pc, data = Produc) ## 6 rmspe_state_year_emp get_rmspe(state_year_emp, data = Produc) We need to define a function to get the RMSPE for each model. get_rmspe &lt;- function(lm_fit, data){ y &lt;- data$gsp yhat &lt;- predict(lm_fit, data = data) terms &lt;- attr(summary(lm_fit)$terms, &quot;term.labels&quot;) data.frame( rmspe = sqrt(mean((y - yhat)^2)), # nolint X1 = terms[1], X2 = terms[2], X3 = terms[3] ) } In our current plan, RMSPE is distributed over 84 targets (one for each model). Let’s plan to combine them all together in a single data frame. rmspe_results_plan &lt;- gather_plan( plan = rmspe_plan, target = &quot;rmspe&quot;, gather = &quot;rbind&quot; ) At the end, let’s generate a pdf plot of the RMSPE scores and a knitr report. output_plan &lt;- drake_plan( ggsave( filename = file_out(&quot;rmspe.pdf&quot;), plot = plot_rmspe(rmspe) ), knit(knitr_in(&quot;report.Rmd&quot;), file_out(&quot;report.md&quot;), quiet = TRUE) ) ## Warning: knitr/rmarkdown report &#39;report.Rmd&#39; does not exist and cannot be ## inspected for dependencies. head(output_plan) ## # A tibble: 2 x 2 ## target command ## &lt;chr&gt; &lt;chr&gt; ## 1 &quot;\\&quot;rmspe.pdf\\&quot;&quot; &quot;ggsave(filename = file_out(\\&quot;rmspe.pdf\\&quot;), plot = plot… ## 2 &quot;\\&quot;report.md\\&quot;&quot; &quot;knit(knitr_in(\\&quot;report.Rmd\\&quot;), file_out(\\&quot;report.md\\&quot;)… We see warnings above because our R Markdown report report.Rmd does not exist yet. You can find it here, and the code below generates it. local &lt;- file.path(&quot;examples&quot;, &quot;gsp&quot;, &quot;report.Rmd&quot;) path &lt;- system.file(path = local, package = &quot;drake&quot;, mustWork = TRUE) file.copy(from = path, to = &quot;report.Rmd&quot;, overwrite = TRUE) ## [1] TRUE At this point, we can gather together the whole workflow plan. whole_plan &lt;- rbind(model_plan, rmspe_plan, rmspe_results_plan, output_plan) Before we run the project, we need to define the plot_rmspe() function. plot_rmspe &lt;- function(rmspe){ ggplot(rmspe) + geom_histogram(aes(x = rmspe), bins = 30) } Now, we can run the project make(whole_plan, verbose = FALSE) ## Saving 6 x 6 in image 4.5 Results Here are the root mean squared prediction errors of all the models. results &lt;- readd(rmspe) loadd(plot_rmspe) library(ggplot2) plot_rmspe(rmspe = results) And here are the best models. The best variables are in the top row under X1, X2, and X3. head(results[order(results$rmspe, decreasing = FALSE), ]) ## rmspe X1 X2 X3 ## rmspe_state_hwy_emp 2613.669 state hwy emp ## rmspe_state_water_emp 2664.842 state water emp ## rmspe_state_util_emp 2665.744 state util emp ## rmspe_state_pc_emp 2666.058 state pc emp ## rmspe_state_pcap_emp 2675.336 state pcap emp ## rmspe_state_emp_unemp 2692.687 state emp unemp 4.6 Comparison with GNU Make If we were using Make instead of drake with the same set of targets, the analogous Makefile would look something like this pseudo-code sketch. models = model_state_year_pcap.rds model_state_year_hwy.rds ... # 84 of these model_% Rscript -e 'saveRDS(lm(...), ...)' rmspe_%: model_% Rscript -e 'saveRDS(get_rmspe(...), ...)' rmspe.rds: rmspe_% Rscript -e 'saveRDS(rbind(...), ...)' rmspe.pdf: rmspe.rds Rscript -e 'ggplot2::ggsave(plot_rmspe(readRDS(\"rmspe.rds\")), \"rmspe.pdf\")' report.md: report.Rmd Rscript -e 'knitr::knit(\"report.Rmd\")' There are three main disadvantages to this approach. Every target requires a new call to Rscript, which means that more time is spent initializing R sessions than doing the actual work. The user must micromanage nearly one hundred output files (in this case, *.rds files), which is cumbersome, messy, and inconvenient. Drake, on the other hand, automatically manages storage using a storr cache. The user needs to write the names of the 84 models near the top of the Makefile, which is less convenient than maintaining a data frame in R. 4.7 References Baltagi, Badi H (2003). Econometric analysis of panel data, John Wiley and sons, http://www.wiley.com/legacy/wileychi/baltagi/. Baltagi, B. H. and N. Pinnoi (1995). “Public capital stock and state productivity growth: further evidence”, Empirical Economics, 20, 351-359. Munnell, A. (1990). “Why has productivity growth declined? Productivity and public investment”“, New England Economic Review, 3-22. Yves Croissant (2016). Ecdat: Data Sets for Econometrics. R package version 0.3-1. https://CRAN.R-project.org/package=Ecdat. "],
["mtcars.html", "Chapter 5 The mtcars example and workflow plan generation 5.1 Get the code. 5.2 Quick examples 5.3 The motivation of the mtcars example 5.4 Set up the mtcars example 5.5 The workflow plan data frame 5.6 Generate the workflow plan 5.7 Flexible workflow plan generation 5.8 Run the workflow 5.9 Automatic watching for changed dependencies 5.10 A note on tidy evaluation 5.11 Need more speed?", " Chapter 5 The mtcars example and workflow plan generation This chapter is a walkthrough of drake’s main functionality based on the mtcars example. It sets up the project and runs it repeatedly to demonstrate drake’s most important functionality. 5.1 Get the code. Write the code files to your workspace. drake_example(&quot;mtcars&quot;) The new mtcars folder now includes a file structure of a serious drake project, plus an interactive-tutorial.R to narrate the example. The code is also online here. 5.2 Quick examples Inspect and run your project. library(drake) load_mtcars_example() # Get the code with drake_example(&quot;mtcars&quot;). config &lt;- drake_config(my_plan) # Master configuration list vis_drake_graph(config) # Hover, click, drag, zoom, pan. make(my_plan) # Run the workflow. outdated(config) # Everything is up to date. Debug errors. failed() # Targets that failed in the most recent `make()` context &lt;- diagnose(large) # Diagnostic metadata: errors, warnings, etc. error &lt;- context$error str(error) # Object of class &quot;error&quot; error$message error$call error$calls # Full traceback of nested calls leading up to the error. # nolint Dive deeper into the built-in examples. drake_example(&quot;mtcars&quot;) # Write the code files. drake_examples() # List the other examples. 5.3 The motivation of the mtcars example Is there an association between the weight and the fuel efficiency of cars? To find out, we use the mtcars dataset from the datasets package. The mtcars dataset originally came from the 1974 Motor Trend US magazine, and it contains design and performance data on 32 models of automobile. ## ?mtcars # more info head(mtcars) ## mpg cyl disp hp drat wt qsec vs am gear carb ## Mazda RX4 21.0 6 160 110 3.90 2.620 16.46 0 1 4 4 ## Mazda RX4 Wag 21.0 6 160 110 3.90 2.875 17.02 0 1 4 4 ## Datsun 710 22.8 4 108 93 3.85 2.320 18.61 1 1 4 1 ## Hornet 4 Drive 21.4 6 258 110 3.08 3.215 19.44 1 0 3 1 ## Hornet Sportabout 18.7 8 360 175 3.15 3.440 17.02 0 0 3 2 ## Valiant 18.1 6 225 105 2.76 3.460 20.22 1 0 3 1 Here, wt is weight in tons, and mpg is fuel efficiency in miles per gallon. We want to figure out if there is an association between wt and mpg. The mtcars dataset itself only has 32 rows, so we generate two larger bootstrapped datasets and then analyze them with regression models. We summarize the regression models to see if there is an association. 5.4 Set up the mtcars example Before you run your project, you need to set up the workspace. In other words, you need to gather the “imports”: functions, pre-loaded data objects, and saved files that you want to be available before the real work begins. library(knitr) # Drake knows which packages you load. library(drake) We need a function to bootstrap larger datasets from mtcars. ## Pick a random subset of n rows from a dataset random_rows &lt;- function(data, n){ data[sample.int(n = nrow(data), size = n, replace = TRUE), ] } ## Bootstrapped datasets from mtcars. simulate &lt;- function(n){ # Pick a random set of cars to bootstrap from the mtcars data. data &lt;- random_rows(data = mtcars, n = n) # x is the car&#39;s weight, and y is the fuel efficiency. data.frame( x = data$wt, y = data$mpg ) } We also need functions to apply the regression models we need for detecting associations. ## Is fuel efficiency linearly related to weight? reg1 &lt;- function(d){ lm(y ~ + x, data = d) } ## Is fuel efficiency related to the SQUARE of the weight? reg2 &lt;- function(d){ d$x2 &lt;- d$x ^ 2 lm(y ~ x2, data = d) } We want to summarize the final results in an R Markdown report, so we need the following report.Rmd source file. path &lt;- file.path(&quot;examples&quot;, &quot;mtcars&quot;, &quot;report.Rmd&quot;) report_file &lt;- system.file(path, package = &quot;drake&quot;, mustWork = TRUE) file.copy(from = report_file, to = getwd(), overwrite = TRUE) ## [1] TRUE Here are the contents of the report. It will serve as a final summary of our work, and we will process it at the very end. Admittedly, some of the text spoils the punch line. cat(readLines(&quot;report.Rmd&quot;), sep = &quot;\\n&quot;) ## --- ## title: &quot;Final results report for the mtcars example&quot; ## author: You ## output: html_document ## --- ## ## # The weight and fuel efficiency of cars ## ## Is there an association between the weight and the fuel efficiency of cars? To find out, we use the `mtcars` dataset from the `datasets` package. The `mtcars` data originally came from the 1974 Motor Trend US magazine, and it contains design and performance data on 32 models of automobile. ## ## ```{r showmtcars} ## # ?mtcars # more info ## head(mtcars) ## ``` ## ## Here, `wt` is weight in tons, and `mpg` is fuel efficiency in miles per gallon. We want to figure out if there is an association between `wt` and `mpg`. The `mtcars` dataset itself only has 32 rows, so we generated two larger bootstrapped datasets. We called them `small` and `large`. ## ## ```{r example_chunk} ## library(drake) ## head(readd(small)) # 48 rows ## loadd(large) # 64 rows ## head(large) ## ``` ## ## Then, we fit a couple regression models to the `small` and `large` to try to detect an association between `wt` and `mpg`. Here are the coefficients and p-values from one of the model fits. ## ## ```{r second_example_chunk} ## readd(coef_regression2_small) ## ``` ## ## Since the p-value on `x2` is so small, there may be an association between weight and fuel efficiency after all. ## ## # A note on knitr reports in drake projects. ## ## Because of the calls to `readd()` and `loadd()`, `drake` knows that `small`, `large`, and `coef_regression2_small` are dependencies of this R Markdown report. This dependency relationship is what causes the report to be processed at the very end. Now, all our imports are set up. When the real work begins, drake will import functions and data objects from your R session environment ls() ## [1] &quot;combos&quot; &quot;commands&quot; &quot;config&quot; ## [4] &quot;create_plot&quot; &quot;dat&quot; &quot;data_plan&quot; ## [7] &quot;get_rmspe&quot; &quot;hist&quot; &quot;local&quot; ## [10] &quot;make_my_plot&quot; &quot;make_my_table&quot; &quot;model_plan&quot; ## [13] &quot;output_plan&quot; &quot;output_types&quot; &quot;package_list&quot; ## [16] &quot;path&quot; &quot;plan&quot; &quot;plot_rmspe&quot; ## [19] &quot;predictors&quot; &quot;Produc&quot; &quot;random_rows&quot; ## [22] &quot;reg1&quot; &quot;reg2&quot; &quot;reportfile&quot; ## [25] &quot;report_file&quot; &quot;report_plan&quot; &quot;results&quot; ## [28] &quot;rmd&quot; &quot;rmspe_plan&quot; &quot;rmspe_results_plan&quot; ## [31] &quot;simulate&quot; &quot;targets&quot; &quot;tmp&quot; ## [34] &quot;whole_plan&quot; and saved files from your file system. list.files() ## [1] &quot;02-intro.Rmd&quot; &quot;03-example-packages.Rmd&quot; ## [3] &quot;04-example-gsp.Rmd&quot; &quot;05-example-mtcars.Rmd&quot; ## [5] &quot;06-best-practices.Rmd&quot; &quot;07-debug.Rmd&quot; ## [7] &quot;08-vis.Rmd&quot; &quot;09-hpc.Rmd&quot; ## [9] &quot;10-time.Rmd&quot; &quot;11-store.Rmd&quot; ## [11] &quot;12-caution.Rmd&quot; &quot;13-faq.Rmd&quot; ## [13] &quot;_book&quot; &quot;_bookdown_files&quot; ## [15] &quot;_bookdown.yml&quot; &quot;build.R&quot; ## [17] &quot;DESCRIPTION&quot; &quot;docs&quot; ## [19] &quot;drake-manual_files&quot; &quot;drake-manual.Rmd&quot; ## [21] &quot;drake-manual.Rproj&quot; &quot;faq-stub.md&quot; ## [23] &quot;images&quot; &quot;index.Rmd&quot; ## [25] &quot;LICENSE&quot; &quot;README.md&quot; ## [27] &quot;report.Rmd&quot; 5.5 The workflow plan data frame Now that your workspace of imports is prepared, we can outline the real work step by step in a workflow plan data frame. load_mtcars_example() # Get the code with drake_example(&quot;mtcars&quot;). my_plan ## # A tibble: 15 x 2 ## target command ## &lt;chr&gt; &lt;chr&gt; ## 1 &quot;&quot; &quot;knit(knitr_in(\\&quot;report.Rmd\\&quot;), file_out(\\&quot;repo… ## 2 small simulate(48) ## 3 large simulate(64) ## 4 regression1_small reg1(small) ## 5 regression1_large reg1(large) ## 6 regression2_small reg2(small) ## 7 regression2_large reg2(large) ## 8 summ_regression1_small suppressWarnings(summary(regression1_small$resi… ## 9 summ_regression1_large suppressWarnings(summary(regression1_large$resi… ## 10 summ_regression2_small suppressWarnings(summary(regression2_small$resi… ## 11 summ_regression2_large suppressWarnings(summary(regression2_large$resi… ## 12 coef_regression1_small suppressWarnings(summary(regression1_small))$co… ## 13 coef_regression1_large suppressWarnings(summary(regression1_large))$co… ## 14 coef_regression2_small suppressWarnings(summary(regression2_small))$co… ## 15 coef_regression2_large suppressWarnings(summary(regression2_large))$co… Each row is an intermediate step, and each command generates a single target. A target is an output R object (cached when generated) or an output file (specified with single quotes), and a command just an ordinary piece of R code (not necessarily a single function call). Commands make use of R objects imported from your workspace, targets generated by other commands, and initial input files. These dependencies give your project an underlying network representation. ## Hover, click, drag, zoom, and pan. config &lt;- drake_config(my_plan) vis_drake_graph(config, width = &quot;100%&quot;, height = &quot;500px&quot;) # Also drake_graph() You can also check the dependencies of individual targets and imported functions. deps_code(reg2) ## [1] &quot;lm&quot; &quot;x2&quot; &quot;y&quot; deps_code(my_plan$command[1]) # Files like report.Rmd are single-quoted. ## [1] &quot;coef_regression2_small&quot; &quot;knit&quot; ## [3] &quot;large&quot; &quot;\\&quot;report.md\\&quot;&quot; ## [5] &quot;\\&quot;report.Rmd\\&quot;&quot; &quot;small&quot; deps_code(my_plan$command[nrow(my_plan)]) ## [1] &quot;regression2_large&quot; &quot;summary&quot; &quot;suppressWarnings&quot; List all the reproducibly-tracked objects and files. tracked(my_plan, targets = &quot;small&quot;) ## [1] &quot;nrow&quot; &quot;sample.int&quot; &quot;data.frame&quot; &quot;mtcars&quot; &quot;random_rows&quot; ## [6] &quot;small&quot; &quot;simulate&quot; tracked(my_plan) ## [1] &quot;nrow&quot; &quot;sample.int&quot; ## [3] &quot;data.frame&quot; &quot;mtcars&quot; ## [5] &quot;random_rows&quot; &quot;lm&quot; ## [7] &quot;x&quot; &quot;y&quot; ## [9] &quot;x2&quot; &quot;summary&quot; ## [11] &quot;coef_regression2_small&quot; &quot;knit&quot; ## [13] &quot;large&quot; &quot;\\&quot;report.Rmd\\&quot;&quot; ## [15] &quot;small&quot; &quot;simulate&quot; ## [17] &quot;reg1&quot; &quot;reg2&quot; ## [19] &quot;regression1_small&quot; &quot;suppressWarnings&quot; ## [21] &quot;regression1_large&quot; &quot;regression2_small&quot; ## [23] &quot;regression2_large&quot; &quot;\\&quot;report.md\\&quot;&quot; ## [25] &quot;summ_regression1_small&quot; &quot;summ_regression1_large&quot; ## [27] &quot;summ_regression2_small&quot; &quot;summ_regression2_large&quot; ## [29] &quot;coef_regression1_small&quot; &quot;coef_regression1_large&quot; ## [31] &quot;coef_regression2_large&quot; Check for circular reasoning, missing input files, and other pitfalls. check_plan(my_plan) 5.6 Generate the workflow plan The workflow plan data frame my_plan would be a pain to write by hand, so drake has functions to help you. Here are the commands to generate the bootstrapped datasets. my_datasets &lt;- drake_plan( small = simulate(48), large = simulate(64)) my_datasets ## # A tibble: 2 x 2 ## target command ## &lt;chr&gt; &lt;chr&gt; ## 1 small simulate(48) ## 2 large simulate(64) For multiple replicates: expand_plan(my_datasets, values = c(&quot;rep1&quot;, &quot;rep2&quot;)) ## # A tibble: 4 x 2 ## target command ## &lt;chr&gt; &lt;chr&gt; ## 1 small_rep1 simulate(48) ## 2 small_rep2 simulate(48) ## 3 large_rep1 simulate(64) ## 4 large_rep2 simulate(64) Here is a template for applying our regression models to our bootstrapped datasets. methods &lt;- drake_plan( regression1 = reg1(dataset__), regression2 = reg2(dataset__)) methods ## # A tibble: 2 x 2 ## target command ## &lt;chr&gt; &lt;chr&gt; ## 1 regression1 reg1(dataset__) ## 2 regression2 reg2(dataset__) We evaluate the dataset__ wildcard to generate all the regression commands we need. my_analyses &lt;- plan_analyses(methods, data = my_datasets) my_analyses ## # A tibble: 4 x 2 ## target command ## &lt;chr&gt; &lt;chr&gt; ## 1 regression1_small reg1(small) ## 2 regression1_large reg1(large) ## 3 regression2_small reg2(small) ## 4 regression2_large reg2(large) Next, we summarize each analysis of each dataset. We calculate descriptive statistics on the residuals, and we collect the regression coefficients and their p-values. summary_types &lt;- drake_plan( summ = suppressWarnings(summary(analysis__$residuals)), coef = suppressWarnings(summary(analysis__))$coefficients ) summary_types ## # A tibble: 2 x 2 ## target command ## &lt;chr&gt; &lt;chr&gt; ## 1 summ suppressWarnings(summary(analysis__$residuals)) ## 2 coef suppressWarnings(summary(analysis__))$coefficients results &lt;- plan_summaries(summary_types, analyses = my_analyses, datasets = my_datasets, gather = NULL) results ## # A tibble: 8 x 2 ## target command ## &lt;chr&gt; &lt;chr&gt; ## 1 summ_regression1_small suppressWarnings(summary(regression1_small$resid… ## 2 summ_regression1_large suppressWarnings(summary(regression1_large$resid… ## 3 summ_regression2_small suppressWarnings(summary(regression2_small$resid… ## 4 summ_regression2_large suppressWarnings(summary(regression2_large$resid… ## 5 coef_regression1_small suppressWarnings(summary(regression1_small))$coe… ## 6 coef_regression1_large suppressWarnings(summary(regression1_large))$coe… ## 7 coef_regression2_small suppressWarnings(summary(regression2_small))$coe… ## 8 coef_regression2_large suppressWarnings(summary(regression2_large))$coe… The gather feature reduces a collection of targets to a single target. The resulting commands are long, so gathering is deactivated for the sake of readability. For your knitr reports, use knitr_in() in your commands so that report.Rmd is a dependency and targets loaded with loadd() and readd() in active code chunks are also dependencies. Use file_out() to tell drake that the target is a file output. If the file is an output, you do not need to name the target. The target name will be the name of the output file in quotes. report &lt;- drake_plan( knit(knitr_in(&quot;report.Rmd&quot;), file_out(&quot;report.md&quot;), quiet = TRUE) ) report ## # A tibble: 1 x 2 ## target command ## &lt;chr&gt; &lt;chr&gt; ## 1 &quot;\\&quot;report.md\\&quot;&quot; &quot;knit(knitr_in(\\&quot;report.Rmd\\&quot;), file_out(\\&quot;report.md\\&quot;)… Finally, consolidate your workflow using rbind(). Row order does not matter. my_plan &lt;- rbind(report, my_datasets, my_analyses, results) my_plan ## # A tibble: 15 x 2 ## target command ## &lt;chr&gt; &lt;chr&gt; ## 1 &quot;\\&quot;report.md\\&quot;&quot; &quot;knit(knitr_in(\\&quot;report.Rmd\\&quot;), file_out(\\&quot;repo… ## 2 small simulate(48) ## 3 large simulate(64) ## 4 regression1_small reg1(small) ## 5 regression1_large reg1(large) ## 6 regression2_small reg2(small) ## 7 regression2_large reg2(large) ## 8 summ_regression1_small suppressWarnings(summary(regression1_small$resi… ## 9 summ_regression1_large suppressWarnings(summary(regression1_large$resi… ## 10 summ_regression2_small suppressWarnings(summary(regression2_small$resi… ## 11 summ_regression2_large suppressWarnings(summary(regression2_large$resi… ## 12 coef_regression1_small suppressWarnings(summary(regression1_small))$co… ## 13 coef_regression1_large suppressWarnings(summary(regression1_large))$co… ## 14 coef_regression2_small suppressWarnings(summary(regression2_small))$co… ## 15 coef_regression2_large suppressWarnings(summary(regression2_large))$co… 5.7 Flexible workflow plan generation If your workflow does not fit the rigid datasets/analyses/summaries framework, consider using functions expand_plan(), evaluate_plan(), gather_plan(), and reduce_plan(). df &lt;- drake_plan(data = simulate(center = MU, scale = SIGMA)) df ## # A tibble: 1 x 2 ## target command ## &lt;chr&gt; &lt;chr&gt; ## 1 data simulate(center = MU, scale = SIGMA) df &lt;- expand_plan(df, values = c(&quot;rep1&quot;, &quot;rep2&quot;)) df ## # A tibble: 2 x 2 ## target command ## &lt;chr&gt; &lt;chr&gt; ## 1 data_rep1 simulate(center = MU, scale = SIGMA) ## 2 data_rep2 simulate(center = MU, scale = SIGMA) evaluate_plan(df, wildcard = &quot;MU&quot;, values = 1:2) ## # A tibble: 4 x 2 ## target command ## &lt;chr&gt; &lt;chr&gt; ## 1 data_rep1_1 simulate(center = 1, scale = SIGMA) ## 2 data_rep1_2 simulate(center = 2, scale = SIGMA) ## 3 data_rep2_1 simulate(center = 1, scale = SIGMA) ## 4 data_rep2_2 simulate(center = 2, scale = SIGMA) evaluate_plan(df, wildcard = &quot;MU&quot;, values = 1:2, expand = FALSE) ## # A tibble: 2 x 2 ## target command ## &lt;chr&gt; &lt;chr&gt; ## 1 data_rep1 simulate(center = 1, scale = SIGMA) ## 2 data_rep2 simulate(center = 2, scale = SIGMA) evaluate_plan(df, rules = list(MU = 1:2, SIGMA = c(0.1, 1)), expand = FALSE) ## # A tibble: 2 x 2 ## target command ## &lt;chr&gt; &lt;chr&gt; ## 1 data_rep1 simulate(center = 1, scale = 0.1) ## 2 data_rep2 simulate(center = 2, scale = 1) evaluate_plan(df, rules = list(MU = 1:2, SIGMA = c(0.1, 1, 10))) ## # A tibble: 12 x 2 ## target command ## &lt;chr&gt; &lt;chr&gt; ## 1 data_rep1_1_0.1 simulate(center = 1, scale = 0.1) ## 2 data_rep1_1_1 simulate(center = 1, scale = 1) ## 3 data_rep1_1_10 simulate(center = 1, scale = 10) ## 4 data_rep1_2_0.1 simulate(center = 2, scale = 0.1) ## 5 data_rep1_2_1 simulate(center = 2, scale = 1) ## 6 data_rep1_2_10 simulate(center = 2, scale = 10) ## 7 data_rep2_1_0.1 simulate(center = 1, scale = 0.1) ## 8 data_rep2_1_1 simulate(center = 1, scale = 1) ## 9 data_rep2_1_10 simulate(center = 1, scale = 10) ## 10 data_rep2_2_0.1 simulate(center = 2, scale = 0.1) ## 11 data_rep2_2_1 simulate(center = 2, scale = 1) ## 12 data_rep2_2_10 simulate(center = 2, scale = 10) gather_plan(df) ## # A tibble: 1 x 2 ## target command ## &lt;chr&gt; &lt;chr&gt; ## 1 target list(data_rep1 = data_rep1, data_rep2 = data_rep2) gather_plan(df, target = &quot;my_summaries&quot;, gather = &quot;rbind&quot;) ## # A tibble: 1 x 2 ## target command ## &lt;chr&gt; &lt;chr&gt; ## 1 my_summaries rbind(data_rep1 = data_rep1, data_rep2 = data_rep2) x_plan &lt;- evaluate_plan( drake_plan(x = VALUE), wildcard = &quot;VALUE&quot;, values = 1:8 ) x_plan ## # A tibble: 8 x 2 ## target command ## &lt;chr&gt; &lt;chr&gt; ## 1 x_1 1 ## 2 x_2 2 ## 3 x_3 3 ## 4 x_4 4 ## 5 x_5 5 ## 6 x_6 6 ## 7 x_7 7 ## 8 x_8 8 x_plan ## # A tibble: 8 x 2 ## target command ## &lt;chr&gt; &lt;chr&gt; ## 1 x_1 1 ## 2 x_2 2 ## 3 x_3 3 ## 4 x_4 4 ## 5 x_5 5 ## 6 x_6 6 ## 7 x_7 7 ## 8 x_8 8 reduce_plan( x_plan, target = &quot;x_sum&quot;, pairwise = TRUE, begin = &quot;fun(&quot;, op = &quot;, &quot;, end = &quot;)&quot; ) ## # A tibble: 7 x 2 ## target command ## &lt;chr&gt; &lt;chr&gt; ## 1 x_sum_1 fun(x_1, x_2) ## 2 x_sum_2 fun(x_3, x_4) ## 3 x_sum_3 fun(x_5, x_6) ## 4 x_sum_4 fun(x_7, x_8) ## 5 x_sum_5 fun(x_sum_1, x_sum_2) ## 6 x_sum_6 fun(x_sum_3, x_sum_4) ## 7 x_sum fun(x_sum_5, x_sum_6) 5.8 Run the workflow You may want to check for outdated or missing targets/imports first. config &lt;- drake_config(my_plan, verbose = FALSE) outdated(config) # Targets that need to be (re)built. ## [1] &quot;coef_regression1_large&quot; &quot;coef_regression1_small&quot; ## [3] &quot;coef_regression2_large&quot; &quot;coef_regression2_small&quot; ## [5] &quot;large&quot; &quot;regression1_large&quot; ## [7] &quot;regression1_small&quot; &quot;regression2_large&quot; ## [9] &quot;regression2_small&quot; &quot;\\&quot;report.md\\&quot;&quot; ## [11] &quot;small&quot; &quot;summ_regression1_large&quot; ## [13] &quot;summ_regression1_small&quot; &quot;summ_regression2_large&quot; ## [15] &quot;summ_regression2_small&quot; missed(config) # Checks your workspace. ## [1] &quot;x&quot; &quot;y&quot; &quot;x2&quot; Then just make(my_plan). make(my_plan) ## target large ## target small ## target regression1_large ## target regression2_large ## target regression1_small ## target regression2_small ## target summ_regression1_large ## target coef_regression1_large ## target summ_regression2_large ## target coef_regression2_large ## target summ_regression1_small ## target coef_regression1_small ## target coef_regression2_small ## target summ_regression2_small ## target file &quot;report.md&quot; For the reg2() model on the small dataset, the p-value on x2 is so small that there may be an association between weight and fuel efficiency after all. readd(coef_regression2_small) ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 27.504915 1.02496426 26.835000 9.676340e-30 ## x2 -0.708536 0.08285938 -8.551066 4.617125e-11 The non-file dependencies of your last target are already loaded in your workspace. ls() ## [1] &quot;combos&quot; &quot;commands&quot; &quot;config&quot; ## [4] &quot;create_plot&quot; &quot;dat&quot; &quot;data_plan&quot; ## [7] &quot;df&quot; &quot;get_rmspe&quot; &quot;hist&quot; ## [10] &quot;local&quot; &quot;make_my_plot&quot; &quot;make_my_table&quot; ## [13] &quot;methods&quot; &quot;model_plan&quot; &quot;my_analyses&quot; ## [16] &quot;my_datasets&quot; &quot;my_plan&quot; &quot;output_plan&quot; ## [19] &quot;output_types&quot; &quot;package_list&quot; &quot;path&quot; ## [22] &quot;plan&quot; &quot;plot_rmspe&quot; &quot;predictors&quot; ## [25] &quot;Produc&quot; &quot;random_rows&quot; &quot;reg1&quot; ## [28] &quot;reg2&quot; &quot;report&quot; &quot;reportfile&quot; ## [31] &quot;report_file&quot; &quot;report_plan&quot; &quot;results&quot; ## [34] &quot;rmd&quot; &quot;rmspe_plan&quot; &quot;rmspe_results_plan&quot; ## [37] &quot;simulate&quot; &quot;summary_types&quot; &quot;targets&quot; ## [40] &quot;tmp&quot; &quot;whole_plan&quot; &quot;x_plan&quot; outdated(config) # Everything is up to date. ## character(0) build_times(digits = 4) # How long did it take to make each target? ## # A tibble: 31 x 5 ## item type elapsed user system ## * &lt;chr&gt; &lt;chr&gt; &lt;S4: Duration&gt; &lt;S4: Duration&gt; &lt;S4: Durat&gt; ## 1 coef_regression1_large target 0.004s 0.005s 0s ## 2 coef_regression1_small target 0.003s 0.003s 0s ## 3 coef_regression2_large target 0.004s 0.004s 0s ## 4 coef_regression2_small target 0.003s 0.003s 0s ## 5 data.frame import 0.019s 0.019s 0s ## 6 knit import 0.019s 0.019s 0s ## 7 large target 0.004s 0.003s 0.001s ## 8 lm import 0.007s 0.007s 0s ## 9 mtcars import 0.001s 0.001s 0s ## 10 nrow import 0.005s 0.005s 0s ## # ... with 21 more rows See also predict_runtime() and rate_limiting_times(). In the new graph, the black nodes from before are now green. ## Hover, click, drag, zoom, and explore. vis_drake_graph(config, width = &quot;100%&quot;, height = &quot;500px&quot;) Optionally, get visNetwork nodes and edges so you can make your own plot with visNetwork() or render_drake_graph(). dataframes_graph(config) Use readd() and loadd() to load targets into your workspace. (They are cached in the hidden .drake/ folder using storr). There are many more functions for interacting with the cache. readd(coef_regression2_large) ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 26.8613175 0.82963761 32.37717 1.485222e-40 ## x2 -0.6299583 0.05501956 -11.44972 6.167412e-17 loadd(small) head(small) ## x y ## 1 3.730 17.3 ## 2 5.250 10.4 ## 3 3.730 17.3 ## 4 5.345 14.7 ## 5 3.190 24.4 ## 6 3.440 17.8 rm(small) cached(small, large) ## small large ## TRUE TRUE cached() ## [1] &quot;coef_regression1_large&quot; &quot;coef_regression1_small&quot; ## [3] &quot;coef_regression2_large&quot; &quot;coef_regression2_small&quot; ## [5] &quot;data.frame&quot; &quot;knit&quot; ## [7] &quot;large&quot; &quot;lm&quot; ## [9] &quot;mtcars&quot; &quot;nrow&quot; ## [11] &quot;random_rows&quot; &quot;reg1&quot; ## [13] &quot;reg2&quot; &quot;regression1_large&quot; ## [15] &quot;regression1_small&quot; &quot;regression2_large&quot; ## [17] &quot;regression2_small&quot; &quot;\\&quot;report.md\\&quot;&quot; ## [19] &quot;\\&quot;report.Rmd\\&quot;&quot; &quot;sample.int&quot; ## [21] &quot;simulate&quot; &quot;small&quot; ## [23] &quot;summary&quot; &quot;summ_regression1_large&quot; ## [25] &quot;summ_regression1_small&quot; &quot;summ_regression2_large&quot; ## [27] &quot;summ_regression2_small&quot; &quot;suppressWarnings&quot; ## [29] &quot;x&quot; &quot;x2&quot; ## [31] &quot;y&quot; built() ## [1] &quot;coef_regression1_large&quot; &quot;coef_regression1_small&quot; ## [3] &quot;coef_regression2_large&quot; &quot;coef_regression2_small&quot; ## [5] &quot;large&quot; &quot;regression1_large&quot; ## [7] &quot;regression1_small&quot; &quot;regression2_large&quot; ## [9] &quot;regression2_small&quot; &quot;\\&quot;report.md\\&quot;&quot; ## [11] &quot;small&quot; &quot;summ_regression1_large&quot; ## [13] &quot;summ_regression1_small&quot; &quot;summ_regression2_large&quot; ## [15] &quot;summ_regression2_small&quot; imported() ## [1] &quot;data.frame&quot; &quot;knit&quot; &quot;lm&quot; ## [4] &quot;mtcars&quot; &quot;nrow&quot; &quot;random_rows&quot; ## [7] &quot;reg1&quot; &quot;reg2&quot; &quot;\\&quot;report.Rmd\\&quot;&quot; ## [10] &quot;sample.int&quot; &quot;simulate&quot; &quot;summary&quot; ## [13] &quot;suppressWarnings&quot; &quot;x&quot; &quot;x2&quot; ## [16] &quot;y&quot; head(read_drake_plan()) ## # A tibble: 6 x 2 ## target command ## &lt;chr&gt; &lt;chr&gt; ## 1 &quot;\\&quot;report.md\\&quot;&quot; &quot;knit(knitr_in(\\&quot;report.Rmd\\&quot;), file_out(\\&quot;report.md\\… ## 2 small simulate(48) ## 3 large simulate(64) ## 4 regression1_small reg1(small) ## 5 regression1_large reg1(large) ## 6 regression2_small reg2(small) head(progress()) # See also in_progress() ## coef_regression1_large coef_regression1_small coef_regression2_large ## &quot;finished&quot; &quot;finished&quot; &quot;finished&quot; ## coef_regression2_small data.frame knit ## &quot;finished&quot; &quot;finished&quot; &quot;finished&quot; progress(large) ## large ## &quot;finished&quot; ## drake_session() # sessionInfo() of the last make() # nolint The next time you run make(my_plan), nothing will build because drake knows everything is already up to date. config &lt;- make(my_plan) # Will use config later. See also drake_config(). ## All targets are already up to date. But if you change one of your functions, commands, or other dependencies, drake will update the affected targets. Suppose we change the quadratic term to a cubic term in reg2(). We might want to do this if we suspect a cubic relationship between tons and miles per gallon. reg2 &lt;- function(d) { d$x3 &lt;- d$x ^ 3 lm(y ~ x3, data = d) } The targets that depend on reg2() need to be rebuilt. outdated(config) ## [1] &quot;coef_regression2_large&quot; &quot;coef_regression2_small&quot; ## [3] &quot;regression2_large&quot; &quot;regression2_small&quot; ## [5] &quot;\\&quot;report.md\\&quot;&quot; &quot;summ_regression2_large&quot; ## [7] &quot;summ_regression2_small&quot; Advanced: To find out why a target is out of date, you can load the storr cache and compare the appropriate hash keys to the output of dependency_profile(). dependency_profile(target = &quot;regression2_small&quot;, config = config) ## $cached_command ## [1] &quot;{\\n reg2(small) \\n}&quot; ## ## $current_command ## [1] &quot;{\\n reg2(small) \\n}&quot; ## ## $cached_file_modification_time ## NULL ## ## $cached_dependency_hash ## [1] &quot;b91a088b0ef9d46f13c59c3d312d45ee83717eaebafcd93d0c7431e4f9a1d3dc&quot; ## ## $current_dependency_hash ## [1] &quot;054b5f4bf8c3d833bf3aa830f7c1ff2af243355e8e6004f8362be1432ace3e20&quot; ## ## $hashes_of_dependencies ## reg2 small ## &quot;a48c685848ad87b1&quot; &quot;7d836504e5060e6d&quot; config$cache$get_hash(key = &quot;small&quot;) # same ## [1] &quot;7d836504e5060e6d&quot; config$cache$get_hash(key = &quot;reg2&quot;) # different ## [1] &quot;9202f02ce34af548&quot; ## Hover, click, drag, zoom, and explore. vis_drake_graph(config, width = &quot;100%&quot;, height = &quot;500px&quot;) The next make() will rebuild the targets depending on reg2() and leave everything else alone. make(my_plan) ## target regression2_large ## target regression2_small ## target summ_regression2_large ## target coef_regression2_large ## target coef_regression2_small ## target summ_regression2_small ## target file &quot;report.md&quot; Trivial changes to whitespace and comments are totally ignored. reg2 &lt;- function(d) { d$x3 &lt;- d$x ^ 3 lm(y ~ x3, data = d) # I indented here. } outdated(config) # Everything is up to date. ## character(0) Drake cares about nested functions too: nontrivial changes to random_rows() will propagate to simulate() and all the downstream targets. random_rows &lt;- function(data, n){ n &lt;- n + 1 data[sample.int(n = nrow(data), size = n, replace = TRUE), ] } outdated(config) ## [1] &quot;coef_regression1_large&quot; &quot;coef_regression1_small&quot; ## [3] &quot;coef_regression2_large&quot; &quot;coef_regression2_small&quot; ## [5] &quot;large&quot; &quot;regression1_large&quot; ## [7] &quot;regression1_small&quot; &quot;regression2_large&quot; ## [9] &quot;regression2_small&quot; &quot;\\&quot;report.md\\&quot;&quot; ## [11] &quot;small&quot; &quot;summ_regression1_large&quot; ## [13] &quot;summ_regression1_small&quot; &quot;summ_regression2_large&quot; ## [15] &quot;summ_regression2_small&quot; make(my_plan) ## target large ## target small ## target regression1_large ## target regression2_large ## target regression1_small ## target regression2_small ## target summ_regression1_large ## target coef_regression1_large ## target summ_regression2_large ## target coef_regression2_large ## target summ_regression1_small ## target coef_regression1_small ## target coef_regression2_small ## target summ_regression2_small ## target file &quot;report.md&quot; Need to add new work on the fly? Just append rows to the workflow plan. If the rest of your workflow is up to date, only the new work is run. new_simulation &lt;- function(n){ data.frame(x = rnorm(n), y = rnorm(n)) } additions &lt;- drake_plan( new_data = new_simulation(36) + sqrt(10)) additions ## # A tibble: 1 x 2 ## target command ## &lt;chr&gt; &lt;chr&gt; ## 1 new_data new_simulation(36) + sqrt(10) my_plan &lt;- rbind(my_plan, additions) my_plan ## # A tibble: 16 x 2 ## target command ## &lt;chr&gt; &lt;chr&gt; ## 1 &quot;\\&quot;report.md\\&quot;&quot; &quot;knit(knitr_in(\\&quot;report.Rmd\\&quot;), file_out(\\&quot;repo… ## 2 small simulate(48) ## 3 large simulate(64) ## 4 regression1_small reg1(small) ## 5 regression1_large reg1(large) ## 6 regression2_small reg2(small) ## 7 regression2_large reg2(large) ## 8 summ_regression1_small suppressWarnings(summary(regression1_small$resi… ## 9 summ_regression1_large suppressWarnings(summary(regression1_large$resi… ## 10 summ_regression2_small suppressWarnings(summary(regression2_small$resi… ## 11 summ_regression2_large suppressWarnings(summary(regression2_large$resi… ## 12 coef_regression1_small suppressWarnings(summary(regression1_small))$co… ## 13 coef_regression1_large suppressWarnings(summary(regression1_large))$co… ## 14 coef_regression2_small suppressWarnings(summary(regression2_small))$co… ## 15 coef_regression2_large suppressWarnings(summary(regression2_large))$co… ## 16 new_data new_simulation(36) + sqrt(10) make(my_plan) ## target new_data If you ever need to erase your work, use clean(). The next make() will rebuild any cleaned targets, so be careful. You may notice that by default, the size of the cache does not go down very much. To purge old data, you could use clean(garbage_collection = TRUE, purge = TRUE). To do garbage collection without removing any important targets, use drake_gc(). ## Uncaches individual targets and imported objects. clean(small, reg1, verbose = FALSE) clean(verbose = FALSE) # Cleans all targets out of the cache. drake_gc(verbose = FALSE) # Just garbage collection. clean(destroy = TRUE, verbose = FALSE) # removes the cache entirely 5.9 Automatic watching for changed dependencies As you have seen with reg2(), drake reacts to changes in dependencies. In other words, make() notices when your dependencies are different from last time, rebuilds any affected targets, and continues downstream. In particular, drake watches for nontrivial changes to the following items as long as they are connected to your workflow. The output values of targets in your workflow plan. The commands themselves. External files, if their names are enclosed in single quotes in commands. R objects mentioned in the commands, including but not limited to user-defined functions and functions from packages. R objects (but not files) nested inside user-defined functions. For packages exposed with expose_imports(), R objects (but not files) nested inside package functions. Files declared with file_in() inside your commands or custom functions. knitr reports declared with knitr_in() in your commands, along with any targets explicitly loaded in active code chunks with loadd() or readd(). Do not use knitr_in() inside your imported functions. Files declared with file_out() in your commands. Do not use file_out() inside your imported functions. To enhance reproducibility beyond the scope of drake, you might consider packrat and a container tool (such as Singularity or Docker. Packrat creates a tightly-controlled local library of packages to extend the shelf life of your project. And with containerization, you can execute your project on a virtual machine to ensure platform independence. Together, packrat and containers can help others reproduce your work even if they have different software and hardware. 5.10 A note on tidy evaluation Running commands in your R console is not always exactly like running them with make(). That’s because make() uses tidy evaluation as implemented in the rlang package. ## This workflow plan uses rlang&#39;s quasiquotation operator `!!`. my_plan &lt;- drake_plan(list = c( little_b = &quot;\\&quot;b\\&quot;&quot;, letter = &quot;!!little_b&quot; )) my_plan ## # A tibble: 2 x 2 ## target command ## &lt;chr&gt; &lt;chr&gt; ## 1 little_b &quot;\\&quot;b\\&quot;&quot; ## 2 letter !!little_b make(my_plan) ## target little_b ## target letter readd(letter) ## [1] &quot;b&quot; For the commands you specify the free-form ... argument, drake_plan() also supports tidy evaluation. For example, it supports quasiquotation with the !! argument. Use tidy_evaluation = FALSE or the list argument to suppress this behavior. my_variable &lt;- 5 drake_plan( a = !!my_variable, b = !!my_variable + 1, list = c(d = &quot;!!my_variable&quot;) ) ## # A tibble: 3 x 2 ## target command ## &lt;chr&gt; &lt;chr&gt; ## 1 a 5 ## 2 b 5 + 1 ## 3 d !!my_variable drake_plan( a = !!my_variable, b = !!my_variable + 1, list = c(d = &quot;!!my_variable&quot;), tidy_evaluation = FALSE ) ## # A tibble: 3 x 2 ## target command ## &lt;chr&gt; &lt;chr&gt; ## 1 a !!my_variable ## 2 b !!my_variable + 1 ## 3 d !!my_variable For instances of !! that remain in the workflow plan, make() will run these commands in tidy fashion, evaluating the !! operator using the environment you provided. 5.11 Need more speed? Drake has extensive high-performance computing support, from local multicore processing to serious distributed computing across multiple nodes of a cluster. See the high-performance computing chapter for detailed instructions. "],
["best-practices.html", "Chapter 6 General best practices for drake projects 6.1 How to organize your files 6.2 Generating workflow plan data frames 6.3 Remote data sources", " Chapter 6 General best practices for drake projects This chapter describes general best practices for creating, configuring, and running drake projects. It answers frequently asked questions and clears up common misconceptions, and it will continuously develop in response to community feedback. 6.1 How to organize your files 6.1.1 Examples For examples of how to structure your code files, see the beginner oriented example projects: mtcars gsp packages Write the code directly with the drake_example() function. drake_example(&quot;mtcars&quot;) drake_example(&quot;gsp&quot;) drake_example(&quot;packages&quot;) In practice, you do not need to organize your files the way the examples do, but it does happen to be a reasonable way of doing things. 6.1.2 Where do you put your code? It is best to write your code as a bunch of functions. You can save those functions in R scripts and then source() them before doing anything else. ## Load functions get_data(), analyze_data, and summarize_results() source(&quot;my_functions.R&quot;) Then, set up your workflow plan data frame. good_plan &lt;- drake_plan( my_data = get_data(file_in(&quot;data.csv&quot;)), # External files need to be in commands explicitly. # nolint my_analysis = analyze_data(my_data), my_summaries = summarize_results(my_data, my_analysis) ) good_plan ## # A tibble: 3 x 2 ## target command ## &lt;chr&gt; &lt;chr&gt; ## 1 my_data &quot;get_data(file_in(\\&quot;data.csv\\&quot;))&quot; ## 2 my_analysis analyze_data(my_data) ## 3 my_summaries summarize_results(my_data, my_analysis) Drake knows that my_analysis depends on my_data because my_data is an argument to analyze_data(), which is part of the command for my_analysis. config &lt;- drake_config(good_plan) vis_drake_graph(config) Now, you can call make() to build the targets. make(good_plan) If your commands are really long, just put them in larger functions. Drake analyzes imported functions for non-file dependencies. 6.1.3 Remember: your commands are code chunks, not R scripts Some people are accustomed to dividing their work into R scripts and then calling source() to run each step of the analysis. For example you might have the following files. get_data.R analyze_data.R summarize_results.R If you migrate to drake, you may be tempted to set up a workflow plan like this. bad_plan &lt;- drake_plan( my_data = source(file_in(&quot;get_data.R&quot;)), my_analysis = source(file_in(&quot;analyze_data.R&quot;)), my_summaries = source(file_in(&quot;summarize_data.R&quot;)) ) bad_plan ## # A tibble: 3 x 2 ## target command ## &lt;chr&gt; &lt;chr&gt; ## 1 my_data &quot;source(file_in(\\&quot;get_data.R\\&quot;))&quot; ## 2 my_analysis &quot;source(file_in(\\&quot;analyze_data.R\\&quot;))&quot; ## 3 my_summaries &quot;source(file_in(\\&quot;summarize_data.R\\&quot;))&quot; But now, the dependency structure of your work is broken. Your R script files are dependencies, but since my_data is not mentioned in a function or command, drake does not know that my_analysis depends on it. ## [[1]] ## [1] TRUE ## ## [[2]] ## [1] TRUE ## ## [[3]] ## [1] TRUE config &lt;- drake_config(bad_plan) vis_drake_graph(config) ## [[1]] ## [1] TRUE ## ## [[2]] ## [1] TRUE ## ## [[3]] ## [1] TRUE Dangers: In the first make(bad_plan, jobs = 2), drake will try to build my_data and my_analysis at the same time even though my_data must finish before my_analysis begins. Drake is oblivious to data.csv since it is not explicitly mentioned in a workflow plan command. So when data.csv changes, make(bad_plan) will not rebuild my_data. my_analysis will not update when my_data changes. The return value of source() is formatted counter-intuitively. If source(file_in(&quot;get_data.R&quot;)) is the command for my_data, then my_data will always be a list with elements &quot;value&quot; and &quot;visible&quot;. In other words, source(file_in(&quot;get_data.R&quot;))$value is really what you would want. In addition, this source()-based approach is simply inconvenient. Drake rebuilds my_data every time get_data.R changes, even when those changes are just extra comments or blank lines. On the other hand, in the previous plan that uses my_data = get_data(), drake does not trigger rebuilds when comments or whitespace in get_data() are modified. Drake is R-focused, not file-focused. If you embrace this viewpoint, your work will be easier. 6.1.4 File output targets In your plan, the file_out() function tells drake that your target is an external file rather than an ordinary R object. plan &lt;- drake_plan( writeLines(text = letters[1:6], con = file_out(&quot;file.txt&quot;)) ) plan ## # A tibble: 1 x 2 ## target command ## &lt;chr&gt; &lt;chr&gt; ## 1 &quot;\\&quot;file.txt\\&quot;&quot; &quot;writeLines(text = letters[1:6], con = file_out(\\&quot;file.t… Now, make() knows to expect a file called file.txt. make(plan) ## target file &quot;file.txt&quot; And if you manually mangle file.txt by accident, make() restores it to its reproducible state. writeLines(text = &quot;123&quot;, con = file_out(&quot;file.txt&quot;)) make(plan) ## target file &quot;file.txt&quot; make(plan) ## All targets are already up to date. But just because your command produces files does not mean you need to track them. plan &lt;- drake_plan(real_output = long_job()) make(plan) list.files() ### [1] &quot;date-time.log&quot; &quot;error.log&quot; &quot;console.log&quot; These log files probably have nothing to do with the objectives of your research. If that is the case, you can safely ignore them with no loss of reproducibility. Generally speaking, drake was designed to be as R-focused as possible, which means you should treat targets as R objects most of the time. External files are really an afterthought. This might be an uncomfortable notion. You may be accustomed to generating lots of files. drake_plan( write.csv(tabulate_results(data), file_out(&quot;results.csv&quot;)), ggsave(my_ggplot(data), file = file_out(&quot;plot.pdf&quot;)) ) ## # A tibble: 2 x 2 ## target command ## &lt;chr&gt; &lt;chr&gt; ## 1 &quot;\\&quot;results.csv\\&quot;&quot; &quot;write.csv(tabulate_results(data), file_out(\\&quot;results… ## 2 &quot;\\&quot;plot.pdf\\&quot;&quot; &quot;ggsave(my_ggplot(data), file = file_out(\\&quot;plot.pdf\\&quot;… But R object targets are much more convenient in the long run. If you really want to display them, consolidate them all in an R Markdown report at the end of the pipeline to reduce the number of output files. drake_plan( tab_results = tabulate_results(data), data_plot = my_ggplot(data), rmarkdown::render( knitr_in(&quot;report.Rmd&quot;), # References tab_results` and data_plot in active code chunks using loadd() or readd(). output_file = file_out(&quot;report.html&quot;) ) ) ## # A tibble: 3 x 2 ## target command ## &lt;chr&gt; &lt;chr&gt; ## 1 tab_results tabulate_results(data) ## 2 data_plot my_ggplot(data) ## 3 &quot;\\&quot;report.html\\&quot;&quot; &quot;rmarkdown::render(knitr_in(\\&quot;report.Rmd\\&quot;), output_f… But sometimes, you may unavoidably have multiple important files for each target. For example, maybe you work with spatial data and use the sf package. st_write(spatial_data, &quot;spatial_data.shp&quot;, driver = &quot;ESRI Shapefile&quot;) ### Creates: ### - &quot;spatial_data.shp&quot; ### - &quot;spatial_data.shx&quot; ### - &quot;spatial_data.prj&quot; ### - &quot;spatial_data.dbf&quot; Later targets may depend on many of these files, but there can only be one output file per target. So what do we do? Spoof drake: pick one file to be the real target, and let the other files be targets that depend on it. library(drake) library(magrittr) drake_plan( st_write(spatial_data, file_out(&quot;spatial_data.shp&quot;), driver = &quot;ESRI Shapefile&quot;), c(file_out(&quot;spatial_data.EXTN&quot;), file_in(&quot;spatial_data.shp&quot;)), out = process_shx(file_in(&quot;spatial_data.EXTN&quot;)) ) %&gt;% evaluate_plan(wildcard = &quot;EXTN&quot;, values = c(&quot;shx&quot;, &quot;prj&quot;, &quot;dbj&quot;)) ## # A tibble: 7 x 2 ## target command ## &lt;chr&gt; &lt;chr&gt; ## 1 &quot;\\&quot;spatial_data.shp\\&quot;&quot; &quot;st_write(spatial_data, file_out(\\&quot;spatial_data.… ## 2 &quot;\\&quot;spatial_data.shx\\&quot;&quot; &quot;c(file_out(\\&quot;spatial_data.shx\\&quot;), file_in(\\&quot;spa… ## 3 &quot;\\&quot;spatial_data.prj\\&quot;&quot; &quot;c(file_out(\\&quot;spatial_data.prj\\&quot;), file_in(\\&quot;spa… ## 4 &quot;\\&quot;spatial_data.dbj\\&quot;&quot; &quot;c(file_out(\\&quot;spatial_data.dbj\\&quot;), file_in(\\&quot;spa… ## 5 out_shx &quot;process_shx(file_in(\\&quot;spatial_data.shx\\&quot;))&quot; ## 6 out_prj &quot;process_shx(file_in(\\&quot;spatial_data.prj\\&quot;))&quot; ## 7 out_dbj &quot;process_shx(file_in(\\&quot;spatial_data.dbj\\&quot;))&quot; But be warned: If you manually mangle spatial_data.shx, spatial_data.prj or spatial_data.dbj later on, make() will not restore them. Having lots of output files can also slow down the construction of workflow plan data frames (ref: issue 366). It may actually be safer to divide the workflow into two pipelines with separate caches and separate plans. That way, all the output files from the first pipeline, tracked or not tracked, become inputs to the second pipeline. An overarching R script can run both pipelines back to back. plan1 &lt;- drake_plan( st_write(spatial_data, file_out(&quot;spatial_data.shp&quot;), driver = &quot;ESRI Shapefile&quot;) ) plan2 &lt;- drake_plan(out = process_shx(file_in(&quot;spatial_data.EXTN&quot;)))%&gt;% evaluate_plan(wildcard = &quot;EXTN&quot;, values = c(&quot;shx&quot;, &quot;prj&quot;, &quot;dbj&quot;)) cache1 &lt;- new_cache(path = &quot;cache1&quot;) cache2 &lt;- new_cache(path = &quot;cache2&quot;) make(plan1, cache = cache1) make(plan2, cache = cache2) See the storage guide for more on caching, particularly functions get_cache() and this_cache(). 6.1.5 R Markdown and knitr reports For a serious project, you should use drake’s make() function outside knitr. In other words, you should treat R Markdown reports and other knitr documents as targets and imports, not as a way to run make(). Viewed as targets, drake makes special exceptions for R Markdown reports and other knitr reports such as *.Rmd and *.Rnw files. Not every drake project needs them, but it is good practice to use them to summarize the final results of a project once all the other targets have already been built. The mtcars example, for instance, has an R Markdown report. report.Rmd is knitted to build report.md, which summarizes the final results. To see where report.md will be built, look to the right of the dependency graph. load_mtcars_example(overwrite = TRUE) # Get the code with drake_example(&quot;mtcars&quot;). ## Warning in load_mtcars_example(overwrite = TRUE): Overwriting file ## &#39;report.Rmd&#39;. config &lt;- drake_config(my_plan) vis_drake_graph(config) Drake treats knitr report as a special cases. Whenever drake sees knit() or render() (rmarkdown) mentioned in a command, it dives into the source file to look for dependencies. Consider report.Rmd, which you can view here. When drake sees readd(small) in an active code chunk, it knows report.Rmd depends on the target called small, and it draws the appropriate arrow in the dependency graph above. And if small ever changes, make(my_plan) will re-process report.Rmd to produce the target file report.md. knitr reports are the only kind of file that drake analyzes for dependencies. It does not give R scripts the same special treatment. 6.1.6 Workflows as R packages The R package structure is a great way to organize the files of your project. Writing your own package to contain your data science workflow is a good idea, but you will need to Use expose_imports() to properly account for all your nested function dependencies, and If you load the package with devtools::load_all(), set the prework argument of make(): e.g. make(prework = &quot;devtools::load_all()&quot;). Thanks to Jasper Clarkberg for the workaround behind expose_imports(). 6.1.6.1 Advantages of putting workflows in R packages The file organization of R packages is a well-understood community standard. If you follow it, your work may be more readable and thus reproducible. R package installation is a standard process. The system makes it easier for others to obtain and run your code. You get development and quality control tools for free: helpers for loading code and creating files, unit testing, package checks, code coverage, and continuous integration. 6.1.6.2 The problem For drake, there is one problem: nested functions. Drake always looks for imported functions nested in other imported functions, but only in your environment. When it sees a function from a package, it does not look in its body for other imports. To see this, consider the digest() function from the digest package. Digest package is a utility for computing hashes, not a data science workflow, but I will use it to demonstrate how drake treats imports from packages. library(digest) g &lt;- function(x){ digest(x) } f &lt;- function(x){ g(x) } plan &lt;- drake_plan(x = f(1)) ## Here are the reproducibly tracked objects in the workflow. tracked(plan) ## [1] &quot;x&quot; &quot;g&quot; &quot;digest&quot; &quot;f&quot; ## But the `digest()` function has dependencies too. ## Because `drake` knows `digest()` is from a package, ## it ignores these dependencies by default. head(deps_code(digest), 10) ## [1] &quot;any&quot; &quot;as.integer&quot; &quot;as.raw&quot; ## [4] &quot;base::serialize&quot; &quot;.Call&quot; &quot;digest_impl&quot; ## [7] &quot;.errorhandler&quot; &quot;file.access&quot; &quot;file.exists&quot; ## [10] &quot;file.info&quot; 6.1.6.3 The solution To force drake to dive deeper into the nested functions in a package, you must use expose_imports(). Again, I demonstrate with the digest package package, but you should really only do this with a package you write yourself to contain your workflow. For external packages, packrat is a much better solution for package reproducibility. expose_imports(digest) ## &lt;environment: R_GlobalEnv&gt; new_objects &lt;- tracked(plan) head(new_objects, 10) ## [1] &quot;digest&quot; &quot;return&quot; &quot;as.integer&quot; &quot;as.raw&quot; &quot;.Call&quot; ## [6] &quot;match.arg&quot; &quot;stop&quot; &quot;warning&quot; &quot;formals&quot; &quot;isTRUE&quot; length(new_objects) ## [1] 32 ## Now when you call `make()`, `drake` will dive into `digest` ## to import dependencies. cache &lt;- storr::storr_environment() # just for examples make(plan, cache = cache) ## target x head(cached(cache = cache), 10) ## [1] &quot;any&quot; &quot;as.integer&quot; &quot;as.raw&quot; ## [4] &quot;base::serialize&quot; &quot;digest&quot; &quot;digest_impl&quot; ## [7] &quot;f&quot; &quot;file.access&quot; &quot;file.exists&quot; ## [10] &quot;file.info&quot; length(cached(cache = cache)) ## [1] 30 ## [1] TRUE 6.2 Generating workflow plan data frames Drake has the following functions to generate workflow plan data frames (the plan argument of make(), where you list your targets and commands). drake_plan() evaluate_plan() expand_plan() gather_plan() reduce_plan() plan_analyses() plan_summaries() Except for drake_plan(), they all use wildcards as templates. For example, suppose your workflow checks several metrics of several schools. The idea is to write a workflow plan with your metrics and let the wildcard templating expand over the available schools. hard_plan &lt;- drake_plan( credits = check_credit_hours(school__), students = check_students(school__), grads = check_graduations(school__), public_funds = check_public_funding(school__) ) evaluate_plan( hard_plan, rules = list(school__ = c(&quot;schoolA&quot;, &quot;schoolB&quot;, &quot;schoolC&quot;)) ) ## # A tibble: 12 x 2 ## target command ## &lt;chr&gt; &lt;chr&gt; ## 1 credits_schoolA check_credit_hours(schoolA) ## 2 credits_schoolB check_credit_hours(schoolB) ## 3 credits_schoolC check_credit_hours(schoolC) ## 4 students_schoolA check_students(schoolA) ## 5 students_schoolB check_students(schoolB) ## 6 students_schoolC check_students(schoolC) ## 7 grads_schoolA check_graduations(schoolA) ## 8 grads_schoolB check_graduations(schoolB) ## 9 grads_schoolC check_graduations(schoolC) ## 10 public_funds_schoolA check_public_funding(schoolA) ## 11 public_funds_schoolB check_public_funding(schoolB) ## 12 public_funds_schoolC check_public_funding(schoolC) But what if some metrics do not make sense? For example, what if schoolC is a completely privately-funded school? With no public funds, check_public_funds(schoolC) may quit in error if we are not careful. This is where setting up workflow plans gets tricky. You may need to use an explicit grid of wildcard values. library(magrittr) rules_grid &lt;- tibble::tibble( school_ = c(&quot;schoolA&quot;, &quot;schoolB&quot;, &quot;schoolC&quot;), funding_ = c(&quot;public&quot;, &quot;public&quot;, &quot;private&quot;), ) %&gt;% tidyr::crossing(cohort_ = c(&quot;2012&quot;, &quot;2013&quot;, &quot;2014&quot;, &quot;2015&quot;)) %&gt;% dplyr::filter(!(school_ == &quot;schoolB&quot; &amp; cohort_ %in% c(&quot;2012&quot;, &quot;2013&quot;))) %&gt;% print() ## # A tibble: 10 x 3 ## school_ funding_ cohort_ ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 schoolA public 2012 ## 2 schoolA public 2013 ## 3 schoolA public 2014 ## 4 schoolA public 2015 ## 5 schoolB public 2014 ## 6 schoolB public 2015 ## 7 schoolC private 2012 ## 8 schoolC private 2013 ## 9 schoolC private 2014 ## 10 schoolC private 2015 Then, expand out your plan manually. plan &lt;- drake_plan( credits = check_credit_hours(&quot;school_&quot;, &quot;funding_&quot;, &quot;cohort_&quot;), students = check_students(&quot;school_&quot;, &quot;funding_&quot;, &quot;cohort_&quot;), grads = check_graduations(&quot;school_&quot;, &quot;funding_&quot;, &quot;cohort_&quot;), public_funds = check_public_funding(&quot;school_&quot;, &quot;funding_&quot;, &quot;cohort_&quot;), strings_in_dots = &quot;literals&quot; )[c(rep(1, 4), rep(2, 2), rep(3, 4)), ] suffixes &lt;- apply(rules_grid, 1, paste, sep = &quot;_&quot;) plan$target &lt;- paste(plan$target, suffixes, sep = &quot;_&quot;) ## Error in `$&lt;-.data.frame`(`*tmp*`, target, value = c(&quot;credits_schoolA&quot;, : replacement has 30 rows, data has 10 plan ## # A tibble: 10 x 2 ## target command ## &lt;chr&gt; &lt;chr&gt; ## 1 credits &quot;check_credit_hours(\\&quot;school_\\&quot;, \\&quot;funding_\\&quot;, \\&quot;cohort_\\&quot;)&quot; ## 2 credits &quot;check_credit_hours(\\&quot;school_\\&quot;, \\&quot;funding_\\&quot;, \\&quot;cohort_\\&quot;)&quot; ## 3 credits &quot;check_credit_hours(\\&quot;school_\\&quot;, \\&quot;funding_\\&quot;, \\&quot;cohort_\\&quot;)&quot; ## 4 credits &quot;check_credit_hours(\\&quot;school_\\&quot;, \\&quot;funding_\\&quot;, \\&quot;cohort_\\&quot;)&quot; ## 5 students &quot;check_students(\\&quot;school_\\&quot;, \\&quot;funding_\\&quot;, \\&quot;cohort_\\&quot;)&quot; ## 6 students &quot;check_students(\\&quot;school_\\&quot;, \\&quot;funding_\\&quot;, \\&quot;cohort_\\&quot;)&quot; ## 7 grads &quot;check_graduations(\\&quot;school_\\&quot;, \\&quot;funding_\\&quot;, \\&quot;cohort_\\&quot;)&quot; ## 8 grads &quot;check_graduations(\\&quot;school_\\&quot;, \\&quot;funding_\\&quot;, \\&quot;cohort_\\&quot;)&quot; ## 9 grads &quot;check_graduations(\\&quot;school_\\&quot;, \\&quot;funding_\\&quot;, \\&quot;cohort_\\&quot;)&quot; ## 10 grads &quot;check_graduations(\\&quot;school_\\&quot;, \\&quot;funding_\\&quot;, \\&quot;cohort_\\&quot;)&quot; Finally, call evaluate_plan() with expand = FALSE and always_rename = TRUE. drake_plan( credits = check_credit_hours(&quot;school_&quot;, &quot;funding_&quot;, &quot;cohort_&quot;), students = check_students(&quot;school_&quot;, &quot;funding_&quot;, &quot;cohort_&quot;), grads = check_graduations(&quot;school_&quot;, &quot;funding_&quot;, &quot;cohort_&quot;), public_funds = check_public_funding(&quot;school_&quot;, &quot;funding_&quot;, &quot;cohort_&quot;), strings_in_dots = &quot;literals&quot; )[c(rep(1, 4), rep(2, 2), rep(3, 4)), ] %&gt;% evaluate_plan( rules = rules_grid, expand = FALSE, always_rename = TRUE ) ## # A tibble: 10 x 2 ## target command ## &lt;chr&gt; &lt;chr&gt; ## 1 credits_schoolA_public_2012 &quot;check_credit_hours(\\&quot;schoolA\\&quot;, \\&quot;public… ## 2 credits_schoolA_public_2013 &quot;check_credit_hours(\\&quot;schoolA\\&quot;, \\&quot;public… ## 3 credits_schoolA_public_2014 &quot;check_credit_hours(\\&quot;schoolA\\&quot;, \\&quot;public… ## 4 credits_schoolA_public_2015 &quot;check_credit_hours(\\&quot;schoolA\\&quot;, \\&quot;public… ## 5 students_schoolB_public_2014 &quot;check_students(\\&quot;schoolB\\&quot;, \\&quot;public\\&quot;, … ## 6 students_schoolB_public_2015 &quot;check_students(\\&quot;schoolB\\&quot;, \\&quot;public\\&quot;, … ## 7 grads_schoolC_private_2012 &quot;check_graduations(\\&quot;schoolC\\&quot;, \\&quot;private… ## 8 grads_schoolC_private_2013 &quot;check_graduations(\\&quot;schoolC\\&quot;, \\&quot;private… ## 9 grads_schoolC_private_2014 &quot;check_graduations(\\&quot;schoolC\\&quot;, \\&quot;private… ## 10 grads_schoolC_private_2015 &quot;check_graduations(\\&quot;schoolC\\&quot;, \\&quot;private… Thanks to Alex Axthelm for this example in issue 235. 6.3 Remote data sources Some workflows rely on remote data from the internet, and the workflow needs to refresh when the datasets change. As an example, let us consider the download logs of CRAN packages. library(drake) library(R.utils) # For unzipping the files we download. library(curl) # For downloading data. library(httr) # For querying websites. url &lt;- &quot;http://cran-logs.rstudio.com/2018/2018-02-09-r.csv.gz&quot; How do we know when the data at the URL changed? We get the time that the file was last modified. (Alternatively, we could use an HTTP ETag.) query &lt;- HEAD(url) timestamp &lt;- query$headers[[&quot;last-modified&quot;]] timestamp ## [1] &quot;Mon, 12 Feb 2018 16:34:48 GMT&quot; In our workflow plan, the timestamp is a target and a dependency. When the timestamp changes, so does everything downstream. cranlogs_plan &lt;- drake_plan( timestamp = HEAD(url)$headers[[&quot;last-modified&quot;]], logs = get_logs(url, timestamp), strings_in_dots = &quot;literals&quot; ) cranlogs_plan ## # A tibble: 2 x 2 ## target command ## &lt;chr&gt; &lt;chr&gt; ## 1 timestamp &quot;HEAD(url)$headers[[\\&quot;last-modified\\&quot;]]&quot; ## 2 logs get_logs(url, timestamp) To make sure we always have the latest timestamp, we use the &quot;always&quot; trigger. (For more on triggers, see the guide to debugging and testing drake projects.) cranlogs_plan$trigger &lt;- c(&quot;always&quot;, &quot;any&quot;) cranlogs_plan ## # A tibble: 2 x 3 ## target command trigger ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 timestamp &quot;HEAD(url)$headers[[\\&quot;last-modified\\&quot;]]&quot; always ## 2 logs get_logs(url, timestamp) any Lastly, we define the get_logs() function, which actually downloads the data. ## The ... is just so we can write dependencies as function arguments ## in the workflow plan. get_logs &lt;- function(url, ...){ curl_download(url, &quot;logs.csv.gz&quot;) # Get a big file. gunzip(&quot;logs.csv.gz&quot;, overwrite = TRUE) # Unzip it. out &lt;- read.csv(&quot;logs.csv&quot;, nrows = 4) # Extract the data you need. unlink(c(&quot;logs.csv.gz&quot;, &quot;logs.csv&quot;)) # Remove the big files out # Value of the target. } When we are ready, we run the workflow. make(cranlogs_plan) ## Unloading targets from environment: ## timestamp ## target timestamp: trigger &quot;always&quot; ## target logs ## Used non-default triggers. Some targets may not be up to date. readd(logs) ## date time size version os country ip_id ## 1 2018-02-09 13:01:13 82375220 3.4.3 win RO 1 ## 2 2018-02-09 13:02:06 74286541 3.3.3 win US 2 ## 3 2018-02-09 13:02:10 82375216 3.4.3 win US 3 ## 4 2018-02-09 13:03:30 82375220 3.4.3 win IS 4 "],
["debug.html", "Chapter 7 Debugging and testing drake projects 7.1 The configuration list 7.2 Plan your work. 7.3 Test with triggers. 7.4 Skipping imports 7.5 Impose timeouts and retries 7.6 Diagnose failures. 7.7 Debrief a build session. 7.8 Start tinkering.", " Chapter 7 Debugging and testing drake projects This chapter is a guide to debugging and testing drake projects. Please also see the compendium of cautionary notes, which addresses drake’s known edge cases, pitfalls, and weaknesses that may or may not be fixed in future releases. For the most up-to-date information on unhandled edge cases, please visit the issue tracker, where you can submit your own bug reports as well. Be sure to search the closed issues too, especially if you are not using the most up-to-date development version. 7.1 The configuration list Most of drake’s functions rely on a central config list. An understanding of config will help you grasp the internals. make() and drake_config() both return the config list. Unlike make(), drake_config()’s return value is visible, and its only purpose is to construct your config. load_mtcars_example() # Get the code with drake_example(&quot;mtcars&quot;). config &lt;- drake_config(my_plan) sort(names(config)) ## [1] &quot;args&quot; &quot;cache&quot; &quot;cache_log_file&quot; ## [4] &quot;cache_path&quot; &quot;caching&quot; &quot;command&quot; ## [7] &quot;console_log_file&quot; &quot;cpu&quot; &quot;elapsed&quot; ## [10] &quot;ensure_workers&quot; &quot;envir&quot; &quot;evaluator&quot; ## [13] &quot;fetch_cache&quot; &quot;graph&quot; &quot;hook&quot; ## [16] &quot;jobs&quot; &quot;keep_going&quot; &quot;lazy_load&quot; ## [19] &quot;log_progress&quot; &quot;long_hash_algo&quot; &quot;makefile_path&quot; ## [22] &quot;parallelism&quot; &quot;plan&quot; &quot;prepend&quot; ## [25] &quot;prework&quot; &quot;pruning_strategy&quot; &quot;recipe_command&quot; ## [28] &quot;retries&quot; &quot;seed&quot; &quot;session&quot; ## [31] &quot;session_info&quot; &quot;short_hash_algo&quot; &quot;skip_imports&quot; ## [34] &quot;skip_safety_checks&quot; &quot;skip_targets&quot; &quot;targets&quot; ## [37] &quot;timeout&quot; &quot;trigger&quot; &quot;verbose&quot; The fields of config mostly arguments to make() and are documented there. The rest of the fields are as follows. graph: An igraph object with the directed acyclic graph (DAG) of the workflow. inventory: A running list of the cached objects in each storr namespace. Maintaining this list helps avoid repeated calls to config$cache$list(), which increases speed. long_hash_algo: Name of the long hash algorithm used throughout make(). Used to generate hash keys that will not become the names of files. See the custom storage guide for details. seed: The random number generator seed taken from the user’s R session. Each target is built reproducibly using a deterministic function of this seed, and the build does not change the seed outside the scope of the target’s command. short_hash_algo: Name of the short hash algorithm used throughout make(). Used to generate hash keys that could become names of files. See the custom storage guide for details. Early in make(), the config list is stored in the cache. You can retrieve it with read_drake_config() and you can access parts of it with some companion functions. read_drake_graph() read_drake_plan() 7.2 Plan your work. 7.2.1 Workflow plan data frames The workflow plan data frame is your responsibility, and it takes effort and care. Fortunately, functions in drake can help. You can check the plan for formatting issues, missing input files, etc. with the check_plan() function. load_mtcars_example() # Get the code with drake_example(&quot;mtcars&quot;). my_plan ## # A tibble: 15 x 2 ## target command ## &lt;chr&gt; &lt;chr&gt; ## 1 &quot;&quot; &quot;knit(knitr_in(\\&quot;report.Rmd\\&quot;), file_out(\\&quot;repo… ## 2 small simulate(48) ## 3 large simulate(64) ## 4 regression1_small reg1(small) ## 5 regression1_large reg1(large) ## 6 regression2_small reg2(small) ## 7 regression2_large reg2(large) ## 8 summ_regression1_small suppressWarnings(summary(regression1_small$resi… ## 9 summ_regression1_large suppressWarnings(summary(regression1_large$resi… ## 10 summ_regression2_small suppressWarnings(summary(regression2_small$resi… ## 11 summ_regression2_large suppressWarnings(summary(regression2_large$resi… ## 12 coef_regression1_small suppressWarnings(summary(regression1_small))$co… ## 13 coef_regression1_large suppressWarnings(summary(regression1_large))$co… ## 14 coef_regression2_small suppressWarnings(summary(regression2_small))$co… ## 15 coef_regression2_large suppressWarnings(summary(regression2_large))$co… check_plan(my_plan) # No issues. 7.2.2 Visualize your workflow. After quality-checking your plan, you should check that you understand how the steps of your workflow are interconnected. The web of dependencies affects which targets are built and which ones are skipped during make(). ## Hover, click, drag, zoom, and pan. See args &#39;from&#39; and &#39;to&#39;. config &lt;- drake_config(my_plan) vis_drake_graph(config, width = &quot;100%&quot;, height = &quot;500px&quot;) See the visualization chapter to learn more about how graphing can help (for example, how to visualize small subgraphs). If you want to take control of your own visNetwork graph, use the dataframes_graph() function to get data frames of nodes, edges, and legend nodes. 7.2.3 Check dependency relationships. Programmatically, several functions can help you check immediate dependencies. deps_code(reg2) ## [1] &quot;lm&quot; &quot;x2&quot; &quot;y&quot; ## knitr_in() makes sure your target depends on `report.Rmd` ## and any dependencies loaded with loadd() and readd() ## in the report&#39;s active code chunks. deps_code(my_plan$command[1]) ## [1] &quot;coef_regression2_small&quot; &quot;knit&quot; ## [3] &quot;large&quot; &quot;\\&quot;report.md\\&quot;&quot; ## [5] &quot;\\&quot;report.Rmd\\&quot;&quot; &quot;small&quot; deps_code(my_plan$command[nrow(my_plan)]) ## [1] &quot;regression2_large&quot; &quot;summary&quot; &quot;suppressWarnings&quot; Drake takes special precautions so that a target/import does not depend on itself. For example, deps_code(f) might return &quot;f&quot; if f() is a recursive function, but make() just ignores this conflict and runs as expected. In other words, make() automatically removes all self-referential loops in the dependency network. List all the reproducibly-tracked objects and files, including imports and targets. tracked(my_plan, targets = &quot;small&quot;) ## [1] &quot;nrow&quot; &quot;sample.int&quot; &quot;data.frame&quot; &quot;mtcars&quot; &quot;random_rows&quot; ## [6] &quot;small&quot; &quot;simulate&quot; tracked(my_plan) ## [1] &quot;nrow&quot; &quot;sample.int&quot; ## [3] &quot;data.frame&quot; &quot;summary&quot; ## [5] &quot;lm&quot; &quot;x&quot; ## [7] &quot;y&quot; &quot;x2&quot; ## [9] &quot;mtcars&quot; &quot;random_rows&quot; ## [11] &quot;coef_regression2_small&quot; &quot;knit&quot; ## [13] &quot;large&quot; &quot;\\&quot;report.Rmd\\&quot;&quot; ## [15] &quot;small&quot; &quot;simulate&quot; ## [17] &quot;reg1&quot; &quot;reg2&quot; ## [19] &quot;regression1_small&quot; &quot;suppressWarnings&quot; ## [21] &quot;regression1_large&quot; &quot;regression2_small&quot; ## [23] &quot;regression2_large&quot; &quot;\\&quot;report.md\\&quot;&quot; ## [25] &quot;summ_regression1_small&quot; &quot;summ_regression1_large&quot; ## [27] &quot;summ_regression2_small&quot; &quot;summ_regression2_large&quot; ## [29] &quot;coef_regression1_small&quot; &quot;coef_regression1_large&quot; ## [31] &quot;coef_regression2_large&quot; 7.2.4 Outdated, up to date, and missing items missed() reports import dependencies missing from your environment config &lt;- drake_config(my_plan, verbose = FALSE) missed(config) # Nothing is missing right now. ## [1] &quot;x&quot; &quot;y&quot; &quot;x2&quot; outdated() reports any targets that are outdated, plus any downstream targets that depend on them. outdated(config) ## [1] &quot;coef_regression1_large&quot; &quot;coef_regression1_small&quot; ## [3] &quot;coef_regression2_large&quot; &quot;coef_regression2_small&quot; ## [5] &quot;large&quot; &quot;regression1_large&quot; ## [7] &quot;regression1_small&quot; &quot;regression2_large&quot; ## [9] &quot;regression2_small&quot; &quot;\\&quot;report.md\\&quot;&quot; ## [11] &quot;small&quot; &quot;summ_regression1_large&quot; ## [13] &quot;summ_regression1_small&quot; &quot;summ_regression2_large&quot; ## [15] &quot;summ_regression2_small&quot; To find out why a target is out of date, you can load the storr-based cache and compare the appropriate hash keys to the output of dependency_profile(). To use dependency_profile(), be sure to supply the master configuration list as the config argument. The same is true for drake_meta(), another alternative. load_mtcars_example() # Get the code with drake_example(&quot;mtcars&quot;). config &lt;- make(my_plan, verbose = FALSE) ## Change a dependency. reg2 &lt;- function(d) { d$x3 &lt;- d$x ^ 3 lm(y ~ x3, data = d) } outdated(config) ## [1] &quot;coef_regression2_large&quot; &quot;coef_regression2_small&quot; ## [3] &quot;regression2_large&quot; &quot;regression2_small&quot; ## [5] &quot;\\&quot;report.md\\&quot;&quot; &quot;summ_regression2_large&quot; ## [7] &quot;summ_regression2_small&quot; dependency_profile(target = &quot;regression2_small&quot;, config = config) ## $cached_command ## [1] &quot;{\\n reg2(small) \\n}&quot; ## ## $current_command ## [1] &quot;{\\n reg2(small) \\n}&quot; ## ## $cached_file_modification_time ## NULL ## ## $cached_dependency_hash ## [1] &quot;b91a088b0ef9d46f13c59c3d312d45ee83717eaebafcd93d0c7431e4f9a1d3dc&quot; ## ## $current_dependency_hash ## [1] &quot;054b5f4bf8c3d833bf3aa830f7c1ff2af243355e8e6004f8362be1432ace3e20&quot; ## ## $hashes_of_dependencies ## reg2 small ## &quot;a48c685848ad87b1&quot; &quot;7d836504e5060e6d&quot; drake_meta(target = &quot;regression2_small&quot;, config = config) ## $target ## [1] &quot;regression2_small&quot; ## ## $imported ## [1] FALSE ## ## $foreign ## [1] TRUE ## ## $missing ## [1] FALSE ## ## $seed ## [1] 1034257256 ## ## $command ## [1] &quot;{\\n reg2(small) \\n}&quot; ## ## $depends ## [1] &quot;054b5f4bf8c3d833bf3aa830f7c1ff2af243355e8e6004f8362be1432ace3e20&quot; ## ## $file ## [1] NA config$cache$get_hash(key = &quot;small&quot;, namespace = &quot;kernels&quot;) # same ## [1] &quot;7d836504e5060e6d&quot; config$cache$get_hash(key = &quot;small&quot;) # same ## [1] &quot;7d836504e5060e6d&quot; config$cache$get_hash(key = &quot;reg2&quot;, namespace = &quot;kernels&quot;) # same ## [1] &quot;a48c685848ad87b1&quot; config$cache$get_hash(key = &quot;reg2&quot;) # different ## [1] &quot;0dcc46cfdf596985&quot; In drake, the “kernel” of a target or import is the piece of the output that is reproducibly tracked. For ordinary R objects, the kernel is just the object itself. For custom external files, it is a separate hash. But for functions, the kernel is the deparsed body of the function, together with the dependency hash if the function is imported (see drake:::store_function()). The internal functions drake:::meta() and drake:::meta_list() compute the metadata on each target that drake uses to decide which targets to build and which to skip (via drake:::should_build_target()). Then, after the target/import is processed, drake:::finish_meta() updates the metadata (except for the $missing element) before it is cached. See diagnose() to read available metadata, along with any errors, warnings, and messages generated during the build. str(diagnose(small)) ## List of 11 ## $ target : chr &quot;small&quot; ## $ imported : logi FALSE ## $ foreign : logi TRUE ## $ missing : logi TRUE ## $ seed : num 1.95e+09 ## $ command : chr &quot;{\\n simulate(48) \\n}&quot; ## $ depends : chr &quot;eb89933a9211e556671c06c5018dcdb7efdad4593b4adff4f88ee6a34de61f7f&quot; ## $ file : chr NA ## $ start : &#39;proc_time&#39; Named num [1:5] 39.22 1.539 50.729 0.252 0.204 ## ..- attr(*, &quot;names&quot;)= chr [1:5] &quot;user.self&quot; &quot;sys.self&quot; &quot;elapsed&quot; &quot;user.child&quot; ... ## $ time_command:&#39;data.frame&#39;: 1 obs. of 5 variables: ## ..$ item : chr &quot;small&quot; ## ..$ type : chr &quot;target&quot; ## ..$ elapsed: num 0 ## ..$ user : num 0 ## ..$ system : num 0 ## $ time_build :&#39;data.frame&#39;: 1 obs. of 5 variables: ## ..$ item : chr &quot;small&quot; ## ..$ type : chr &quot;target&quot; ## ..$ elapsed: num 0.004 ## ..$ user : num 0.003 ## ..$ system : num 0 str(diagnose(&quot;\\&quot;report.md\\&quot;&quot;)) ## List of 12 ## $ target : chr &quot;\\&quot;report.md\\&quot;&quot; ## $ imported : logi FALSE ## $ foreign : logi TRUE ## $ missing : logi TRUE ## $ seed : num 1.85e+09 ## $ command : chr &quot;{\\n knit(knitr_in(\\&quot;report.Rmd\\&quot;), file_out(\\&quot;report.md\\&quot;), quiet = TRUE) \\n}&quot; ## $ depends : chr &quot;c48c0247f07440bb89da71c0a50be4e40bd4ceaa4548f18717708174b3fadf17&quot; ## $ file : chr &quot;65f43df5f3fb7d0e2b78b2fa2ada9a635a7557780e79e08805156d60b53e7abc&quot; ## $ start : &#39;proc_time&#39; Named num [1:5] 39.367 1.539 50.877 0.252 0.204 ## ..- attr(*, &quot;names&quot;)= chr [1:5] &quot;user.self&quot; &quot;sys.self&quot; &quot;elapsed&quot; &quot;user.child&quot; ... ## $ time_command:&#39;data.frame&#39;: 1 obs. of 5 variables: ## ..$ item : chr &quot;\\&quot;report.md\\&quot;&quot; ## ..$ type : chr &quot;target&quot; ## ..$ elapsed: num 0.036 ## ..$ user : num 0.032 ## ..$ system : num 0.004 ## $ mtime : POSIXct[1:1], format: &quot;2018-06-19 05:16:04&quot; ## $ time_build :&#39;data.frame&#39;: 1 obs. of 5 variables: ## ..$ item : chr &quot;\\&quot;report.md\\&quot;&quot; ## ..$ type : chr &quot;target&quot; ## ..$ elapsed: num 0.04 ## ..$ user : num 0.036 ## ..$ system : num 0.004 If your target’s last build succeeded, then diagnose(your_target) has the most current information from that build. But if your target failed, then only diagnose(your_target)$error, diagnose(your_target)$warnings, and diagnose(your_target)$messages correspond to the failure, and all the other metadata correspond to the last build that completed without an error. 7.3 Test with triggers. To track dependencies and make decisions about what needs building, make() store the fingerprint, or hash, of each target. Hashing is great for detecting the right changes in targets, but if all you want to do is test and debug a workflow, the full rigor can be time-consuming. Fortunately, you can change the triggers that tell drake when to (re)build each target. Below, drake disregards outdatedness and just builds the targets that are missing. clean(verbose = FALSE) # Start from scratch config &lt;- make(my_plan, trigger = &quot;missing&quot;) ## target large: trigger &quot;missing&quot; ## target small: trigger &quot;missing&quot; ## target regression1_large: trigger &quot;missing&quot; ## target regression2_large: trigger &quot;missing&quot; ## target regression1_small: trigger &quot;missing&quot; ## target regression2_small: trigger &quot;missing&quot; ## target summ_regression1_large: trigger &quot;missing&quot; ## target coef_regression1_large: trigger &quot;missing&quot; ## target summ_regression2_large: trigger &quot;missing&quot; ## target coef_regression2_large: trigger &quot;missing&quot; ## target summ_regression1_small: trigger &quot;missing&quot; ## target coef_regression1_small: trigger &quot;missing&quot; ## target coef_regression2_small: trigger &quot;missing&quot; ## target summ_regression2_small: trigger &quot;missing&quot; ## target file &quot;report.md&quot;: trigger &quot;missing&quot; ## Used non-default triggers. Some targets may not be up to date. You can choose from any of the following triggers for all targets or for each target individually. always: Always build the target regardless of the circumstance, even if the target is already up to date. any: Apply all the triggers below (default). In other words, trigger a build if the command trigger, depends trigger, file trigger, or missing trigger is activated. command: Build if the workflow plan command changed since the last make() or the target is missing. depends: Build if any of the target’s dependencies changed since the last make() or if the target is missing. file: Build if the target is an output file and the file is either missing or corrupted. Also build if the file’s hash is missing from the cache. missing: Build if and only if the target is missing. To select triggers for individual targets, create an optional trigger column in the workflow plan data frame. Entries in this column override the trigger argument to make() my_plan$trigger &lt;- &quot;command&quot; my_plan$trigger[1] &lt;- &quot;file&quot; my_plan ## # A tibble: 15 x 3 ## target command trigger ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 &quot;&quot; &quot;knit(knitr_in(\\&quot;report.Rmd\\&quot;), file_ou… file ## 2 small simulate(48) command ## 3 large simulate(64) command ## 4 regression1_small reg1(small) command ## 5 regression1_large reg1(large) command ## 6 regression2_small reg2(small) command ## 7 regression2_large reg2(large) command ## 8 summ_regression1_small suppressWarnings(summary(regression1_sm… command ## 9 summ_regression1_large suppressWarnings(summary(regression1_la… command ## 10 summ_regression2_small suppressWarnings(summary(regression2_sm… command ## 11 summ_regression2_large suppressWarnings(summary(regression2_la… command ## 12 coef_regression1_small suppressWarnings(summary(regression1_sm… command ## 13 coef_regression1_large suppressWarnings(summary(regression1_la… command ## 14 coef_regression2_small suppressWarnings(summary(regression2_sm… command ## 15 coef_regression2_large suppressWarnings(summary(regression2_la… command ## Change an imported dependency: reg2 ## function(d) { ## d$x3 &lt;- d$x ^ 3 ## lm(y ~ x3, data = d) ## } reg2 &lt;- function(d) { d$x3 &lt;- d$x ^ 3 lm(y ~ x3, data = d) } make(my_plan, trigger = &quot;any&quot;) # Nothing changes! ## Used non-default triggers. Some targets may not be up to date. The outdated() function responds to triggers. For example, even if outdated(my_plan) shows all targets up to date, outdated(my_plan, trigger = &quot;always&quot;) will claim that all the targets are outdated. 7.4 Skipping imports Similar to triggers, you can also to skip the processing of imported objects and files. However, you should only use this for testing purposes. If some of your imports are not already cached and up to date, any built targets will be out of sync. In other words, outdated() is more likely to be wrong, and your project may no longer be reproducible. clean(verbose = FALSE) my_plan$trigger &lt;- NULL make(my_plan, skip_imports = TRUE) ## target large ## target small ## target regression1_large ## target regression2_large ## target regression1_small ## target regression2_small ## target summ_regression1_large ## target coef_regression1_large ## target summ_regression2_large ## target coef_regression2_large ## target summ_regression1_small ## target coef_regression1_small ## target coef_regression2_small ## target summ_regression2_small ## target file &quot;report.md&quot; ## Skipped the imports. If some imports are not already cached, targets could be out of date. 7.5 Impose timeouts and retries See the timeout, cpu, elapsed, and retries argument to make(). clean(verbose = FALSE) f &lt;- function(...){ Sys.sleep(1) } debug_plan &lt;- drake_plan(x = 1, y = f(x)) debug_plan ## # A tibble: 2 x 2 ## target command ## &lt;chr&gt; &lt;chr&gt; ## 1 x 1 ## 2 y f(x) withr::with_message_sink( stdout(), make(debug_plan, timeout = 1e-3, retries = 2) ) ## target x ## target y ## retry y: 1 of 2 ## retry y: 2 of 2 ## [2018-06-19 05:16:10] TimeoutException: reached CPU time limit [cpu=0.001s, ## elapsed=0.001s] ## Warning: No message sink to remove. To tailor these settings to each individual target, create new timeout, cpu, elapsed, or retries columns in your workflow plan. These columns override the analogous arguments to make(). clean(verbose = FALSE) debug_plan$timeout &lt;- c(1e-3, 2e-3) debug_plan$retries &lt;- 1:2 debug_plan ## # A tibble: 2 x 4 ## target command timeout retries ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; ## 1 x 1 0.001 1 ## 2 y f(x) 0.002 2 withr::with_message_sink( new = stdout(), make(debug_plan, timeout = Inf, retries = 0) ) ## Unloading targets from environment: ## x ## target x ## target y ## fail y ## Error: Target `y` failed. Call `diagnose(y)` for details. Error message: ## reached elapsed time limit ## Warning: No message sink to remove. 7.6 Diagnose failures. Drake records diagnostic metadata on all your targets, including the latest errors, warnings, messages, and other bits of context. diagnose(verbose = FALSE) # Targets with available metadata. ## [1] &quot;f&quot; &quot;Sys.sleep&quot; &quot;x&quot; &quot;y&quot; f &lt;- function(x){ if (x &lt; 0){ stop(&quot;`x` cannot be negative.&quot;) } x } bad_plan &lt;- drake_plan( a = 12, b = -a, my_target = f(b) ) bad_plan ## # A tibble: 3 x 2 ## target command ## &lt;chr&gt; &lt;chr&gt; ## 1 a 12 ## 2 b -a ## 3 my_target f(b) withr::with_message_sink( new = stdout(), make(bad_plan) ) ## target a ## target b ## target my_target ## fail my_target ## Error: Target `my_target` failed. Call `diagnose(my_target)` for details. Error message: ## `x` cannot be negative. ## Warning: No message sink to remove. failed(verbose = FALSE) # from the last make() only ## [1] &quot;my_target&quot; ## See also warnings and messages. error &lt;- diagnose(my_target, verbose = FALSE)$error error$message ## [1] &quot;`x` cannot be negative.&quot; error$call ## f(b) error$calls # View the traceback. ## [[1]] ## local({ ## f(b) ## }) ## ## [[2]] ## eval.parent(substitute(eval(quote(expr), envir))) ## ## [[3]] ## eval(expr, p) ## ## [[4]] ## eval(expr, p) ## ## [[5]] ## eval(quote({ ## f(b) ## }), new.env()) ## ## [[6]] ## eval(quote({ ## f(b) ## }), new.env()) ## ## [[7]] ## f(b) ## ## [[8]] ## stop(&quot;`x` cannot be negative.&quot;) To figure out what went wrong, you could try to build the failed target interactively. To do that, simply call drake_build(). This function first calls loadd(deps = TRUE) to load any missing dependencies (see the replace argument here) and then builds your target. ## Pretend we just opened a new R session. library(drake) ## Unloads target `b`. config &lt;- drake_config(plan = bad_plan) ## Unloading targets from environment: ## b ## my_target depends on b. &quot;b&quot; %in% ls() ## [1] FALSE ## Try to build my_target until the error is fixed. ## Skip all that pesky work checking dependencies. drake_build(my_target, config = config) ## target my_target ## fail my_target ## Error: Target `my_target` failed. Call `diagnose(my_target)` for details. Error message: ## `x` cannot be negative. ## The target failed, but the dependency was loaded. &quot;b&quot; %in% ls() ## [1] TRUE ## What was `b` again? b ## [1] -12 ## How was `b` used? diagnose(my_target)$message ## NULL diagnose(my_target)$call ## NULL f ## function(x){ ## if (x &lt; 0){ ## stop(&quot;`x` cannot be negative.&quot;) ## } ## x ## } ## Aha! The error was in f(). Let&#39;s fix it and try again. f &lt;- function(x){ x &lt;- abs(x) if (x &lt; 0){ stop(&quot;`x` cannot be negative.&quot;) } x } ## Now it works! ## Since you called make() previously, `config` is read from the cache ## if you do not supply it. drake_build(my_target) ## target my_target readd(my_target) ## [1] 12 7.6.1 Tidy evaluation: a caveat to diagnosing interactively Running commands in your R console is not always exactly like running them with make(). That’s because make() uses tidy evaluation as implemented in the rlang package. ## This workflow plan uses rlang&#39;s quasiquotation operator `!!`. my_plan &lt;- drake_plan(list = c( little_b = &quot;\\&quot;b\\&quot;&quot;, letter = &quot;!!little_b&quot; )) my_plan ## # A tibble: 2 x 2 ## target command ## &lt;chr&gt; &lt;chr&gt; ## 1 little_b &quot;\\&quot;b\\&quot;&quot; ## 2 letter !!little_b make(my_plan) ## target little_b ## target letter readd(letter) ## [1] &quot;b&quot; 7.7 Debrief a build session. After your project is at least somewhat built, you can inspect and read your results from the cache. make(my_plan, verbose = FALSE) ## drake_session(verbose = FALSE) # Prints the sessionInfo() of the last make(). # nolint cached(verbose = FALSE) ## [1] &quot;a&quot; &quot;b&quot; &quot;f&quot; &quot;letter&quot; &quot;little_b&quot; &quot;my_target&quot; ## [7] &quot;stop&quot; &quot;Sys.sleep&quot; &quot;x&quot; built(verbose = FALSE) ## [1] &quot;a&quot; &quot;b&quot; &quot;letter&quot; &quot;little_b&quot; &quot;my_target&quot; &quot;x&quot; imported(verbose = FALSE) ## [1] &quot;f&quot; &quot;stop&quot; &quot;Sys.sleep&quot; loadd(little_b, verbose = FALSE) little_b ## [1] &quot;b&quot; readd(letter, verbose = FALSE) ## [1] &quot;b&quot; progress(verbose = FALSE) ## Error in progress(verbose = FALSE): unused argument (verbose = FALSE) in_progress(verbose = FALSE) # Unfinished targets ## character(0) There are functions to help you locate the project’s cache. ## find_project() # nolint ## find_cache() # nolint For more information on the cache, see the chapter on storage and caches. 7.8 Start tinkering. The load_mtcars_example() function loads the mtcars example from drake_example(&quot;mtcars&quot;) right into your workspace. The workflow plan data frame, workspace, and import files are set up for you. Only make(my_plan) is left to you. Drake has many more built-in examples. To see your choices, use drake_examples() ## [1] &quot;Docker-psock&quot; &quot;gsp&quot; &quot;main&quot; ## [4] &quot;Makefile-cluster&quot; &quot;mtcars&quot; &quot;packages&quot; ## [7] &quot;sge&quot; &quot;slurm&quot; &quot;torque&quot; To write the files for an example, use drake_example(). drake_example(&quot;mtcars&quot;) drake_example(&quot;slurm&quot;) "],
["vis.html", "Chapter 8 Visualization with drake 8.1 Dependency reactivity 8.2 Subgraphs 8.3 Control the legend. 8.4 More flexibility", " Chapter 8 Visualization with drake Drake has powerful visuals to help you plan your project. You can generate an interactive workflow network with either drake_graph() or vis_drake_graph(). Then click, drag, hover, zoom, and pan. Use either the mouse or the green buttons near the bottom. 8.1 Dependency reactivity Initially, your entire project is out of date. library(drake) load_mtcars_example() # Get the code with drake_example(&quot;mtcars&quot;). config &lt;- drake_config(my_plan) vis_drake_graph(config) # Same as drake_graph() After make(), the whole project is all caught up. config &lt;- make(my_plan, jobs = 4, verbose = FALSE) vis_drake_graph(config) But when you change a dependency, some targets are out of date until the next make(my_plan). reg2 &lt;- function(d){ d$x3 &lt;- d$x ^ 3 lm(y ~ x3, data = d) } vis_drake_graph(config) 8.2 Subgraphs Graphs can grow enormous for serious projects, so there are multiple ways to focus on a manageable subgraph. The most brute-force way is to just pick a manual subset of nodes. However, with the subset argument, vis_drake_graph() may drop intermediate nodes and edges. vis_drake_graph( config, subset = c(&quot;regression2_small&quot;, file_store(&quot;report.md&quot;)) ) The rest of the subgraph functionality preserves connectedness. Use targets_only to ignore the imports. vis_drake_graph(config, targets_only = TRUE) Similarly, you can just show downstream nodes. vis_drake_graph(config, from = c(&quot;regression2_small&quot;, &quot;regression2_large&quot;)) Or upstream ones. vis_drake_graph(config, from = &quot;small&quot;, mode = &quot;in&quot;) In fact, let us just take a small neighborhood around a target in both directions. vis_drake_graph(config, from = &quot;small&quot;, mode = &quot;all&quot;, order = 1) 8.3 Control the legend. To remove superfluous information from the legend, set the full_legend argument to FALSE. vis_drake_graph(config, full_legend = FALSE) To remove the legend altogether, set the ncol_legend argument to 0. vis_drake_graph(config, ncol_legend = 0) 8.4 More flexibility We have only scratched the surface of vis_drake_graph(). The help files (?vis_drake_graph) document much more functionality. In particular, the dataframes_graph() and render_drake_graph() functions let you customize your own visNetwork graph. "],
["hpc.html", "Chapter 9 High-performance computing with drake 9.1 Batch mode for long workflows 9.2 Let drake schedule your targets. 9.3 Parallel backends 9.4 Local workers 9.5 Remote workers 9.6 Scheduling algorithms 9.7 Final thoughts 9.8 Footnotes", " Chapter 9 High-performance computing with drake Drake is not only a reproducibility tool, but also a high-performance computing engine. To activate parallel computing, just set the jobs argument of make() to a value greater than 1. Below, up to 2 targets can run simultaneously at any given time. library(drake) load_mtcars_example() make(my_plan, jobs = 2) 9.1 Batch mode for long workflows To deploy serious long workflows, we recommend putting the call to make() in a script (say, drake_work.R) and running it in an unobtrusive background process that persists after you log out. In the Linux command line, this is straightforward. nohup nice -19 R CMD BATCH drake_work.R & Or, you could call drake inside an overarching Makefile that chains multiple stages together in a larger reproducible pipeline. (See Karl Broman’s post on Makefiles for reproducible research.) all: final_output.pdf final_output.pdf: python_magic.py results_summary.csv python python_magic.py results_summary.csv: drake_work.R Rscript drake_work.R clean: rm -rf .drake Then, run your whole pipleine in a persistent background process. nohup nice -19 R CMD BATCH make & If you do write a custom Makefile at the root of your project and you plan to use make(parallelism = &quot;Makefile&quot;), please read about make(parallelism = &quot;Makefile&quot;) later in this document to avoid potential conflicts between your Makefile and the one drake writes. 9.2 Let drake schedule your targets. When you deploy your project, drake uses the dependency network to figure out how to run your work in parallel. You as the user do not have to micromanage when individual targets are built. load_mtcars_example() config &lt;- drake_config(my_plan) vis_drake_graph(config) 9.3 Parallel backends There are multiple ways to walk this graph and multiple ways to launch workers, and every project has its own needs. Thus, drake supports multiple parallel backends. Choose the backend with the parallelism argument. make(my_plan, parallelism = &quot;parLapply&quot;, jobs = 2) You can use a different backend for the imports than you select for the targets. If you do so, you force all the imports to be processed before any of the targets are built, but you might want to do so anyway. For example, staged scheduling could be great for imports even when it is not be the right choice for the targets (more on that later). make( my_plan, parallelism = c(imports = &quot;mclapply_staged&quot;, targets = &quot;mclapply&quot;), jobs = 2 ) List your options with parallelism_choices(). parallelism_choices() ## [1] &quot;mclapply&quot; &quot;parLapply&quot; &quot;mclapply_staged&quot; ## [4] &quot;parLapply_staged&quot; &quot;future&quot; &quot;future_lapply&quot; ## [7] &quot;Makefile&quot; The backends vary widely in terms of how the workers deploy and how they are scheduled. Deploy: local Deploy: remote Schedule: persistent “mclapply”, “parLapply” “future_lapply” Schedule: transient “future”, “Makefile” Schedule: staged “mclapply_staged”, “parLapply_staged” The next sections describe how and when to use each scheduling algorithm and deployment strategy. 9.4 Local workers Local workers deploy as separate forks or processes to you computer. The &quot;mclapply&quot; and &quot;mclapply_staged&quot; backends uses the mclapply() function from the parallel package to launch workers. make(my_plan, parallelism = &quot;mclapply&quot;, jobs = 2) make(my_plan, parallelism = &quot;mclapply_staged&quot;, jobs = 2) Workers are quicker to launch than in any other drake backend, so these two choices are the lowest-overhead options. However, they have limitations: the mclapply() function is inefficient with respect to computer memory (see explanations here and here) and it cannot launch multiple workers on Windows. For this reason, drake supports platform agnostic backends &quot;parLapply&quot; and &quot;parLapply_staged&quot;, both of which are based on the parLapply() function from the parallel package. These options work on Windows, but each make() requires extra overhead to create a parallel socket (PSOCK) cluster. make(my_plan, parallelism = &quot;parLapply&quot;, jobs = 2) make(my_plan, parallelism = &quot;parLapply_staged&quot;, jobs = 2) The default parallelism is &quot;parLapply&quot; on Windows and &quot;mclapply&quot; everywhere else. default_parallelism() ## [1] &quot;mclapply&quot; 9.5 Remote workers The &quot;future_lapply&quot;, &quot;future&quot;, and &quot;Makefile&quot; backends have the option to launch workers to remote resources such as nodes on a computing cluster. parallelism_choices(distributed_only = TRUE) ## [1] &quot;future&quot; &quot;future_lapply&quot; &quot;Makefile&quot; Testing them out is straightforward. make(my_plan, parallelism = &quot;future&quot;, jobs = 2) make(my_plan, parallelism = &quot;future_lapply&quot;, jobs = 2) make(my_plan, parallelism = &quot;Makefile&quot;, jobs = 2) For remote workers, the all the imports are processed with one of the local worker backends before any of the targets start. You can use different numbers of workers for the imports and the targets. make(my_plan, parallelism = &quot;future&quot;, jobs = c(imports = 2, targets = 4)) By default, these backends launch the workers on your local machine. It takes extra configuring to actually deploy them to a remote cluster. The next subsections have the details. 9.5.1 &quot;future&quot; and &quot;future_lapply&quot; The plan() function from the future package configures how and where the workers will deploy on the next make(). For example, the following code uses future’s multisession backend, which is analogous to drake’s &quot;parLapply&quot; parallelism. library(future) future::plan(multisession) make(my_plan, parallelism = &quot;future&quot;, jobs = 2) ## Same technology, different scheduling: make(my_plan, parallelism = &quot;future_lapply&quot;, jobs = 2) To deploy to a cluster (say, a SLURM cluster), you need the batchtools and future.batchtools packages. library(future.batchtools) You also need template file to configure batchtools the remote resources, such as the memory and wall time limits. Use drake_batchtools_tmpl_file() to write one of the examples from the drake_example() files. You will probably need to edit it manually to match your resources and needs. drake_batchtools_tmpl_file(&quot;slurm&quot;) # Write batchtools.slurm.tmpl. Load the template file your future::plan() and call make() to run the project. future::plan(batchtools_slurm, template = &quot;batchtools.slurm.tmpl&quot;) make(my_plan, parallelism = &quot;future&quot;, jobs = 2) ## Same technology, different scheduling: make(my_plan, parallelism = &quot;future_lapply&quot;, jobs = 2) See packages future, future.batchtools, and batchtools for more options. For example, the alternatives for future::plan() are listed here and here. 9.5.2 &quot;Makefile&quot; Here, drake actually writes, configures, and runs a proper Makefile to run the targets. make(my_plan, parallelism = &quot;Makefile&quot;, jobs = 2) You can configure both the Unix command that runs the Makefile and the command line arguments passed to it. make( my_plan, parallelism = &quot;Makefile&quot;, command = &quot;lsmake&quot;, args = c(&quot;--touch&quot;, &quot;--silent&quot;) ) If drake’s Makefile conflicts with a Makefile you already wrote yourself, drake does not overwrite your Makefile. Instead, make() tells you about the conflict and then stops running. To force drake to use a different Makefile that does not conflict with yours, pass the file path to the makefile_path argument and set the --file argument in args. make( my_plan, parallelism = &quot;Makefile&quot;, makefile_path = &quot;my_folder/my_makefile&quot;, args = &quot;--file=my_folder/my_makefile&quot; ) There are more customization options in make(), such as the recipe_command argument. make(my_plan, parallelism = &quot;Makefile&quot;, jobs = 4, recipe_command = &quot;R -e &#39;R_RECIPE&#39; -q&quot;) See the help files of individual functions for details. default_Makefile_command() ## [1] &quot;make&quot; default_recipe_command() ## [1] &quot;Rscript -e &#39;R_RECIPE&#39;&quot; r_recipe_wildcard() ## [1] &quot;R_RECIPE&quot; Makefile_recipe( recipe_command = &quot;R -e &#39;R_RECIPE&#39; -q&quot;, target = &quot;this_target&quot;, cache_path = &quot;custom_cache&quot; ) ## R -e &#39;drake::mk(target = &quot;this_target&quot;, cache_path = &quot;custom_cache&quot;)&#39; -q To deploy workers to a cluster, you need to supply the Makefile with a custom shell script that launches cluster jobs. Use the shell_file() function to write an example compatible with the Univa Grid Engine. You will probably need to configure it manually. Suppose our file is shell.sh. #!/bin/bash shift echo \"module load R; $*\" | qsub -sync y -cwd -j y You will need to set permissions to allow execution. In the Linux command line, this is straightforward. $ chmod +x shell.sh When you actually call make(), use the prepend argument to write a line at the top of the Makefile to reference your shell file. make(my_plan, parallelism = &quot;Makefile&quot;, jobs = 2, prepend = &quot;SHELL=./shell.sh&quot;) SLURM users may be able to invoke srun and dispense with shell.sh altogether, though success may vary depending on the SLURM system. You will probably also need to set resource allocation parameters governing memory, runtime, etc. See man srun for the possible .SHELLFLAGS. make( my_plan, parallelism = &quot;Makefile&quot;, jobs = 2, prepend = c( &quot;SHELL=srun&quot;, &quot;.SHELLFLAGS=-N1 -n1 bash -c&quot; ) ) 9.6 Scheduling algorithms 9.6.1 Persistent scheduling Backends “mclapply”, “parLapply”, and “future_lapply” launch persistent workers. make(my_plan, parallelism = &quot;mclapply&quot;, jobs = 2) make(my_plan, parallelism = &quot;parLapply&quot;, jobs = 2) future::plan(future::multisession) make(my_plan, parallelism = &quot;future_lapply&quot;, jobs = 2) In each of these calls to make(), three processes launch: two workers and one master. Whenever a worker is idle, the master assigns it the next available target (whose dependencies have been built). The workers keep running until there are no more targets to build. The following video demonstrates the concept. For staged scheduling, you can micromanage which workers can run which targets. This column can be an integer vector or a list of integer vectors. Simply set an optional workers column in your drake_plan(). Why would you wish to do this? Consider the mtcars example. load_mtcars_example() my_plan$workers &lt;- 1 my_plan$workers[grepl(&quot;large&quot;, my_plan$target)] &lt;- 2 my_plan ## # A tibble: 15 x 3 ## target command workers ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 &quot;&quot; &quot;knit(knitr_in(\\&quot;report.Rmd\\&quot;), file_ou… 1 ## 2 small simulate(48) 1 ## 3 large simulate(64) 2 ## 4 regression1_small reg1(small) 1 ## 5 regression1_large reg1(large) 2 ## 6 regression2_small reg2(small) 1 ## 7 regression2_large reg2(large) 2 ## 8 summ_regression1_small suppressWarnings(summary(regression1_sm… 1 ## 9 summ_regression1_large suppressWarnings(summary(regression1_la… 2 ## 10 summ_regression2_small suppressWarnings(summary(regression2_sm… 1 ## 11 summ_regression2_large suppressWarnings(summary(regression2_la… 2 ## 12 coef_regression1_small suppressWarnings(summary(regression1_sm… 1 ## 13 coef_regression1_large suppressWarnings(summary(regression1_la… 2 ## 14 coef_regression2_small suppressWarnings(summary(regression2_sm… 1 ## 15 coef_regression2_large suppressWarnings(summary(regression2_la… 2 Here, one of the workers is in charge of all the targets that have to do with the large dataset. That way, we do not need other workers to read large from disk. If reads from disk take a long time, this could speed up your workflow. On the other hand, delegating all the large targets to worker 2 could prevent worker 1 from sharing the computational load, which could slow things down. Ultimately, you as the user need to make these tradeoffs. Also, the workers column only applies to the persistent scheduling backends. Similarly, you can set an optional priority column for your drake_plan(). plan &lt;- drake_plan(A = build(), B = stuff()) plan$priority &lt;- c(1, 2) plan ## # A tibble: 2 x 3 ## target command priority ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 A build() 1 ## 2 B stuff() 2 Because of the priority column, if targets A and B are both ready to build, then A will be assigned to a worker first. Custom priorities apply to the staged scheduling backends, plus the &quot;future&quot; backend. The predict_runtime() and predict_load_balancing() functions emulate persistent workers, and the predictions also apply to transient workers. See the timing guide for a demonstration. These functions also respond to the workers column. 9.6.2 Transient scheduling Persistent workers are great because they minimize overhead: all the workers are created at the beginning, and then you never have to create any more for the rest of the runthrough. Unfortunately, computing clusters usually limit the amount of time each worker can stay running. That is why drake also supports transient workers in backends &quot;future&quot; and &quot;Makefile&quot;. Here, the master process creates a new worker for each target individually, and the worker dies after it finishes its single target. For the &quot;future&quot; backend, the master is just the existing process calling make(). The following video demonstrates the concept. future::plan(future::multisession) make(my_plan, parallelism = &quot;future&quot;, jobs = 2) make(my_plan, parallelism = &quot;Makefile&quot;, jobs = 2) 9.6.3 Staged scheduling Backends &quot;mclapply_staged&quot; and &quot;parLapply_staged&quot; support staged scheduling. make(my_plan, parallelism = &quot;mclapply_staged&quot;, jobs = 2) make(my_plan, parallelism = &quot;parLapply_staged&quot;, jobs = 2) Here, the dependency network is divided into separate stages of conditionally independent targets. Within each stage, drake uses mclapply() or parLapply() to process the targets in parallel. Stages run one after the other, so the slowest target in the current stage needs to complete before the next stage begins. So we lose a lot of parallel efficiency. The following video demonstrates the major drawback.[1] However, because there is no formal master process in each stage, overhead is extremely low. This lack of overhead can make staged parallelism a great choice for projects with a small number of large stages: tall dependency graphs with most of the work in the tallest stages. library(dplyr) library(drake) N &lt;- 500 gen_data &lt;- function() { tibble(a = seq_len(N), b = 1, c = 2, d = 3) } plan_data &lt;- drake_plan( data = gen_data() ) plan_sub &lt;- gen_data() %&gt;% transmute( target = paste0(&quot;data&quot;, a), command = paste0(&quot;data[&quot;, a, &quot;, ]&quot;) ) plan &lt;- bind_rows(plan_data, plan_sub) plan ## # A tibble: 501 x 2 ## target command ## &lt;chr&gt; &lt;chr&gt; ## 1 data gen_data() ## 2 data1 data[1, ] ## 3 data2 data[2, ] ## 4 data3 data[3, ] ## 5 data4 data[4, ] ## 6 data5 data[5, ] ## 7 data6 data[6, ] ## 8 data7 data[7, ] ## 9 data8 data[8, ] ## 10 data9 data[9, ] ## # ... with 491 more rows config &lt;- drake_config(plan) vis_drake_graph(config) 9.7 Final thoughts 9.7.1 Debugging For large workflows, downsizing and debugging tools become super important. See the guide to debugging and testing drake projects for help on diagnosing problems with a workflow. Triggers and cached error logs especially speed the development and testing process. 9.7.2 Drake as an ordinary job scheduler If you do not care about reproducibility and you want drake to be an ordinary job scheduler, consider using alternative triggers (see ?triggers). load_mtcars_example() make(my_plan, trigger = &quot;missing&quot;) # Also consider &quot;always&quot;. Above, drake only builds the missing targets. This skips much of the time-consuming hashing that ordinarily detects which targets are out of date. 9.7.3 More resources See the timing guide for explanations of functions predict_runtime() and predict_load_balancing(), which can help you plan and strategize deployment. 9.8 Footnotes [1] The video of staged parallelism is an oversimplification. It holds mostly true for make(parallelism = &quot;parLapply_staged&quot;), but make(parallelism = &quot;mclapply_staged&quot;) is a bit different. In the former case, each stage is a call to parLapply(), which recycles existing workers on a pre-built parallel socket (PSOCK) cluster. But in the latter, every stage is a new call to mclapply(), which launches a brand new batch of workers. In that sense, workers in make(parallelism = &quot;parLapply_staged&quot;) are sort of persistent, and workers in make(parallelism = &quot;mclapply_staged&quot;) are sort of transient for some projects. "],
["time.html", "Chapter 10 Time: logging, prediction, and strategy 10.1 Predict total runtime 10.2 Strategize your high-performance computing", " Chapter 10 Time: logging, prediction, and strategy Thanks to Jasper Clarkberg, drake records how long it takes to build each target. For large projects that take hours or days to run, this feature becomes important for planning and execution. library(drake) load_mtcars_example() # Get the code with drake_example(&quot;mtcars&quot;). make(my_plan, jobs = 2) build_times(digits = 8) # From the cache. ## # A tibble: 31 x 5 ## item type elapsed user system ## * &lt;chr&gt; &lt;chr&gt; &lt;S4: Duration&gt; &lt;S4: Duration&gt; &lt;S4: Durat&gt; ## 1 coef_regression1_large target 0.005s 0.005s 0s ## 2 coef_regression1_small target 0.005s 0.005s 0s ## 3 coef_regression2_large target 0.005s 0.005s 0s ## 4 coef_regression2_small target 0.004s 0.004s 0.001s ## 5 data.frame import 0.062s 0.049s 0.012s ## 6 knit import 0.022s 0.019s 0.003s ## 7 large target 0.005s 0.006s 0s ## 8 lm import 0.011s 0.011s 0s ## 9 mtcars import 0.001s 0.002s 0s ## 10 nrow import 0.011s 0.011s 0s ## # ... with 21 more rows ## `dplyr`-style `tidyselect` commands build_times(starts_with(&quot;coef&quot;), digits = 8) ## # A tibble: 4 x 5 ## item type elapsed user system ## * &lt;chr&gt; &lt;chr&gt; &lt;S4: Duration&gt; &lt;S4: Duration&gt; &lt;S4: Durati&gt; ## 1 coef_regression1_large target 0.005s 0.005s 0s ## 2 coef_regression1_small target 0.005s 0.005s 0s ## 3 coef_regression2_large target 0.005s 0.005s 0s ## 4 coef_regression2_small target 0.004s 0.004s 0.001s build_times(digits = 8, targets_only = TRUE) ## # A tibble: 15 x 5 ## item type elapsed user system ## * &lt;chr&gt; &lt;chr&gt; &lt;S4: Duration&gt; &lt;S4: Duration&gt; &lt;S4: Durat&gt; ## 1 coef_regression1_large target 0.005s 0.005s 0s ## 2 coef_regression1_small target 0.005s 0.005s 0s ## 3 coef_regression2_large target 0.005s 0.005s 0s ## 4 coef_regression2_small target 0.004s 0.004s 0.001s ## 5 large target 0.005s 0.006s 0s ## 6 regression1_large target 0.005s 0.005s 0.001s ## 7 regression1_small target 0.005s 0.005s 0s ## 8 regression2_large target 0.005s 0.006s 0s ## 9 regression2_small target 0.005s 0.005s 0s ## 10 &quot;\\&quot;report.md\\&quot;&quot; target 0.05s 0.05s 0s ## 11 small target 0.006s 0.005s 0s ## 12 summ_regression1_large target 0.005s 0.005s 0s ## 13 summ_regression1_small target 0.004s 0.004s 0s ## 14 summ_regression2_large target 0.004s 0.004s 0.001s ## 15 summ_regression2_small target 0.004s 0.004s 0s For drake version 4.1.0 and earlier, build_times() just measures the elapsed runtime of each command in my_plan$command. For later versions, the build times also account for all the internal operations in drake:::build(), such as storage and hashing. 10.1 Predict total runtime Drake uses these times to predict the runtime of the next make(). At this moment, everything is up to date in the current example, so the next make() should be fast. Here, we only factor in the times of the formal targets in the workflow plan, excluding any imports. config &lt;- drake_config(my_plan, verbose = FALSE) predict_runtime(config, targets_only = TRUE) ## [1] &quot;0.117s&quot; Suppose we change a dependency to make some targets out of date. Now, even though, the next make() should take a little longer. reg2 &lt;- function(d){ d$x3 &lt;- d$x ^ 3 lm(y ~ x3, data = d) } predict_runtime(config, targets_only = TRUE) ## [1] &quot;0.117s&quot; But what if you plan on starting from scratch next time, either after clean() or with make(..., trigger = &quot;always&quot;)? predict_runtime(config, from_scratch = TRUE, targets_only = TRUE) ## [1] &quot;0.117s&quot; 10.2 Strategize your high-performance computing Let’s say you are scaling up your workflow. You just put bigger data and heavier computation in your custom code, and the next time you run make(), your targets will take much longer to build. In fact, you estimate that every target except for your R Markdown report will take two hours to complete. Let’s write down these known times in seconds. known_times &lt;- c(5, rep(7200, nrow(my_plan) - 1)) names(known_times) &lt;- c(file_store(&quot;report.md&quot;), my_plan$target[-1]) known_times ## &quot;report.md&quot; small large ## 5 7200 7200 ## regression1_small regression1_large regression2_small ## 7200 7200 7200 ## regression2_large summ_regression1_small summ_regression1_large ## 7200 7200 7200 ## summ_regression2_small summ_regression2_large coef_regression1_small ## 7200 7200 7200 ## coef_regression1_large coef_regression2_small coef_regression2_large ## 7200 7200 7200 How many parallel jobs should you use in the next make()? The predict_runtime() function can help you decide. predict_runtime(jobs = n) simulates persistent parallel workers and reports the estimated total runtime of make(jobs = n). (See also predict_load_balancing().) time &lt;- c() for (jobs in 1:12){ time[jobs] &lt;- predict_runtime( config, jobs = jobs, from_scratch = TRUE, known_times = known_times ) } library(ggplot2) ggplot(data.frame(time = time / 3600, jobs = ordered(1:12), group = 1)) + geom_line(aes(x = jobs, y = time, group = group)) + scale_y_continuous(breaks = 0:10 * 4, limits = c(0, 29)) + theme_gray(16) + xlab(&quot;jobs argument of make()&quot;) + ylab(&quot;Predicted runtime of make() (hours)&quot;) We see serious potential speed gains up to 4 jobs, but beyond that point, we have to double the jobs to shave off another 2 hours. Your choice of jobs for make() ultimately depends on the runtime you can tolerate and the computing resources at your disposal. A final note on predicting runtime: the output of predict_runtime() and predict_load_balancing() also depends the optional workers column of your drake_plan(). If you micromanage which workers are allowed to build which targets, you may minimize reads from disk, but you could also slow down your workflow if you are not careful. See the high-performance computing guide for more. "],
["store.html", "Chapter 11 Storage 11.1 Caches 11.2 Hash algorithms 11.3 Which hash algorithm should you choose? 11.4 Select the hash algorithms of the cache 11.5 Using storr directly 11.6 Cleaning up", " Chapter 11 Storage Drake’s make() function generates your project’s output, and drake takes storing this output seriously. This guide explains how drake caches and hashes its data, and describes customization options that can increase convenience and speed. 11.1 Caches When you run make(), drake stores your imports and targets in a hidden cache. library(drake) load_mtcars_example(verbose = FALSE) # Get the code with drake_example(&quot;mtcars&quot;). config &lt;- make(my_plan) ## target large ## target small ## target regression1_large ## target regression2_large ## target regression1_small ## target regression2_small ## target summ_regression1_large ## target coef_regression1_large ## target summ_regression2_large ## target coef_regression2_large ## target summ_regression1_small ## target coef_regression1_small ## target coef_regression2_small ## target summ_regression2_small ## target file &quot;report.md&quot; You can explore your cached data using functions loadd(), readd(), cached(), and others. head(cached()) ## [1] &quot;coef_regression1_large&quot; &quot;coef_regression1_small&quot; ## [3] &quot;coef_regression2_large&quot; &quot;coef_regression2_small&quot; ## [5] &quot;data.frame&quot; &quot;knit&quot; head(readd(small)) ## x y ## 1 3.730 17.3 ## 2 5.250 10.4 ## 3 3.730 17.3 ## 4 5.345 14.7 ## 5 3.190 24.4 ## 6 3.440 17.8 loadd(large) head(large) ## x y ## 1 3.780 15.2 ## 2 3.170 15.8 ## 3 5.424 10.4 ## 4 5.250 10.4 ## 5 3.780 15.2 ## 6 3.570 14.3 rm(large) # Does not remove `large` from the cache. By default, these objects live in a hidden .drake folder in your working directory. find_cache() ### [1] &quot;/home/you/project/.drake&quot; find_project() ### [1] &quot;/home/you/project&quot; Drake (via storr) has an object-like interface to these caches. cache &lt;- get_cache() cache$list() ## [1] &quot;coef_regression1_large&quot; &quot;coef_regression1_small&quot; ## [3] &quot;coef_regression2_large&quot; &quot;coef_regression2_small&quot; ## [5] &quot;data.frame&quot; &quot;knit&quot; ## [7] &quot;large&quot; &quot;lm&quot; ## [9] &quot;mtcars&quot; &quot;nrow&quot; ## [11] &quot;random_rows&quot; &quot;reg1&quot; ## [13] &quot;reg2&quot; &quot;regression1_large&quot; ## [15] &quot;regression1_small&quot; &quot;regression2_large&quot; ## [17] &quot;regression2_small&quot; &quot;\\&quot;report.md\\&quot;&quot; ## [19] &quot;\\&quot;report.Rmd\\&quot;&quot; &quot;sample.int&quot; ## [21] &quot;simulate&quot; &quot;small&quot; ## [23] &quot;summary&quot; &quot;summ_regression1_large&quot; ## [25] &quot;summ_regression1_small&quot; &quot;summ_regression2_large&quot; ## [27] &quot;summ_regression2_small&quot; &quot;suppressWarnings&quot; ## [29] &quot;x&quot; &quot;x2&quot; ## [31] &quot;y&quot; head(cache$get(&quot;small&quot;)) ## x y ## 1 3.730 17.3 ## 2 5.250 10.4 ## 3 3.730 17.3 ## 4 5.345 14.7 ## 5 3.190 24.4 ## 6 3.440 17.8 tail(cache$get(&quot;small&quot;, namespace = &quot;meta&quot;)) ## $command ## [1] &quot;{\\n simulate(48) \\n}&quot; ## ## $depends ## [1] &quot;eb89933a9211e556671c06c5018dcdb7efdad4593b4adff4f88ee6a34de61f7f&quot; ## ## $file ## [1] NA ## ## $start ## user system elapsed ## 75.132 11.787 89.789 ## ## $time_command ## item type elapsed user system ## 1 small target 0 0 0 ## ## $time_build ## item type elapsed user system ## 1 small target 0.004 0.004 0 cache$list_namespaces() ## [1] &quot;attempt&quot; &quot;common&quot; &quot;config&quot; &quot;kernels&quot; &quot;meta&quot; &quot;objects&quot; ## [7] &quot;progress&quot; &quot;session&quot; Create a new cache of your own with new_cache(). cache2 &lt;- new_cache(path = &quot;cache2&quot;) file.exists(&quot;cache2&quot;) ## [1] TRUE You can use multiple caches simultaneously, default and non-default alike. config &lt;- drake_config(cache = cache) config2 &lt;- drake_config(cache = cache2) outdated(config) ## character(0) outdated(config2) ## [1] &quot;coef_regression1_large&quot; &quot;coef_regression1_small&quot; ## [3] &quot;coef_regression2_large&quot; &quot;coef_regression2_small&quot; ## [5] &quot;large&quot; &quot;regression1_large&quot; ## [7] &quot;regression1_small&quot; &quot;regression2_large&quot; ## [9] &quot;regression2_small&quot; &quot;\\&quot;report.md\\&quot;&quot; ## [11] &quot;small&quot; &quot;summ_regression1_large&quot; ## [13] &quot;summ_regression1_small&quot; &quot;summ_regression2_large&quot; ## [15] &quot;summ_regression2_small&quot; make(my_plan, cache = cache) ## All targets are already up to date. make(my_plan, cache = cache2) ## target large ## target small ## target regression1_large ## target regression2_large ## target regression1_small ## target regression2_small ## target summ_regression1_large ## target coef_regression1_large ## target summ_regression2_large ## target coef_regression2_large ## target summ_regression1_small ## target coef_regression1_small ## target coef_regression2_small ## target summ_regression2_small ## target file &quot;report.md&quot; There are a couple different ways to retrieve caches. get_cache(path = &quot;my_path&quot;) assumes my_path is a project root containing a .drake folder. If it does not find a .drake folder in my_path, it searches up through the ancestors of my_path until it finds one. this_cache(path = &quot;my_path&quot;) literally assumes my_path is the path to the cache, .drake folder or not. storr::storr_rds(&quot;my_path&quot;, mangle_key = TRUE) is analogous to this_cache(path = &quot;my_path&quot;). cache3 &lt;- get_cache(path = getwd()) # Finds the .drake folder in your directory. head(cache3$list()) ## [1] &quot;coef_regression1_large&quot; &quot;coef_regression1_small&quot; ## [3] &quot;coef_regression2_large&quot; &quot;coef_regression2_small&quot; ## [5] &quot;data.frame&quot; &quot;knit&quot; cache4 &lt;- this_cache(path = &quot;cache2&quot;) # The cache folder is literally called cache2. head(cache4$list()) ## [1] &quot;coef_regression1_large&quot; &quot;coef_regression1_small&quot; ## [3] &quot;coef_regression2_large&quot; &quot;coef_regression2_small&quot; ## [5] &quot;data.frame&quot; &quot;knit&quot; Destroy caches to remove them from your file system. cache4$destroy() cache2$list() # Same folder as cache4. ## character(0) See storr for more on drake’s caching infrastructure. 11.2 Hash algorithms The concept of hashing is central to storr’s internals. Storr uses hashes to label stored objects, and drake leverages these hashes to figure out which targets are up to date and which ones are outdated. A hash is like a target’s fingerprint, so the hash changes when the target changes. Regardless of the target’s size, the hash is always the same number of characters. library(digest) # package for hashing objects and files smaller_data &lt;- 12 larger_data &lt;- rnorm(1000) digest(smaller_data) # compute the hash ## [1] &quot;23c80a31c0713176016e6e18d76a5f31&quot; digest(larger_data) ## [1] &quot;7386d2909711f2be4e9fdb2f3b1de03b&quot; However, different hash algorithms vary in length. digest(larger_data, algo = &quot;sha512&quot;) ## [1] &quot;a1c86d5a6880ec6333d4b04e3b84b04fff3e77dd11d1084790573bf454a85fdc71c9c86c88f9b62ecec120ec8866cbb7fe3ca2669159474fa38e25f59e7d028f&quot; digest(larger_data, algo = &quot;md5&quot;) ## [1] &quot;7386d2909711f2be4e9fdb2f3b1de03b&quot; digest(larger_data, algo = &quot;xxhash64&quot;) ## [1] &quot;2ecacf8c43cefe91&quot; digest(larger_data, algo = &quot;murmur32&quot;) ## [1] &quot;bd5a15f6&quot; 11.3 Which hash algorithm should you choose? Hashing is expensive, and unsurprisingly, shorter hashes are usually faster to compute. So why not always use murmur32? One reason is the risk of collisions: that is, when two different objects have the same hash. In general, shorter hashes have more frequent collisions. On the other hand, a longer hash is not always the answer. Besides the loss of speed, drake and storr sometimes use hash keys as file names, and long hashes could violate the 260-character cap on Windows file paths. That is why drake uses a shorter hash algorithm for internal cache-related file names and a longer hash algorithm for everything else. default_short_hash_algo() ## [1] &quot;xxhash64&quot; default_long_hash_algo() ## [1] &quot;sha256&quot; short_hash(cache) ## [1] &quot;xxhash64&quot; long_hash(cache) ## [1] &quot;sha256&quot; 11.4 Select the hash algorithms of the cache If you want to set the hash algorithms, do so right when the cache is first created. ## cache_path(cache) # Default cache from before. # nolint ## Start from scratch to reset both hash algorithms. clean(destroy = TRUE) tmp &lt;- new_cache( path = default_cache_path(), # The `.drake/` folder. short_hash_algo = &quot;crc32&quot;, long_hash_algo = &quot;sha1&quot; ) config &lt;- make(my_plan, verbose = FALSE) short_hash(config$cache) # xxhash64 is the default_short_hash_algo() ## [1] &quot;crc32&quot; long_hash(config$cache) # sha256 is the default_long_hash_algo() ## [1] &quot;sha1&quot; You can change the long hash algorithm without throwing away the cache, but your project will rebuild from scratch. As for the short hash, you are committed until you delete the cache and all its supporting files. outdated(config) # empty ## character(0) config$cache &lt;- configure_cache( config$cache, long_hash_algo = &quot;murmur32&quot;, overwrite_hash_algos = TRUE ) Below, the targets become outdated because the existing hash keys do not match the new hash algorithm. config &lt;- drake_config(my_plan, verbose = FALSE, cache = config$cache) outdated(config) ## [1] &quot;coef_regression1_large&quot; &quot;coef_regression1_small&quot; ## [3] &quot;coef_regression2_large&quot; &quot;coef_regression2_small&quot; ## [5] &quot;large&quot; &quot;regression1_large&quot; ## [7] &quot;regression1_small&quot; &quot;regression2_large&quot; ## [9] &quot;regression2_small&quot; &quot;\\&quot;report.md\\&quot;&quot; ## [11] &quot;small&quot; &quot;summ_regression1_large&quot; ## [13] &quot;summ_regression1_small&quot; &quot;summ_regression2_large&quot; ## [15] &quot;summ_regression2_small&quot; config &lt;- make(my_plan, verbose = FALSE) short_hash(config$cache) # same as before ## [1] &quot;crc32&quot; long_hash(config$cache) # different from before ## [1] &quot;murmur32&quot; 11.5 Using storr directly If you want bypass drake and generate a cache directly from storr, it is best to do so right from the beginning. library(storr) my_storr &lt;- storr_rds(&quot;my_storr&quot;, mangle_key = TRUE) new_plan &lt;- drake_plan(simple = sqrt(4)) make(new_plan, cache = my_storr) ## target simple cached(cache = my_storr) ## [1] &quot;simple&quot; &quot;sqrt&quot; readd(simple, cache = my_storr) ## [1] 2 In addition to storr_rds(), drake supports in-memory caches created from storr_environment(). However, parallel computing is not supported these caches. The jobs argument must be 1, and the parallelism argument must be either &quot;mclapply&quot; or &quot;parLapply&quot;. (It is sufficient to leave the default values alone.) memory_cache &lt;- storr_environment() other_plan &lt;- drake_plan( some_data = rnorm(50), more_data = rpois(75, lambda = 10), result = mean(c(some_data, more_data)) ) make(other_plan, cache = memory_cache) ## target some_data ## target more_data ## target result cached(cache = memory_cache) ## [1] &quot;c&quot; &quot;mean&quot; &quot;more_data&quot; &quot;result&quot; &quot;rnorm&quot; &quot;rpois&quot; ## [7] &quot;some_data&quot; readd(result, cache = memory_cache) ## [1] 6.232917 In theory, it should be possible to leverage serious databases using storr_dbi(). However, if you use such caches, please heed the following. Be sure you have storr version 1.1.3 or greater installed. Be careful about parallel computing. For example the storr::storr_dbi() cache is not thread-safe. Either use no parallel computing at all or set parallelism = &quot;future&quot; with caching = &quot;master&quot;. The &quot;future&quot; backend is currently experimental, but it allows the master process to do all the caching in order to avoid race conditions. The following example requires the DBI and RSQLite packages. mydb &lt;- DBI::dbConnect(RSQLite::SQLite(), &quot;my-db.sqlite&quot;) cache &lt;- storr::storr_dbi( tbl_data = &quot;data&quot;, tbl_keys = &quot;keys&quot;, con = mydb ) load_mtcars_example() # Get the code with drake_example(&quot;mtcars&quot;). unlink(&quot;.drake&quot;, recursive = TRUE) make(my_plan, cache = cache) 11.6 Cleaning up If you want to start from scratch, you can clean() the cache. Use the destroy argument to remove it completely. cache$del() and cache$destroy() are also options, but they leave output file targets dangling. By contrast, clean(destroy = TRUE) removes file targets generated by drake::make(). drake_gc() and clean(..., garbage_collection = TRUE) do garbage collection, and clean(purge = TRUE) removes all target-level data, not just the final output values. clean(small, large) cached() # &#39;small&#39; and &#39;large&#39; are gone ## [1] &quot;coef_regression1_large&quot; &quot;coef_regression1_small&quot; ## [3] &quot;coef_regression2_large&quot; &quot;coef_regression2_small&quot; ## [5] &quot;data.frame&quot; &quot;knit&quot; ## [7] &quot;lm&quot; &quot;mtcars&quot; ## [9] &quot;nrow&quot; &quot;random_rows&quot; ## [11] &quot;reg1&quot; &quot;reg2&quot; ## [13] &quot;regression1_large&quot; &quot;regression1_small&quot; ## [15] &quot;regression2_large&quot; &quot;regression2_small&quot; ## [17] &quot;\\&quot;report.md\\&quot;&quot; &quot;\\&quot;report.Rmd\\&quot;&quot; ## [19] &quot;sample.int&quot; &quot;simulate&quot; ## [21] &quot;summary&quot; &quot;summ_regression1_large&quot; ## [23] &quot;summ_regression1_small&quot; &quot;summ_regression2_large&quot; ## [25] &quot;summ_regression2_small&quot; &quot;suppressWarnings&quot; ## [27] &quot;x&quot; &quot;x2&quot; ## [29] &quot;y&quot; clean(destroy = TRUE) clean(destroy = TRUE, cache = my_storr) "],
["caution.html", "Chapter 12 Cautionary notes 12.1 Projects built with drake &lt;= 4.4.0 are not back compatible with drake &gt; 4.4.0. 12.2 Workflow plans 12.3 Execution 12.4 Dependencies 12.5 High-performance computing 12.6 Storage", " Chapter 12 Cautionary notes This chapter addresses drake’s known edge cases, pitfalls, and weaknesses that might not be fixed in future releases. For the most up-to-date information on unhandled edge cases, please visit the issue tracker, where you can submit your own bug reports as well. Be sure to search the closed issues too, especially if you are not using the most up-to-date development version of drake. For a guide to debugging and testing drake projects, please refer to the separate guide to debugging and testing drake projects. 12.1 Projects built with drake &lt;= 4.4.0 are not back compatible with drake &gt; 4.4.0. The cache internals changed between 4.4.0 and 5.0.0. Unfortunately, you will need to make() your project all over again. 12.2 Workflow plans 12.2.1 Externalizing commands in R script files It is common practice to divide the work of a project into multiple R files, but if you do this, you will not get the most out of drake. Please see the best practices chapter for more details. 12.2.2 Commands are NOT perfectly flexible. In your workflow plan data frame (produced by drake_plan() and accepted by make()), your commands can usually be flexible R expressions. drake_plan( target1 = 1 + 1 - sqrt(sqrt(3)), target2 = my_function(web_scraped_data) %&gt;% my_tidy ) ## # A tibble: 2 x 2 ## target command ## &lt;chr&gt; &lt;chr&gt; ## 1 target1 1 + 1 - sqrt(sqrt(3)) ## 2 target2 my_function(web_scraped_data) %&gt;% my_tidy However, please try to avoid formulas and function definitions in your commands. You may be able to get away with drake_plan(f = function(x){x + 1}) or drake_plan(f = y ~ x) in some use cases, but be careful. It is generally to define functions and formulas in your workspace and then let make() import them. (Alternatively, use the envir argument to make() to tightly control which imported functions are available.) Use the check_plan() function to help screen and quality-control your workflow plan data frame, use tracked() to see the items that are reproducibly tracked, and use vis_drake_graph() and build_drake_graph() to see the dependency structure of your project. 12.3 Execution 12.3.1 Install drake properly. You must properly install drake using install.packages(), devtools::install_github(), or a similar approach. Functions like devtools::load_all() are insufficient, particularly for parallel computing functionality in which separate new R sessions try to require(drake). 12.3.2 Install all your packages. Your workflow may depend on external packages such as ggplot2, dplyr, and MASS. Such packages must be formally installed with install.packages(), devtools::install_github(), devtools::install_local(), or a similar command. If you load uninstalled packages with devtools::load_all(), results may be unpredictable and incorrect. 12.3.3 A note on tidy evaluation Running commands in your R console is not always exactly like running them with make(). That’s because make() uses tidy evaluation as implemented in the rlang package. ## This workflow plan uses rlang&#39;s quasiquotation operator `!!`. my_plan &lt;- drake_plan(list = c( little_b = &quot;\\&quot;b\\&quot;&quot;, letter = &quot;!!little_b&quot; )) my_plan ## # A tibble: 2 x 2 ## target command ## &lt;chr&gt; &lt;chr&gt; ## 1 little_b &quot;\\&quot;b\\&quot;&quot; ## 2 letter !!little_b make(my_plan) ## Unloading targets from environment: ## little_b ## target little_b ## target letter readd(letter) ## [1] &quot;b&quot; For the commands you specify the free-form ... argument, drake_plan() also supports tidy evaluation. For example, it supports quasiquotation with the !! argument. Use tidy_evaluation = FALSE or the list argument to suppress this behavior. my_variable &lt;- 5 drake_plan( a = !!my_variable, b = !!my_variable + 1, list = c(d = &quot;!!my_variable&quot;) ) ## # A tibble: 3 x 2 ## target command ## &lt;chr&gt; &lt;chr&gt; ## 1 a 5 ## 2 b 5 + 1 ## 3 d !!my_variable drake_plan( a = !!my_variable, b = !!my_variable + 1, list = c(d = &quot;!!my_variable&quot;), tidy_evaluation = FALSE ) ## # A tibble: 3 x 2 ## target command ## &lt;chr&gt; &lt;chr&gt; ## 1 a !!my_variable ## 2 b !!my_variable + 1 ## 3 d !!my_variable For instances of !! that remain in the workflow plan, make() will run these commands in tidy fashion, evaluating the !! operator using the environment you provided. 12.3.4 Find and diagnose your errors. When make() fails, use failed() and diagnose() to debug. Try the following out yourself. ## Targets with available diagnostic metadata, incluing errors, warnings, etc. diagnose() ## [1] &quot;letter&quot; &quot;little_b&quot; f &lt;- function(){ stop(&quot;unusual error&quot;) } bad_plan &lt;- drake_plan(target = f()) withr::with_message_sink( stdout(), make(bad_plan) ) ## target target ## fail target ## Error: Target `target` failed. Call `diagnose(target)` for details. Error message: ## unusual error ## Warning: No message sink to remove. failed() # From the last make() only ## [1] &quot;target&quot; error &lt;- diagnose(target)$error # See also warnings and messages. error$message ## [1] &quot;unusual error&quot; error$call ## f() error$calls # View the traceback. ## [[1]] ## local({ ## f() ## }) ## ## [[2]] ## eval.parent(substitute(eval(quote(expr), envir))) ## ## [[3]] ## eval(expr, p) ## ## [[4]] ## eval(expr, p) ## ## [[5]] ## eval(quote({ ## f() ## }), new.env()) ## ## [[6]] ## eval(quote({ ## f() ## }), new.env()) ## ## [[7]] ## f() ## ## [[8]] ## stop(&quot;unusual error&quot;) 12.3.5 Refresh the drake_config() list early and often. The master configuration list returned by drake_config() is important to drake’s internals, and you will need it for functions like outdated() and vis_drake_graph(). The config list corresponds to a single call to make(), and you should not modify it by hand afterwards. For example, modifying the targets element post-hoc will have no effect because the graph element will remain the same. It is best to just call drake_config() again. 12.3.6 Workflows as R packages. The R package structure is a great way to organize the files of your project. Writing your own package to contain your data science workflow is a good idea, but you will need to Use expose_imports() to properly account for all your nested function dependencies, and If you load the package with devtools::load_all(), set the prework argument of make(): e.g. make(prework = &quot;devtools::load_all()&quot;). See the best practices guide and ?expose_imports for detailed explanations. Thanks to Jasper Clarkberg for the workaround. 12.3.7 The lazy_load flag does not work with &quot;parLapply&quot; parallelism. Ordinarily, drake prunes the execution environment at every parallelizable stage. In other words, it loads all the dependencies and unloads anything superfluous for entire batches of targets. This approach may require too much memory for some use cases, so there is an option to delay the loading of dependencies using the lazy_load argument to make() (powered by delayedAssign()). There are two major risks. make(..., lazy_load = TRUE, parallelism = &quot;parLapply&quot;, jobs = 2) does not work. If you want to use local multisession parallelism with multiple jobs and lazy loading, try &quot;future_lapply&quot; parallelism instead. library(future) future::plan(multisession) load_mtcars_example() # Get the code with drake_example(&quot;mtcars&quot;). make(my_plan, lazy_load = TRUE, parallelism = &quot;future_lapply&quot;) Delayed evaluation may cause the same dependencies to be loaded multiple times, and these duplicated loads could be slow. 12.3.8 Timeouts may be unreliable. You can call make(..., timeout = 10) to time out all each target after 10 seconds. However, timeouts rely on R.utils::withTimeout(), which in turn relies on setTimeLimit(). These functions are the best that R can offer right now, but they have known issues, and timeouts may fail to take effect for certain environments. 12.4 Dependencies 12.4.1 Dependency objects containing functions may change unexpectedly For example, an R6 class changes whenever a new R6 object of that class is created. library(digest) library(R6) example_class &lt;- R6Class( &quot;example_class&quot;, private = list(data = list()), public = list( initialize = function(data = list()) { private$data &lt;- data } ) ) digest(example_class) ## [1] &quot;a7b1ac6031d8ab548ffeb8fd292d4929&quot; example_object &lt;- example_class$new(data = 1234) digest(example_class) # example_class changed ## [1] &quot;5934b77bad3f2fbe115e675df15acd94&quot; Drake detects this type strange change and unavoidably rebuilds targets. plan &lt;- drake_plan(example_target = example_class$new(1234)) make(plan) # `example_class` changes because it is referenced. make(plan) # Builds `example_target` again because `example_class` changed. The same behavior affects objects containing functions more broadly, not just R6 classes. For more on this edge case, see issue 345. 12.4.2 The magrittr dot (.) is always ignored. It is common practice to use a literal dot (.) to carry an object through a magrittr pipeline. Due to some tricky limitations in static code analysis, drake never treats the dot (.) as a dependency, even if you use it as an ordinary variable outside of a tidyverse context. deps_code(&quot;sqrt(x + y + .)&quot;) ## [1] &quot;sqrt&quot; &quot;x&quot; &quot;y&quot; deps_code(&quot;dplyr::filter(complete.cases(.))&quot;) ## [1] &quot;complete.cases&quot; &quot;dplyr::filter&quot; 12.4.3 Triggers and skipped imports With alternate triggers (see ?triggers) and the option in make() to skip imports, you can sacrifice reproducibility to gain speed. However, these options can throw the dependency network out of sync. You should only use them for testing and debugging. 12.4.4 Dependencies are not tracked in some edge cases. You should explicitly learn the items in your workflow and the dependencies of your targets. ?deps ?tracked ?vis_drake_graph Drake can be fooled into skipping objects that should be treated as dependencies. For example: f &lt;- function(){ b &lt;- get(&quot;x&quot;, envir = globalenv()) # x is incorrectly ignored digest::digest(file_dependency) } deps_code(f) ## [1] &quot;digest::digest&quot; &quot;file_dependency&quot; &quot;get&quot; &quot;globalenv&quot; command &lt;- &quot;x &lt;- digest::digest(file_in(\\&quot;input_file.rds\\&quot;)); assign(\\&quot;x\\&quot;, 1); x&quot; # nolint deps_code(command) ## [1] &quot;assign&quot; &quot;digest::digest&quot; &quot;\\&quot;input_file.rds\\&quot;&quot; Drake takes special precautions so that a target/import does not depend on itself. For example, deps_code(f) might return &quot;f&quot; if f() is a recursive function, but make() just ignores this conflict and runs as expected. In other words, make() automatically removes all self-referential loops in the dependency network. 12.4.5 Dependencies of knitr reports If you have knitr reports, you can use knitr_report() in your commands so that your reports are refreshed every time one of their dependencies changes. See drake_example(&quot;mtcars&quot;) and the ?knitr_in() help file examples for demonstrations. Dependencies are detected if you call loadd() or readd() in your code chunks. But beware: an empty call to loadd() does not account for any dependencies even though it loads all the available targets into your R session. 12.4.6 Knitr inputs and file outputs in imported functions. Similarly, file_out() in a command tells drake that the result of a command is an output file. Clearly, this is inappropriate for imported functions, but drake will look anyway. Do not try to use file_out() or knitr_in() inside your custom imported functions. Drake only pays attention to them in proper commands in your workflow plan data frame. However, file_in() is perfectly fine if your imported function needs a file in order to run. Here are some examples. ## toally_fine() will depend on the imported data.csv file. ## But make sure data.csv is an imported file and not a file target. totally_okay &lt;- function(x, y, z){ read.csv(file_in(&quot;data.csv&quot;)) } ## file_out() is for file targets, so `drake` will ignore it. avoid_this &lt;- function(x, y, z){ read.csv(file_out(&quot;data.csv&quot;)) } ## knitr_in() is for knitr files with dependencies ## in their active code chunks (explicitly referenced with loadd() and readd(). ## Drake just treats knitr_in() as an ordinary file input in this case. ## You should really be using file_in() instead. avoid_this &lt;- function(x, y, z){ read.csv(knitr_in(&quot;report.Rmd&quot;)) } 12.4.7 Functions produced by Vectorize() With functions produced by Vectorize(), detecting dependencies is especially hard because the body of every such function is args &lt;- lapply(as.list(match.call())[-1L], eval, parent.frame()) names &lt;- if (is.null(names(args))) character(length(args)) else names(args) dovec &lt;- names %in% vectorize.args do.call(&quot;mapply&quot;, c(FUN = FUN, args[dovec], MoreArgs = list(args[!dovec]), SIMPLIFY = SIMPLIFY, USE.NAMES = USE.NAMES)) Thus, if f is constructed with Vectorize(g, ...), drake searches g() for dependencies, not f(). In fact, if drake sees that environment(f)[[&quot;FUN&quot;]] exists and is a function, then environment(f)[[&quot;FUN&quot;]] will be analyzed instead of f(). Furthermore, if f() is the output of Vectorize(), then drake reproducibly tracks environment(f)[[&quot;FUN&quot;]] rather than f() itself. Thus, if the configuration settings of vectorization change (such as which arguments are vectorized), but the core element-wise functionality remains the same, then make() will not react. Also, if you hover over the f node in vis_drake_graph(hover = TRUE), then you will see the body of environment(f)[[&quot;FUN&quot;]], not the body of f(). 12.4.8 Compiled code is not reproducibly tracked. Some R functions use .Call() to run compiled code in the backend. The R code in these functions is tracked, but not the compiled object called with .Call(), nor its C/C++/Fortran source. 12.4.9 Directories (folders) are not reproducibly tracked. In your workflow plan, you can use file_in(), file_out(), and knitr_in() to assert that some targets/imports are external files. However, entire directories (i.e. folders) cannot be reproducibly tracked this way. Please see issue 12 for a discussion. 12.4.10 Packages are not tracked as dependencies. Drake may import functions from packages, but the packages themselves are not tracked as dependencies. For this, you will need other tools that support reproducibility beyond the scope of drake. Packrat creates a tightly-controlled local library of packages to extend the shelf life of your project. And with Docker, you can execute your project on a virtual machine to ensure platform independence. Together, packrat and Docker can help others reproduce your work even if they have different software and hardware. 12.5 High-performance computing 12.5.1 The practical utility of parallel computing Drake claims that it can Build and cache your targets in parallel (in stages). Build and cache your targets in the correct order, finishing dependencies before starting targets that depend on them. Deploy your targets to the parallel backend of your choice. However, the practical efficiency of the parallel computing functionality remains to be verified rigorously. Serious performance studies will be part of future work that has not yet been conducted at the time of writing. In addition, each project has its own best parallel computing set up, and the user needs to optimize it on a case-by-case basis. Some general considerations include the following. The high overhead and high scalability of distributed computing versus the low overhead and low scalability of local multicore computing. The high memory usage of local multicore computing, especially &quot;mclapply&quot; parallelism, as opposed to distributed computing, which can spread the memory demands over the available nodes on a cluster. The marginal gains of increasing the number of jobs indefinitely, especially in the case of local multicore computing if the number of cores is low. 12.5.2 Maximum number of simultaneous jobs Be mindful of the maximum number of simultaneous parallel jobs you deploy. At best, too many jobs is poor etiquette on a system with many users and limited resources. At worst, too many jobs will crash a system. The jobs argument to make() sets the maximum number of simultaneous jobs in most cases, but not all. For most of drake’s parallel backends, jobs sets the maximum number of simultaneous parallel jobs. However, there are ways to break the pattern. For example, make(..., parallelism = &quot;Makefile&quot;, jobs = 2, args = &quot;--jobs=4&quot;) uses at most 2 jobs for the imports and at most 4 jobs for the targets. (In make(), args overrides jobs for the targets). For make(..., parallelism = &quot;future_lapply&quot;), the jobs argument is ignored altogether. Instead, you should set the workers argument where it is available (for example, future::plan(mutlisession(workers = 2)) or future::plan(future.batchtools::batchtools_local(workers = 2))) in the preparations before make(). Alternatively, you might limit the max number of jobs by setting options(mc.cores = 2) before calling make(). Depending on the future backend you select with future::plan() or future::plan(), you might make use of one of the other environment variables listed in ?future::future.options. 12.5.3 Parallel computing on Windows On Windows, do not use make(..., parallelism = &quot;mclapply&quot;, jobs = n) with n greater than 1. You could try, but jobs will just be demoted to 1. Instead, please replace &quot;mclapply&quot; with one of the other parallelism_choices() or let drake choose the parallelism backend for you. For make(..., parallelism = &quot;Makefile&quot;), Windows users need to download and install Rtools. 12.5.4 Configuring future/batchtools parallelism for clusters The &quot;future_lapply&quot; backend unlocks a large array of distributed computing options on serious computing clusters. However, it is your responsibility to configure your workflow for your specific job scheduler. In particular, special batchtools *.tmpl configuration files are required, and the technique is described in the documentation of batchtools. You can find some examples of these files in the inst/templates folders of the batchtools and future.batchtools GitHub repositories. Drake has some built-in prepackaged example workflows. See drake_examples() to view your options, and then drake_example() to write the files for an example. drake_example(&quot;sge&quot;) # Sun/Univa Grid Engine workflow and supporting files drake_example(&quot;slurm&quot;) # SLURM drake_example(&quot;torque&quot;) # TORQUE To write just *.tmpl files from these examples, see the drake_batchtools_tmpl_file() function. Unfortunately, there is no one-size-fits-all *.tmpl configuration file for any job scheduler, so we cannot guarantee that the above examples will work for you out of the box. To learn how to configure the files to suit your needs, you should make sure you understand your job scheduler and batchtools. 12.5.5 Proper Makefiles are not standalone. The Makefile generated by make(myplan, parallelism = &quot;Makefile&quot;) is not standalone. Do not run it outside of drake::make(). Drake uses dummy timestamp files to tell the Makefile what to do, and running make in the terminal will most likely give incorrect results. 12.5.6 Makefile-level parallelism for imported objects and files Makefile-level parallelism is only used for targets in your workflow plan data frame, not imports. To process imported objects and files, drake selects the best local parallel backend for your system and uses the jobs argument to make(). To use at most 2 jobs for imports and at most 4 jobs for targets, run make(..., parallelism = &quot;Makefile&quot;, jobs = 2, args = &quot;--jobs=4&quot;) 12.5.7 Zombie processes Some parallel backends, particularly mclapply and future::multicore, may create zombie processes. Zombie children are not usually harmful, but you may wish to kill them yourself. The following function by Carl Boneri should work on Unix-like systems. For a discussion, see drake issue 116. fork_kill_zombies &lt;- function(){ require(inline) includes &lt;- &quot;#include &lt;sys/wait.h&gt;&quot; code &lt;- &quot;int wstat; while (waitpid(-1, &amp;wstat, WNOHANG) &gt; 0) {};&quot; wait &lt;- inline::cfunction( body = code, includes = includes, convention = &quot;.C&quot; ) invisible(wait()) } 12.6 Storage 12.6.1 Projects hosted on Dropbox and similar platforms If download a drake project from Dropbox, you may get an error like the one in issue 198: cache pathto/.drake connect 61 imports: ... connect 200 targets: ... Error in rawToChar(as.raw(x)) : embedded nul in string: 'initial_drake_version\\0\\0\\x9a\\x9d\\xdc\\0J\\xe9\\0\\0\\0(\\x9d\\xf9brם\\0\\xca)\\0\\0\\xb4\\xd7\\0\\0\\0\\0\\xb9' In addition: Warning message: In rawToChar(as.raw(x)) : out-of-range values treated as 0 in coercion to raw This is probably because Dropbox generates a bunch of “conflicted copy” files when file transfers do not go smoothly. This confuses storr, drake’s caching backend. keys/config/aG9vaw (Sandy Sum's conflicted copy 2018-01-31) keys/config/am9icw (Sandy Sum's conflicted copy 2018-01-31) keys/config/c2VlZA (Sandy Sum's conflicted copy 2018-01-31) Just remove these files using drake_gc() and proceed with your work. cache &lt;- get_cache() drake_gc(cache) 12.6.2 Cache customization is limited The storage guide describes how storage works in drake. As explained near the end of that chapter, you can plug custom storr caches into make(). However, non-RDS caches such as storr_dbi() may not work with most forms of parallel computing. The storr::storr_dbi() cache and many others are not thread-safe. Either use no parallel computing at all or set parallelism = &quot;future&quot; with caching = &quot;master&quot;. The &quot;future&quot; backend is currently experimental, but it allows the master process to do all the caching in order to avoid race conditions. 12.6.3 Runtime predictions In predict_runtime() and rate_limiting_times(), drake only accounts for the targets with logged build times. If some targets have not been timed, drake throws a warning and prints the untimed targets. "],
["faq.html", "Chapter 13 Frequently-asked questions", " Chapter 13 Frequently-asked questions This FAQ is a compendium of pedagogically useful issues tagged on GitHub. To contribute, please submit a new issue and ask that it be labeled a frequently asked question. How to propagate wild cards into future steps How to speed up construction of a (very) large plan? evaluate file.path and variables in file_out and friends Working with HPC time limits How to debug file targets Gather without loading all dependencies at the same time Reproducibility with random numbers output file as target How should I mix non-R code (e.g. Python and shell scripts) in a large drake workflow? Helper function for creating file targets with multiple files Reproducible remote data sources Command that writes a file always runs Using strings as wildcards? Trouble with caches sent through Dropbox How to add .R files to drake_plan() Add an option to always build some selected targets (add an “always” trigger) evaluate_plan() with file targets "]
]
