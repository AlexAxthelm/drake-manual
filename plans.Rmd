# `drake` plans {#plans}

```{r plans_setup, message = FALSE, warning = FALSE, echo = FALSE}
knitr::opts_knit$set(root.dir = fs::dir_create(tempfile()))
knitr::opts_chunk$set(collapse = TRUE, comment = "#>")
```

```{r plans_setup2, message = FALSE, warning = FALSE, echo = FALSE}
library(drake)
library(glue)
library(purrr)
library(rlang)
library(tidyverse)
invisible(drake_example("main", overwrite = TRUE))
invisible(file.copy("main/raw_data.xlsx", ".", overwrite = TRUE))
invisible(file.copy("main/report.Rmd", ".", overwrite = TRUE))
tmp <- suppressWarnings(drake_plan(x = 1, y = 2))
```

## What is a `drake` plan?

A `drake` plan is a data frame with columns named `target` and `command`. Each target is an R object, and each command is an [expression](http://adv-r.had.co.nz/Expressions.html) to produce it.[^1] The `drake_plan()` function is the best way to set up plans.[^2] Recall the plan from the [walkthrough](#walkthrough):

[^1]: You can turn the `command` column of your plan into a character vector (e.g. `plan$command <- purrr::map_chr(plan$command, rlang::expr_text)`) and `drake` will still understand you. However, the recommended format is a list of [expressions](http://adv-r.had.co.nz/Expressions.html). `drake_plan()` and friends always supply [expression](http://adv-r.had.co.nz/Expressions.html) lists.
[^2]: `drake_plan()` is the best way to create plans, but you can create plans any way you like. `drake` will understand plans you create directly using `data.frame()` or `tibble()`.

```{r firstexampleplan}
plan <- drake_plan(
  raw_data = readxl::read_excel(file_in("raw_data.xlsx")),
  data = raw_data %>%
    mutate(Species = forcats::fct_inorder(Species)),
  hist = create_plot(data),
  fit = lm(Sepal.Width ~ Petal.Width + Species, data),
  report = rmarkdown::render(
    knitr_in("report.Rmd"),
    output_file = file_out("report.html"),
    quiet = TRUE
  )
)

plan
```

`drake_plan()` does not run the workflow, it only creates the plan. To build the actual targets, we need to run `make()`. Creating the plan is like writing an R script, and running `make(your_plan)` is like calling [`source("your_script.R")`](https://www.rdocumentation.org/packages/base/versions/3.5.2/topics/source).

## Plans are similar to R scripts.

Your `drake` plan is like a top-level R script that runs everything from end to end. In fact, you can convert back and forth between plans and scripts using functions [`plan_to_code()`](https://ropensci.github.io/drake/reference/plan_to_code.html) and [`code_to_plan()`](https://ropensci.github.io/drake/reference/code_to_plan.html) (with some [caveats](https://ropensci.github.io/drake/reference/code_to_plan.html#details)).

```{r plan_to_code_planschapter}
plan_to_code(plan, "new_script.R")
cat(readLines("new_script.R"), sep = "\n")

code_to_plan("new_script.R")
```

And [`plan_to_notebook()`](https://ropensci.github.io/drake/reference/plan_to_notebook.html) turns plans into [R notebooks](https://bookdown.org/yihui/rmarkdown/notebook.html).

```{r plan_to_notebook_planschapter}
plan_to_notebook(plan, "new_notebook.Rmd")
cat(readLines("new_notebook.Rmd"), sep = "\n")

code_to_plan("new_notebook.Rmd")
```

## So why do we use plans?

If you have ever waited more than 10 minutes for an R script to finish, then you know the frustration of having to rerun the whole thing every time you make a change. Plans make life easier.

### Plans chop up the work into pieces.

Some targets may need an update while others may not. In the [walkthrough](#walkthrough), `make()` was smart enough to skip the data cleaning step and just rebuild the plot and report. `drake` and its plans compartmentalize the work, and this can save you from wasted effort in the long run.

### `drake` uses plans to schedule you work.

`make()` automatically learns the build order of your targets and [how to run them in parallel](#hpc). The underlying magic is [_static code analysis_](http://adv-r.had.co.nz/Expressions.html#ast-funs), which automatically detects the dependencies of each target without having to run its command.

```{r depscode_plans}
create_plot <- function(data) {
  ggplot(data, aes(x = .data$Petal.Width, fill = .data$Species)) +
    geom_histogram(bins = 20)
}

deps_code(create_plot)

deps_code(quote(create_plot(datasets::iris)))
```

Because of the dependency relationships, row order does not matter once the plan is fully defined. The following plan declares `file` before `plot`.

```{r smallplan__}
small_plan <- drake_plan(
  file = ggsave(file_out("plot.png"), plot, width = 7, height = 5),
  plot = create_plot(datasets::iris)
)
```

But `file` actually depends on `plot`.

```{r smallvis__}
small_config <- drake_config(small_plan)
vis_drake_graph(small_config)
```

So `make()` builds `plot` first.

```{r smallmake__}
library(ggplot2)
make(small_plan)
```

## Special custom columns in your plan

You can add other columns besides the required `target` and `command`.

```{r addcolplan}
cbind(small_plan, cpu = c(1, 2))
```

Within `drake_plan()`, `target()` lets you create any custom column except `target`, `command`, and `transform`, the last of which [has a special meaning](https://ropenscilabs.github.io/drake-manual/plans.html#create-large-plans-the-easy-way).

```{r targetfn}
drake_plan(
  file = target(
    ggsave(file_out("plot.png"), plot),
    elapsed = 10
  ),
  create_plot(datasets::iris)
)
```

The following columns have special meanings for `make()`.

- `format`: set a storage format to save big targets more efficiently. Most formats are faster than ordinary storage, and they consume far less memory. Available formats:
    - `"fst"`: save big data frames fast. The target must be a data frame, and you must have the `fst` package installed.
    - `"keras"`: save Keras models as HDF5 files. Requires the `keras` package. Warning: `format = "keras"` is incompatible with certain kinds of high-performance computing. This is because a Keras model must be serialized before being sent to another R process, and `format = "keras"` does not serialize models. If you use HPC and master caching (e.g. `make(parallelism = "clustermq", caching = "master")`) consider one of the workarounds listed in the "High-performance computing caveats" section of <https://ropenscilabs.github.io/drake-manual/churn.html>.
    - `"rds"`: save any object. This is similar to the default storage except we avoid creating a serialized copy of the entire target in memory. Requires R >= 3.5.0 so drake can use ALTREP.
- `trigger`: rule to decide whether a target needs to run. See the [trigger chapter](#triggers) to learn more.
- `elapsed` and `cpu`: number of seconds to wait for the target to build before timing out (`elapsed` for elapsed time and `cpu` for CPU time).
- `hpc`: logical values (`TRUE`/`FALSE`/`NA`) whether to send each target to parallel workers. [Click here](https://ropenscilabs.github.io/drake-manual/hpc.html#selectivity) to learn more.
- `resources`: target-specific lists of resources for a computing cluster. See the advanced options in the [parallel computing](#hpc) chapter for details.
- `caching`: overrides the `caching` argument of [make()] for each target individually. Only supported in `drake` version 7.6.1.9000 and above. Possible values:
    - "master": tell the master process to store the target in the cache.
    - "worker": tell the HPC worker to store the target in the cache.
    - NA: default to the `caching` argument of [make()].
- `retries`: number of times to retry building a target in the event of an error.
- `seed`: pseudo-random number generator (RNG) seed for each target. `drake` usually computes its own unique reproducible target-specific seeds using the target name and the global seed (the `seed` argument of `make()` and `drake_config()`). Any non-missing seeds in the `seed` column override `drake`'s default target seeds.


## Large plans

`drake` version 7.0.0 introduced new syntax to make it easier to create plans. To try it out before the next [CRAN](http://cran.r-project.org) release, install the [current development version](https://github.com/ropensci/drake) from GitHub.

```{r installdevdrakedsl, eval = FALSE}
install.packages("remotes")
library(remotes)
install_github("ropensci/drake")
```

### How to create large plans

Ordinarily, `drake_plan()` requires you to write out all the targets one-by-one. This is a literal pain.

```{r fulldrakeplanlongstats, eval = FALSE}
drake_plan(
  data = get_data(),
  analysis_1_1 = fit_model_x(data, mean = 1, sd = 1),
  analysis_2_1 = fit_model_x(data, mean = 2, sd = 1),
  analysis_5_1 = fit_model_x(data, mean = 5, sd = 1),
  analysis_10_1 = fit_model_x(data, mean = 10, sd = 1),
  analysis_100_1 = fit_model_x(data, mean = 100, sd = 1),
  analysis_1000_1 = fit_model_x(data, mean = 1000, sd = 1),
  analysis_1_2 = fit_model_x(data, mean = 1, sd = 2),
  analysis_2_2 = fit_model_x(data, mean = 2, sd = 2),
  analysis_5_2 = fit_model_x(data, mean = 5, sd = 2),
  analysis_10_2 = fit_model_x(data, mean = 10, sd = 2),
  analysis_100_2 = fit_model_x(data, mean = 100, sd = 2),
  analysis_1000_2 = fit_model_x(data, mean = 1000, sd = 2),
  # UUUGGGHH my wrists are cramping! :( ...
)
```

Transformations reduce typing, especially when combined with tidy evaluation (`!!`).

```{r draketrans1}
lots_of_sds <- as.numeric(1:1e3)

drake_plan(
  data = get_data(),
  analysis = target(
    fun(data, mean = mean_val, sd = sd_val),
    transform = cross(mean_val = c(2, 5, 10, 100, 1000), sd_val = !!lots_of_sds)
  )
)
```

Behind the scenes during a transformation, `drake_plan()` creates new columns to track what is happening. You can see them with `trace = TRUE`.

```{r draketrans3}
drake_plan(
  data = get_data(),
  analysis = target(
    analyze(data, mean, sd),
    transform = map(mean = c(3, 4), sd = c(1, 2))
  ),
  trace = TRUE
)
```

Because of those columns, you can chain transformations together in complex pipelines.

```{r draketrans4}
plan1 <- drake_plan(
  small = get_small_data(),
  large = get_large_data(),
  analysis = target( # Analyze each dataset once with a different mean.
    analyze(data, mean),
    transform = map(data = c(small, large), mean = c(1, 2))
  ),
  # Calculate 2 different performance metrics on every model fit.
  metric = target(
    metric_fun(analysis),
    # mse = mean squared error, mae = mean absolute error.
    # Assume these are functions you write.
    transform = cross(metric_fun = c(mse, mae), analysis)
  ),
  # Summarize the performance metrics for each dataset.
  summ_data = target(
    summary(metric),
    transform = combine(metric, .by = data)
  ),
  # Same, but for each metric type.
  summ_metric = target(
    summary(metric),
    transform = combine(metric, .by = metric_fun)
  )
)

plan1

config1 <- drake_config(plan1)
vis_drake_graph(config1)
```

And you can write the transformations in any order. The following plan is equivalent to `plan1` despite the rearranged rows.

```{r draketrans4b}
plan2 <- drake_plan(
  # Calculate 2 different performance metrics on every model fit.
  summ_metric = target(
    summary(metric),
    transform = combine(metric, .by = metric_fun)
  ),
  metric = target(
    metric_fun(analysis),
    # mse = mean squared error, mae = mean absolute error.
    # Assume these are functions you write.
    transform = cross(metric_fun = c(mse, mae), analysis)
  ),
  small = get_small_data(),
  analysis = target( # Analyze each dataset once with a different mean.
    analyze(data, mean),
    transform = map(data = c(small, large), mean = c(1, 2))
  ),
  # Summarize the performance metrics for each dataset.
  summ_data = target(
    summary(metric),
    transform = combine(metric, .by = data)
  ),
  large = get_large_data()
  # Same, but for each metric type.
)

plan2

config2 <- drake_config(plan2)
vis_drake_graph(config2)
```


### Start small

Some plans are too large to deploy right away.

```{r max_expand_dsl}
plan <- drake_plan(
  data = target(
    get_data(source),
    transform = map(source = !!seq_len(25))
  ),
  analysis = target(
    fn(data, param),
    transform = cross(
      data,
      fn = !!letters,
      param = !!seq_len(25)
    ),
  ),
  result = target(
    bind_rows(analysis),
    transform = combine(analysis, .by = fn)
  )
)

dim(plan)
```

It is extremely difficult to understand, visualize, test, and debug a workflow with so many targets. `make()`, `drake_config()`, and `vis_drake_graph()` simply take too long if you are not ready for production.

To speed up initial testing and experimentation, you may want to limit the number of extra targets created by the `map()` and `cross()` transformations. Simply set `max_expand` in `drake_plan()`.

```{r max_expand_dslfinal}
plan <- drake_plan(
  max_expand = 2,
  data = target(
    get_data(source),
    transform = map(source = !!seq_len(25))
  ),
  analysis = target(
    fn(data, param),
    transform = cross(
      data,
      fn = !!letters,
      param = !!seq_len(25)
    ),
  ),
  result = target(
    bind_rows(analysis),
    transform = combine(analysis, .by = fn)
  )
)

plan
```

With a downsized plan, we can inspect the graph to make sure the dependencies line up correctly.

```{r max_expand_dsl2}
config <- drake_config(plan)
vis_drake_graph(config)
```

We can even run `make(plan)` and check a strategic subset of targets.

```{r max_expand_dsl3, eval = FALSE}
make(plan)                       # Run the small subset of targets we kept.
loadd()                          # Load all those targets into memory.
summary(analysis_z_25L_data_13L) # Look at the values of those targets
                                 # and decide if we are ready to scale up.
```

When we are ready to scale back up, we simply remove `max_expand` from the call to `drake_plan()`. Nothing else needs to change.

```{r max_expand_dsl4}
plan <- drake_plan(
  data = target(
    get_data(source),
    transform = map(source = !!seq_len(25))
  ),
  analysis = target(
    fn(data, param),
    transform = cross(
      data,
      fn = !!letters,
      param = !!seq_len(25)
    ),
  ),
  result = target(
    bind_rows(analysis),
    transform = combine(analysis, .by = fn)
  )
)

nrow(plan)
```

### The types of transformations

`drake` supports four types of transformations: `map()`, `cross()`, `split()` (unsupported in `drake` <= 7.3.0), and `combine()`. These are not actual functions, but you can treat them as functions when you use them in `drake_plan()`. Each transformation takes after a function from the [Tidyverse](https://www.tidyverse.org/).

| `drake`     | Tidyverse analogue          |
|-------------|-----------------------------|
| `map()`     | `pmap()` from `purrr`       |
| `cross()`   | `crossing()` from `tidyr`   |
| `split()`   | `group_map()`  from `dplyr` |
| `combine()` | `summarize()` from `dplyr`  |

#### `map()`

`map()` creates a new target for each row in a grid.

```{r drakemap1}
drake_plan(
  x = target(
    simulate_data(center, scale),
    transform = map(center = c(2, 1, 0), scale = c(3, 2, 1))
  )
)
```

You can supply your own custom grid using the `.data` argument. Note the use of `!!` below.

```{r drakemapgrid}
my_grid <- tibble(
  sim_function = c("rnrom", "rt", "rcauchy"),
  title = c("Normal", "Student t", "Cauchy")
)
my_grid$sim_function <- rlang::syms(my_grid$sim_function)

drake_plan(
  x = target(
    simulate_data(sim_function, title, center, scale),
    transform = map(
      center = c(2, 1, 0),
      scale = c(3, 2, 1),
      .data = !!my_grid,
      # In `.id`, you can select one or more grouping variables
      # for pretty target names.
      # Set to FALSE to use short numeric suffixes.
      .id = sim_function # Try `.id = c(sim_function, center)` yourself.
    )
  )
)
```

#### Special considerations in `map()`

`map()` column-binds variables together to create a grid. The lengths of those variables need to be conformable just as with `data.frame()`.

```{r drakemaperr, error = TRUE}
drake_plan(
  x = target(
    simulate_data(center, scale),
    transform = map(center = c(2, 1, 0), scale = c(3, 2))
  )
)
```

Sometimes, the results are sensible when grouping variable lengths are multiples of each other, but be careful.

```{r drakemap2}
drake_plan(
  x = target(
    simulate_data(center, scale),
    transform = map(center = c(2, 1, 0), scale = 4)
  )
)
```

Things get tricker when `drake` reuses grouping variables from previous transformations. For example, below, each `x_*` target has an associated `nrow` value. So if you write `transform = map(x)`, then `nrow` goes along for the ride.

```{r drakemap3}
drake_plan(
  x = target(
    simulate_data(center),
    transform = map(center = c(1, 2))
  ),
  y = target(
    process_data(x, center),
    transform = map(x)
  ),
  trace = TRUE # Adds extra columns for the grouping variables.
)
```

But if other targets have `centers`'s of their own, `drake_plan()` may not know what to do with them.

```{r drakemap4}
drake_plan(
  w = target(
    simulate_data(center),
    transform = map(center = c(3, 4))
  ),
  x = target(
    simulate_data_2(center),
    transform = map(center = c(1, 2))
  ),
  y = target(
    process_data(w, x, center),
    transform = map(w, x)
  ),
  trace = TRUE
)
```

The problems is that there are 4 values of `center` and only two `x_*` targets (and two `y_*` targets). Even if you explicitly supply `center` to the transformation, `map()` can only takes the first two values.

```{r drakemap5}
drake_plan(
  w = target(
    simulate_data(center),
    transform = map(center = c(3, 4))
  ),
  x = target(
    simulate_data_2(center),
    transform = map(center = c(1, 2))
  ),
  y = target(
    process_data(w, x, center),
    transform = map(w, x, center)
  ),
  trace = TRUE
)
```

So please inspect the plan before you run it with `make()`. Once you have a `drake_config()` object, `vis_drake_graph()` and `deps_target()` can help.

#### `cross()`

`cross()` creates a new target for each combination of argument values.

```{r drakecross}
drake_plan(
  x = target(
    simulate_data(nrow, ncol),
    transform = cross(nrow = c(1, 2, 3), ncol = c(4, 5))
  )
)
```


#### `split()`

`split()` is not supported in `drake` 7.3.0 and below. It should reach the next CRAN release in June 2019.

The `split()` transformation distributes a dataset as uniformly as possible across multiple targets.

```{r, split1}
plan <- drake_plan(
  large_data = get_data(),
  slice_analysis = target(
    large_data %>%
      analyze(),
    transform = split(large_data, slices = 4)
  ),
  results = target(
    dplyr::bind_rows(slice_analysis),
    transform = combine(slice_analysis)
  )
)

plan
```

```{r split3}
config <- drake_config(plan)
vis_drake_graph(config)
```

Here, `drake_slice()` takes a single subset of the data at runtime. 

```{r darke_slice}
dataset <- tibble::as_tibble(iris)
dim(dataset)

drake_slice(dataset, slices = 50, index = 1)

drake_slice(dataset, slices = 50, index = 2)

drake_slice(dataset, slices = 3, index = 1, margin = 2)
```

`drake_slice()` supports data frames, matrices, and arbitrary arrays, and you can subset on any margin (rows, columns, etc). Even better, you can split up ordinary vectors and lists. Instead of taking slices of the actual dataset, you can split up a set of indices. Combined with [high-performance computing](#hpc), this should help you avoid loading an entire big data file into memory on a single compute node.

```{r splitfilenomem}
plan <- drake_plan(
  all_rows = file_in("huge.csv") %>%
    number_of_rows() %>%
    seq_len(),
  rows = target(
    all_rows,
    transform = split(all_rows, slices = 3)
  ),
  analysis = target(
    read_rows( # custom function
      file = file_in("huge.csv"),
      rows = rows
    ) %>%
      analyze_data(),
    transform = map(rows, .id = rows_index) # an internal trick
  )
)

drake_plan_source(plan)
```


#### `combine()`

In `combine()`, you can insert multiple targets into individual commands. The closest comparison is the unquote-splice operator `!!!` from the Tidyverse.

```{r transform5}
plan <- drake_plan(
  data = target(
    sim_data(mean = x, sd = y),
    transform = map(x = c(1, 2), y = c(3, 4))
  ),
  larger = target(
    bind_rows(data, .id = "id") %>%
      arrange(sd) %>%
      head(n = 400),
    transform = combine(data)
  )
)

plan

drake_plan_source(plan)

config <- drake_config(plan)
vis_drake_graph(config)
```

You can different groups of targets in the same command.

```{r transform5b}
plan <- drake_plan(
  data_group1 = target(
    sim_data(mean = x, sd = y),
    transform = map(x = c(1, 2), y = c(3, 4))
  ),
  data_group2 = target(
    pull_data(url),
    transform = map(url = c("example1.com", "example2.com"))
  ),
  larger = target(
    bind_rows(data_group1, data_group2, .id = "id") %>%
      arrange(sd) %>%
      head(n = 400),
    transform = combine(data_group1, data_group2)
  )
)

drake_plan_source(plan)
```

And as with `group_by()` from `dplyr`, you can create a separate aggregate for each combination of levels of the arguments. Just pass a symbol or vector of symbols to the optional `.by` argument of `combine()`.

```{r transform6}
plan <- drake_plan(
  data = target(
    sim_data(mean = x, sd = y, skew = z),
    transform = cross(x = c(1, 2), y = c(3, 4), z = c(5, 6))
  ),
  combined = target(
    bind_rows(data, .id = "id") %>%
      arrange(sd) %>%
      head(n = 400),
    transform = combine(data, .by = c(x, y))
  )
)

drake_plan_source(plan)
```

In your post-processing, you may need the values of `x` and `y` that underly `data_1_3` and `data_2_4`. Solution: get the trace and the target names. We define a new plan

```{r transform7}
plan <- drake_plan(
  data = target(
    sim_data(mean = x, sd = y),
    transform = map(x = c(1, 2), y = c(3, 4))
  ),
  larger = target(
    post_process(data, plan = ignore(plan)) %>%
      arrange(sd) %>%
      head(n = 400),
    transform = combine(data)
  ),
  trace = TRUE
)

drake_plan_source(plan)
```

and a new function

```{r transform8, eval = FALSE}
post_process <- function(..., plan) {
  args <- list(...)
  names(args) <- all.vars(substitute(list(...)))
  trace <- filter(plan, target %in% names(args))
  # Do post-processing with args and trace.
}
```

### Grouping variables

A grouping variable is an argument to `map()`, `cross()`, or `combine()` that identifies a sub-collection of target names. Grouping variables can be either literals or symbols. Symbols can be scalars or vectors, and you can pass them to transformations with or without argument names.

#### Literal arguments

When you pass a grouping variable of literals, you must use an explicit argument name. One does not simply write `map(c(1, 2))`.

```{r namedlittrans}
drake_plan(x = target(sqrt(y), transform = map(y = c(1, 2))))
```

And if you supply integer sequences the usual way, you may notice some rows are missing.

```{r namedlittrans2}
drake_plan(x = target(sqrt(y), transform = map(y = 1:3)))
```

Tidy evaluation and `as.numeric()` make sure all the data points show up.

```{r namedlittrans3}
y_vals <- as.numeric(1:3)
drake_plan(x = target(sqrt(y), transform = map(y = !!y_vals)))
```

Character vectors usually work without a hitch, and quotes are converted into dots to make valid target names.

```{r namedlittrans4}
drake_plan(x = target(get_data(y), transform = map(y = c("a", "b", "c"))))
```

```{r namedlittrans5}
y_vals <- letters
drake_plan(x = target(get_data(y), transform = map(y = !!y_vals)))
```

#### Named symbol arguments

Symbols passed with explicit argument names define new groupings of existing targets on the fly, and only the `map()` and `cross()` transformations can accept them this ways. To generate long symbol lists, use the `syms()` function from the `rlang` package. Remember to use the tidy evaluation operator `!!` inside the transformation.

```{r mapsym2}
vals <- rlang::syms(letters)
drake_plan(x = target(get_data(y), transform = map(y = !!vals)))
```

The new groupings carry over to downstream targets by default, which you can see with `trace = TRUE`. Below, the rows for targets `w_x` and `w_y` have entries in the and `z` column.

```{r mapsym3}
drake_plan(
  x = abs(mean(rnorm(10))),
  y = abs(mean(rnorm(100, 1))),
  z = target(sqrt(val), transform = map(val = c(x, y))),
  w = target(val + 1, transform = map(val)),
  trace = TRUE
)
```

However, this is *incorrect* because `w` does not depend on `z_x` or `z_y`. So for `w`, you should write `map(val = c(x, y))` instead of `map(val)` to tell `drake` to clear the trace. Then, you will see `NA`s in the `z` column for `w_x` and `w_y`, which is right and proper.

```{r mapsym4}
drake_plan(
  x = abs(mean(rnorm(10))),
  y = abs(mean(rnorm(100, 1))),
  z = target(sqrt(val), transform = map(val = c(x, y))),
  w = target(val + 1, transform = map(val = c(x, y))),
  trace = TRUE
)
```

### Tags

Tags are special optional grouping variables. They are ignored while the transformation is happening and then added to the plan to help subsequent transformations. There are two types of tags:

1. In-tags, which contain the target name you start with, and
2. Out-tags, which contain the target names generated by the transformations.

```{r gettags}
drake_plan(
  x = target(
    command,
    transform = map(y = c(1, 2), .tag_in = from, .tag_out = c(to, out))
  ),
  trace = TRUE
)
```

Subsequent transformations can use tags as grouping variables and add to existing tags.

```{r draketrans2}
plan <- drake_plan(
  prep_work = do_prep_work(),
  local = target(
    get_local_data(n, prep_work),
    transform = map(n = c(1, 2), .tag_in = data_source, .tag_out = data)
  ),
  online = target(
    get_online_data(n, prep_work, port = "8080"),
    transform = map(n = c(1, 2), .tag_in = data_source, .tag_out = data)
  ),
  summary = target(
    summarize(bind_rows(data, .id = "data")),
    transform = combine(data, .by = data_source)
  ),
  munged = target(
    munge(bind_rows(data, .id = "data")),
    transform = combine(data, .by = n)
  )
)

plan

config <- drake_config(plan)
vis_drake_graph(config)
```

<br>

### Target names

All transformations have an optional `.id` argument to control the names of targets. Use it to select the grouping variables that go into the names, as well as the order they appear in the suffixes. 

```{r dslidnames}
drake_plan(
  data = target(
    get_data(param1, param2),
    transform = map(
      param1 = c(123, 456),
      param2 = c(7, 9),
      param2 = c("abc", "xyz"),
      .id = param2
    )
  )
)
```

```{r dslidnames2}
drake_plan(
  data = target(
    get_data(param1, param2),
    transform = map(
      param1 = c(123, 456),
      param2 = c(7, 9),
      param2 = c("abc", "xyz"),
      .id = c(param2, param1)
    )
  )
)
```

```{r dslidnames3}
drake_plan(
  data = target(
    get_data(param1, param2),
    transform = map(
      param1 = c(123, 456),
      param2 = c(7, 9),
      param2 = c("abc", "xyz"),
      .id = c(param1, param2)
    )
  )
)
```

Set `.id` to `FALSE` to ignore the grouping variables altogether.

```{r dslidnames4}
drake_plan(
  data = target(
    get_data(param1, param2),
    transform = map(
      param1 = c(123, 456),
      param2 = c(7, 9),
      param2 = c("abc", "xyz"),
      .id = FALSE
    )
  )
)
```

Finally, `drake` supports a special `.id_chr` symbol in commands to let you refer to the name of the current target as a character string.

```{r dslidnames5}
as_chr <- function(x) {
  deparse(substitute(x))
}
plan <- drake_plan(
  data = target(
    get_data(param),
    transform = map(param = c(123, 456))
  ),
  keras_model = target(
    save_model_hdf5(fit_model(data), file_out(!!sprintf("%s.h5", .id_chr))),
    transform = map(data, .id = param)
  ),
  result = target(
    predict(load_model_hdf5(file_in(!!sprintf("%s.h5", as_chr(keras_model))))),
    transform = map(keras_model, .id = param)
  )
)

plan
```

```{r dslnames6}
drake_plan_source(plan)
```
