# Workflow plan data frames {#plans}

```{r loaddrake14, echo = FALSE}
unlink(
  c("main", "report.Rmd", "raw_data.xlsx"),
  recursive = TRUE
)
knitr::opts_chunk$set(collapse = TRUE)
suppressPackageStartupMessages(library(drake))
suppressPackageStartupMessages(library(glue))
suppressPackageStartupMessages(library(purrr))
suppressPackageStartupMessages(library(rlang))
suppressPackageStartupMessages(library(tidyverse))
clean(destroy = TRUE)
invisible(drake_example("main", overwrite = TRUE))
invisible(file.copy("main/raw_data.xlsx", ".", overwrite = TRUE))
invisible(file.copy("main/report.Rmd", ".", overwrite = TRUE))
tmp <- suppressWarnings(drake_plan(x = 1, y = 2))
```

## What is a `drake` plan?

A `drake` plan is a data frame with columns named `target` and `command`. Each target is an R object produced in your workflow, and each command is the R code to produce it. You can create plans any way you like, and the `drake_plan()` function is particularly convenient. Recall the plan from our [previous example](#main):

```{r firstexampleplan}
plan <- drake_plan(
  raw_data = readxl::read_excel(file_in("raw_data.xlsx")),
  data = raw_data %>%
    mutate(Species = forcats::fct_inorder(Species)),
  hist = create_plot(data),
  fit = lm(Sepal.Width ~ Petal.Width + Species, data),
  report = rmarkdown::render(
    knitr_in("report.Rmd"),
    output_file = file_out("report.html"),
    quiet = TRUE
  )
)
plan
```

`drake_plan()` does not run the workflow, it only creates the plan. To build the actual targets, we need to run `make()`. Creating the plan is like writing an R script, and running `make(your_plan)` is like calling [`source("your_script.R")`](https://www.rdocumentation.org/packages/base/versions/3.5.2/topics/source).

## Plans are similar to R scripts.

Your `drake` plan is like a top-level R script that runs everything from end to end. In fact, you can convert back and forth between plans and scripts using functions [`plan_to_code()`](https://ropensci.github.io/drake/reference/plan_to_code.html) and [`code_to_plan()`](https://ropensci.github.io/drake/reference/code_to_plan.html) (with some [caveats](https://ropensci.github.io/drake/reference/code_to_plan.html#details)).

```{r plan_to_code_planschapter}
plan_to_code(plan, "new_script.R")
cat(readLines("new_script.R"), sep = "\n")

code_to_plan("new_script.R")
```

And [`plan_to_notebook()`](https://ropensci.github.io/drake/reference/plan_to_notebook.html) turns plans into [R notebooks](https://bookdown.org/yihui/rmarkdown/notebook.html).

```{r plan_to_notebook_planschapter}
plan_to_notebook(plan, "new_notebook.Rmd")
cat(readLines("new_notebook.Rmd"), sep = "\n")

code_to_plan("new_notebook.Rmd")
```

## So why do we use plans?

If you have ever waited more than 10 minutes for an R script to finish, then you know the frustration of having to rerun the whole thing every time you make a change. Plans make life easier.

### Plans chop up the work into pieces.

Some targets may need an update while others may not. In our [first example](#main), `make()` was smart enough to skip the data cleaning step and just rebuild the plot and report. `drake` and its plans compartmentalize the work, and this can save you from wasted effort in the long run.

### `drake` uses plans to schedule you work.

`make()` automatically learns the build order of your targets and [how to run them in parallel](#hpc). The underlying magic is [_static code analysis_](http://adv-r.had.co.nz/Expressions.html#ast-funs), which automatically detects the dependencies of each target without having to run its command.

```{r depscode_plans}
create_plot <- function(data) {
  ggplot(data, aes_string(x = "Petal.Width", fill = "Species")) +
    geom_histogram(bins = 20)
}

deps_code(create_plot)

deps_code("create_plot(datasets::iris)")
```

Because of the dependency relationships, row order does not matter once the plan is fully defined. The following plan declares `file` before `plot`.

```{r smallplan__}
small_plan <- drake_plan(
  file = ggsave(file_out("plot.png"), plot, width = 7, height = 5),
  plot = create_plot(datasets::iris)
)
```

But `file` actually depends on `plot`.

```{r smallvis__}
small_config <- drake_config(small_plan)
vis_drake_graph(small_config)
```

So `make()` builds `plot` first.

```{r smallmake__}
library(ggplot2)
make(small_plan)
```

## Special custom columns in your plan.

You can add other columns besides the required `target` and `command`.

```{r addcolplan}
cbind(small_plan, cpu = c(1, 2))
```

Within `drake_plan()`, `target()` lets you create any custom column except `transform` and `group`, which have special meanings in `drake`'s [domain-specific language](http://adv-r.had.co.nz/dsl.html), (See the next section.)

```{r targetfn}
drake_plan(
  file = target(
    ggsave(file_out("plot.png"), plot),
    elapsed = 10
  ),
  create_plot(datasets::iris)
)
```

The following columns have special meanings for `make()`.

- `elapsed` and `cpu`: number of seconds to wait for the target to build before timing out (`elapsed` for elapsed time and `cpu` for CPU time).
- `priority`: for [parallel computing](#hpc), optionally rank the targets according to priority in the scheduler.
- `resources`: target-specific lists of resources for a computing cluster. See the advanced options in the [parallel computing](#hpc) chapter for details.
- `retries`: number of times to retry building a target in the event of an error.
- `trigger`: rule to decide whether a target needs to run. See the [trigger chapter](#triggers) to learn more.

## Create large plans the *easy* way

`drake` version 7.0.0 will introduce new experimental syntax to make it easer to create plans. To try it out before the next [CRAN](http://cran.r-project.org) release, install the [current development version](https://github.com/ropensci/drake) from GitHub.

```{r installdevdrakedsl, eval = FALSE}
install.packages("remotes")
library(remotes)
install_github("ropensci/drake")
```version 7.0.0 reaches

### Transformations: a high level

Transformations let you generate targets from templates. The general syntax is

```{r transformat, eval = FALSE}
drake_plan(
  template_target = target(
    your_command,
    transform = supported_transformation(grouping_variables),
    group = c(custom_group_1, custom_group_2) # optional
  )
)
```

The behavior mimics the Tidyverse. Transformations are just like Tidyverse verbs, and grouping variables are like arguments to `dplyr::group_by()`. Supported transformations:

- **map()**: like `purrr::pmap()`. Creates a new target for each index along your grouping variables. Grouping variables must be all the same length.
- **cross()**: like `tidyr::crossing()`. Creates a new target for each unique combination of levels of the grouping variables.
- **reduce()**: like `dplyr::summarize()`. Targets are aggregated at each combination of levels of the grouping variables.

### Transformations minimize typing

It can get tiring to write out every single target by hand.

```{r fulldrakeplanlongstats, eval = FALSE}
drake_plan(
  data = get_data(),
  analysis_1_1 = fit_model_x(data, mean = 1, sd = 1),
  analysis_2_1 = fit_model_x(data, mean = 2, sd = 1),
  analysis_5_1 = fit_model_x(data, mean = 5, sd = 1),
  analysis_10_1 = fit_model_x(data, mean = 10, sd = 1),
  analysis_100_1 = fit_model_x(data, mean = 100, sd = 1),
  analysis_1000_1 = fit_model_x(data, mean = 1000, sd = 1),
  analysis_1_2 = fit_model_x(data, mean = 1, sd = 2),
  analysis_2_2 = fit_model_x(data, mean = 2, sd = 2),
  analysis_5_2 = fit_model_x(data, mean = 5, sd = 2),
  analysis_10_2 = fit_model_x(data, mean = 10, sd = 2),
  analysis_100_2 = fit_model_x(data, mean = 100, sd = 2),
  analysis_1000_2 = fit_model_x(data, mean = 1000, sd = 2),
  # uuuuugh my wrists are cramping :( ...
)
```

Save yourself trouble and apply a transformation.

```{r transform1}
drake_plan(
  data = get_data(),
  analysis = target(
    fit_model_x(data, mean = mean_val, sd = sd_val),
    transform = cross(
      mean = c(1, 2, 5, 10, 100, 1000),
      sd = c(1, 2, 5, 10)
    )
  )
)
```

Use `map()` to move along the indices of your grouping variables.

```{r transform1b}
drake_plan(
  data = get_data(),
  analysis = target(
    fit_model(data, mean = mean_val, sd = sd_val),
    transform = map(
      fit_model = c(fit_model_x, fit_model_y),
      mean_val = c(0, 1),
      sd_val = c(2, 3)
    )
  )
)
```

Use `cross()` to get a model for each combination of `fit_model`, `mean_val` and `sd_val`.

```{r transform2}
drake_plan(
  data = get_data(),
  analysis = target(
    fit_model(data, mean = mean_val, sd = sd_val),
    transform = cross(
      fit_model = c(fit_model_x, fit_model_y),
      mean_val = c(0, 1),
      sd_val = c(2, 3)
    )
  )
)
```

You can use multiple transformations. The code below plans multiple datasets and declares multiple analyses for each one.

```{r transform3}
drake_plan(
  data = target(
    get_data(name),
    transform = map(name = c("A", "B"))
  ),
  analysis = target(
    fit_model(data, mean = mean_val, sd = sd_val),
    transform = cross(
      data,
      fit_model = c(fit_model_x, fit_model_y),
      mean_val = c(0, 1),
      sd_val = c(2, 3)
    )
  )
)
```

For really huge plans, you can define the grouping variables in advance and use the tidy evaluation operator `!!` to plug in the values.

```{r transform4}
data_names <- LETTERS
model_functions <- rlang::syms(c("fit_model_x", "fit_model_y"))
mean_vals <- 1:1000
sd_vals <- 1:1000

drake_plan(
  data = target(
    get_data(name),
    transform = map(name = !!data_names)
  ),
  analysis = target(
    fit_model(data, mean = mean_val, sd = sd_val),
    transform = cross(
      data,
      fit_model = !!model_functions,
      mean_val = !!mean_vals,
      sd_val = !!sd_vals
    )
  )
)
```
A reduction gathers targets into named lists, which you are free to post-process with `do.call()` or similar.

```{r transform5}
plan <- drake_plan(
  data = target(
    sim_data(mean = x, sd = y),
    transform = map(x = c(1, 2), y = c(3, 4))
  ),
  target(
    do.call(rbind, data),
    transform = reduce()
  )
)

plan

config <- drake_config(plan)
vis_drake_graph(config)
```

You can configure `reduce()` to give you a summary for each combination of grouping levels.

```{r transform6}
plan <- drake_plan(
  data = target(
    sim_data(mean = x, sd = y),
    transform = cross(x = c(1, 2), y = c(3, 4))
  ),
  target(
    do.call(rbind, data),
    transform = reduce(x)
  )
)

config <- drake_config(plan)
vis_drake_graph(config)
```

Groupings for `reduce()` propagate downstream. Click and drag the nodes in the graph to mentally unpack the transformations.

```{r groupings9}
plan <- drake_plan(
  small = simulate(48),
  large = simulate(64),
  reg = target(
    reg_fun(data),
    transform = cross(reg_fun = c(reg1, reg2), data = c(small, large))
  ),
  summ = target(
    sum_fun(data, reg),
    transform = cross(sum_fun = c(coef, residuals), reg)
  ),
  winners = target(
    min(summ),
    transform = reduce(data, sum_fun)
  ),
  others = target(
    analyze(list(c(summ), c(data))),
    transform = reduce(data, sum_fun)
  ),
  final_winner = target(
    min(winners),
    transform = reduce()
  )
)

config <- drake_config(plan)
vis_drake_graph(config)
```

 You can even define custom post-hoc groupings for further control. Just supply new symbols to `group`.

```{r groupings8}
plan <- drake_plan(
  data_sim = target(
    sim_data(mean = x, sd = y),
    transform = cross(x = c(1, 2), y = c(3, 4)),
    group = c(data, sim)
  ),
  data_download = target(
    download_data(url = x),
    transform = map(x = c("http://url_1", "http://url_2")),
    group = data
  ),
  summaries = target(
    compare_datasets(data),
    transform = reduce()
  )
)

config <- drake_config(plan)
vis_drake_graph(config)
```

<br>

## Create large plans the *old* way

`drake` provides several older utility that increase the flexibility of workflow plan creation.

- `drake_plan()`
- `map_plan()`
- `evaluate_plan()`
- `expand_plan()`
- `gather_by()`
- `reduce_by()`
- `gather_plan()`
- `reduce_plan()`

### `map_plan()`

[`purrr`](https://github.com/tidyverse/purrr)-like functional programming is like looping, but cleaner. The idea is to iterate the same computation over multiple different data points. You write a function to do something once, and a [`map()`](https://purrr.tidyverse.org/reference/map.html)-like helper invokes it on each point in your dataset. `drake`'s version of [`map()`](https://purrr.tidyverse.org/reference/map.html) &mdash; or more precisely, [`pmap_df()`](https://purrr.tidyverse.org/reference/map2.html) &mdash; is [`map_plan()`](https://ropensci.github.io/drake/reference/map_plan.html).

In the following example, we want to know how well each pair covariates in the [`mtcars` dataset](https://stat.ethz.ch/R-manual/R-devel/library/datasets/html/mtcars.html) can predict fuel efficiency (in miles per gallon). We will try multiple pairs of covariates using the same statistical analysis, so it is a great time for `drake`-flavored functional programming with `map_plan()`.

As with its cousin, [`pmap_df()`](https://purrr.tidyverse.org/reference/map2.html), [`map_plan()`](https://ropensci.github.io/drake/reference/map_plan.html) needs

1. A function.
2. A grid of function arguments.

Our function fits a fuel efficiency model given a *single* pair of covariate names `x1` and `x2`.

```{r map_plan_fn}
my_model_fit <- function(x1, x2, data){
  lm(as.formula(paste("mpg ~", x1, "+", x2)), data = data)
}
```

Our grid of function arguments is a data frame of possible values for `x1`, `x2`, and `data`.

```{r map_plan_covariates}
covariates <- setdiff(colnames(mtcars), "mpg") # Exclude the response variable.
args <- t(combn(covariates, 2)) # Take all possible pairs.
colnames(args) <- c("x1", "x2") # The column names must be the argument names of my_model_fit()
args <- tibble::as_tibble(args) # Tibbles are so nice.
args$data <- "mtcars"

args
```

Each row of `args` corresponds to a call to `my_model_fit()`. To actually write out all those function calls, we use `map_plan()`. 

```{r argsplan}
map_plan(args, my_model_fit)
```

We now have a plan, but it has a couple issues.

1. The `data` argument should be a symbol. In other words, we want `my_model_fit(data = mtcars)`, not `my_model_fit(data = "mtcars")`. So we use the [`syms()`](https://rlang.r-lib.org/reference/sym.html) function from the [`rlang`](https://github.com/r-lib/rlang) package turn `args$data` into a list of symbols.
2. The default argument names are ugly, so we can add a new `"id"` column to `args` (or select one with the `id` argument of `map_plan()`).

```{r mapplanid}
# Fixes (1)
args$data <- rlang::syms(args$data)

# Alternative if each element of `args$data` is code with multiple symbols:
# args$data <- purrr::map(args$data, rlang::parse_expr)

# Fixes (2)
args$id <- paste0("fit_", args$x1, "_", args$x2)

args
```

Much better.

```{r mapplanmakesymbols}
plan <- map_plan(args, my_model_fit)
plan
```

We may also want to retain information about the constituent function arguments of each target. With `map_plan(trace = TRUE)`, we can append the columns of `args` alongside the usual `"target"` and `"command"` columns of our plan.

```{r mapplantrace}
map_plan(args, my_model_fit, trace = TRUE)
```

In any case, we can now fit our models.

```{r map_plan_make}
make(plan, verbose = FALSE)
```

And inspect the output.

```{r map_plan_readd}
readd(fit_cyl_disp)
```

### Wildcard templating

In `drake`, you can write plans with wildcards. These wildcards are placeholders for text in commands. By iterating over the possible values of a wildcard, you can easily generate plans with thousands of targets. Let's say you are running a simulation study, and you need to generate sets of random numbers from different distributions.


```{r evaluteplan1}
plan <- drake_plan(
  t  = rt(1000, df = 5),
  normal = runif(1000, mean = 0, sd = 1)
)
```

If you need to generate many datasets with different means, you may wish to write out each target individually.

```{r evaluteplan2, eval = FALSE}
drake_plan(
  t  = rt(1000, df = 5),
  normal_0 = runif(1000, mean = 0, sd = 1),
  normal_1 = runif(1000, mean = 1, sd = 1),
  normal_2 = runif(1000, mean = 2, sd = 1),
  normal_3 = runif(1000, mean = 3, sd = 1),
  normal_4 = runif(1000, mean = 4, sd = 1),
  normal_5 = runif(1000, mean = 5, sd = 1),
  normal_6 = runif(1000, mean = 6, sd = 1),
  normal_7 = runif(1000, mean = 7, sd = 1),
  normal_8 = runif(1000, mean = 8, sd = 1),
  normal_9 = runif(1000, mean = 9, sd = 1)
)
```

But writing all that code manually is a pain and prone to human error. Instead, use `evaluate_plan()`

```{r evaluateplan3}
plan <- drake_plan(
  t  = rt(1000, df = 5),
  normal = runif(1000, mean = mean__, sd = 1)
)
evaluate_plan(plan, wildcard = "mean__", values = 0:9)
```

You can specify multiple wildcards at once. If multiple wildcards appear in the same command, you will get a new target for each unique combination of values.

```{r evaluateplan4}
plan <- drake_plan(
  t  = rt(1000, df = df__),
  normal = runif(1000, mean = mean__, sd = sd__)
)
evaluate_plan(
  plan,
  rules = list(
    mean__ = c(0, 1),
    sd__ = c(3, 4),
    df__ = 5:7
  )
)
```

Wildcards for `evaluate_plan()` do not need to have the double-underscore suffix. Any valid symbol will do.

```{r evaluateplan5}
plan <- drake_plan(
  t  = rt(1000, df = .DF.),
  normal = runif(1000, mean = `{MEAN}`, sd = ..sd)
)
evaluate_plan(
  plan,
  rules = list(
    "`{MEAN}`" = c(0, 1),
    ..sd = c(3, 4),
    .DF. = 5:7
  )
)
```

Set `expand` to `FALSE` to disable expansion.

```{r noexpand}
plan <- drake_plan(
  t  = rpois(samples__, lambda = mean__),
  normal = runif(samples__, mean = mean__)
)
evaluate_plan(
  plan,
  rules = list(
    samples__ = c(50, 100),
    mean__ = c(1, 5)
  ),
  expand = FALSE
)
```

Wildcard templating can sometimes be tricky. For example, suppose your project is to analyze school data, and your workflow checks several metrics of several schools. The idea is to write a workflow plan with your metrics and let the wildcard templating expand over the available schools.

```{r schoolswildcards1}
hard_plan <- drake_plan(
  credits = check_credit_hours(school__),
  students = check_students(school__),
  grads = check_graduations(school__),
  public_funds = check_public_funding(school__)
)

evaluate_plan(
  hard_plan,
  rules = list(school__ = c("schoolA", "schoolB", "schoolC"))
)
```

But what if some metrics do not make sense? For example, what if `schoolC` is a completely privately-funded school? With no public funds, `check_public_funds(schoolC)` may quit in error if we are not careful. This is where setting up workflow plans requires a little creativity. In this case, we recommend that you use two wildcards: one for all the schools and another for just the public schools. The new plan has no twelfth row.

```{r schoolsplanfinal}
plan_template <- drake_plan(
  school = get_school_data("school__"),
  credits = check_credit_hours(all_schools__),
  students = check_students(all_schools__),
  grads = check_graduations(all_schools__),
  public_funds = check_public_funding(public_schools__)
)
evaluate_plan(
  plan = plan_template,
  rules = list(
    school__ = c("A", "B", "C"),
    all_schools__ =  c("school_A", "school_B", "school_C"),
    public_schools__ = c("school_A", "school_B")
  )
)
```

Thanks to [Alex Axthelm](https://github.com/AlexAxthelm) for this use case in [issue 235](https://github.com/ropensci/drake/issues/235).


### Wildcard clusters

With `evaluate_plan(trace = TRUE)`, you can generate columns that show how the targets were generated from the wildcards.

```{r trace1}
plan_template <- drake_plan(
  school = get_school_data("school__"),
  credits = check_credit_hours(all_schools__),
  students = check_students(all_schools__),
  grads = check_graduations(all_schools__),
  public_funds = check_public_funding(public_schools__)
)
plan <- evaluate_plan(
  plan = plan_template,
  rules = list(
    school__ = c("A", "B", "C"),
    all_schools__ =  c("school_A", "school_B", "school_C"),
    public_schools__ = c("school_A", "school_B")
  ),
  trace = TRUE
)
plan
```

And then when you visualize the dependency graph, you can cluster nodes based on the wildcard info.

```{r tracevis1hide, echo = FALSE}
check_credit_hours <- check_students <- check_graduations <-
  check_public_funding <- get_school_data <- function(){}
```

```{r tracevisplans1}
config <- drake_config(plan)
vis_drake_graph(
  config,
  group = "all_schools__",
  clusters = c("school_A", "school_B", "school_C")
)
```

See the [visualization guide](#vis) for more details.

### Non-wildcard functions

#### `expand_plan()`

Sometimes, you just want multiple replicates of the same targets.

```{r expandplan}
plan <- drake_plan(
  fake_data = simulate_from_model(),
  bootstrapped_data = bootstrap_from_real_data(real_data)
)
expand_plan(plan, values = 1:3)
```


#### `gather_plan()` and `gather_by()`

Other times, you want to combine multiple targets into one. 

```{r gather1}
plan <- drake_plan(
  small = data.frame(type = "small", x = rnorm(25), y = rnorm(25)),
  large = data.frame(type = "large", x = rnorm(1000), y = rnorm(1000))
)
gather_plan(plan, target = "combined")
```

In this case, `small` and `large` are data frames, so it may be more convenient to combine the rows together.

```{r gather2}
gather_plan(plan, target = "combined", gather = "rbind")
```

See also `gather_by()` to gather multiple groups of targets based on other columns in the plan (e.g. from `evaluate_plan(trace = TRUE)`).

#### `reduce_plan()` and `reduce_by()`

`reduce_plan()` is similar to `gather_plan()`, but it allows you to combine multiple targets together in pairs. This is useful if combining everything at once requires too much time or computer memory, or if you want to parallelize the aggregation.

```{r reduceplan}
plan <- drake_plan(
  a = 1,
  b = 2,
  c = 3,
  d = 4
)
reduce_plan(plan)
```

You can control how each pair of targets gets combined.

```{r reduceplan2}
reduce_plan(plan, begin = "c(", op = ", ", end = ")")
```

See also `reduce_by()` to do reductions on multiple groups of targets based on other columns in the plan (e.g. from `evaluate_plan(trace = TRUE)`).

### Custom metaprogramming

The workflow plan is just a data frame. There is nothing magic about it, and you can create it any way you want. With your own custom metaprogramming, you don't even need the `drake_plan()` function.

The following example could more easily be implemented with `map_plan()`, but we use other techniques to demonstrate the versatility of custom metaprogramming. Let's consider a file-based example workflow. Here, our targets execute Linux commands to process input files and create output files.

<pre><code>cat in1.txt > out1.txt
cat in2.txt > out2.txt
</code></pre>

The [`glue`](https://github.com/tidyverse/glue) package can automatically generate these Linux commands.

```{r systemcmdglue}
library(glue)
glue_data(
  list(
    inputs = c("in1.txt", "in2.txt"), 
    outputs = c("out1.txt", "out2.txt")
  ),
  "cat {inputs} > {outputs}"
)
```

Our `drake` commands will use `system()` to execute the Linux commands that [`glue`](https://github.com/tidyverse/glue) generates. Technically, we could use `drake_plan()` if we wanted.

```{r hypotheticaldrakeplan}
library(tidyverse)
drake_plan(
  glue_data(
    list(
      inputs = file_in(c("in1.txt", "in2.txt")), 
      outputs = file_out(c("out1.txt", "out2.txt"))
    ),
    "cat {inputs} > {outputs}"
  ) %>%
    lapply(FUN = system)
)
```

But what if we want to *generate* these [`glue`](https://github.com/tidyverse/glue) commands instead of writing them literally in our plan? This is a job for custom metaprogramming with [tidy evaluation](https://www.youtube.com/watch?v=nERXS3ssntw). First, we create a function to generate the `drake` command of an arbitrary target.

```{r tidyevalplan1}
library(rlang) # for tidy evaluation
write_command <- function(cmd, inputs = NULL , outputs = NULL){
  inputs <- enexpr(inputs)
  outputs <- enexpr(outputs)
  expr({
    glue_data(
      list(
        inputs = file_in(!!inputs),
        outputs = file_out(!!outputs)
      ),
      !!cmd
    ) %>%
      lapply(FUN = system)
  }) %>%
    expr_text
}

write_command(
  cmd = "cat {inputs} > {outputs}",
  inputs = c("in1.txt", "in2.txt"),
  outputs = c("out1.txt", "out2.txt")
) %>%
  cat
```

Then, we lay out all the arguments we will pass to `write_command()`. Here, each row corresponds to a separate target.

```{r tidyevalplan2}
meta_plan <- tribble(
  ~cmd, ~inputs, ~outputs,
  "cat {inputs} > {outputs}", c("in1.txt", "in2.txt"), c("out1.txt", "out2.txt"),
  "cat {inputs} {inputs} > {outputs}", c("out1.txt", "out2.txt"), c("out3.txt", "out4.txt")
) %>%
  print
```

Finally, we create our workflow plan without any built-in `drake` functions.

```{r tidyevalplan3}
plan <- tibble(
  target = paste0("target_", seq_len(nrow(meta_plan))),
  command = pmap_chr(meta_plan, write_command)
) %>%
  print
writeLines("in1", "in1.txt")
writeLines("in2", "in2.txt")
vis_drake_graph(drake_config(plan))
```

Alternatively, you could use `as.call()` instead of tidy evaluation to generate your plan. Use `as.call()` to construct calls to `file_in()`, `file_out()`, and custom functions in your commands.

```{r alternativenontidyplan4}
library(purrr) # pmap_chr() is particularly useful here.

# A function that will be called in your commands.
command_function <- function(cmd, inputs, outputs){
  glue_data(
    list(
      inputs = inputs,
      outputs = outputs
    ),
    cmd
  ) %>%
    purrr::walk(system)
}

# A function to generate quoted calls to command_function(),
# which in turn contain quoted calls to file_in() and file_out().
write_command <- function(...){
  args <- list(...)
  args$inputs <- as.call(list(quote(file_in), args$inputs))
  args$outputs <- as.call(list(quote(file_out), args$outputs))
  c(quote(command_function), args) %>%
    as.call() %>%
    rlang::expr_text()
}

plan <- tibble(
  target = paste0("target_", seq_len(nrow(meta_plan))),
  command = pmap_chr(meta_plan, write_command)
) %>%
  print
```

Metaprogramming gets much simpler if you do not need to construct literal calls to `file_in()`, `file_out()`, etc. in your commands. The construction of `model_plan` in the [gross state product exmaple](#gsp) is an example.

Thanks to [Chris Hammill](https://github.com/cfhammill) for [presenting this scenario and contributing to the solution](https://github.com/ropensci/drake/issues/451).

```{r endofline_plans, echo = FALSE}
clean(destroy = TRUE, verbose = FALSE)
unlink(
  c("main", "code_to_plan", "start.rds", "report.Rmd", "raw_data.xlsx",
    "STDIN.o*", "Thumbs.db", "in1.txt", "in2.txt", "new_script.R",
    "new_notebook.Rmd", "plot.png"),
  recursive = TRUE
)
```

